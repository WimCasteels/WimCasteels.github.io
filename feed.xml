<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="nl"><generator uri="https://jekyllrb.com/" version="4.3.4">Jekyll</generator><link href="https://wimcasteels.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://wimcasteels.github.io/" rel="alternate" type="text/html" hreflang="nl"/><updated>2025-03-16T19:20:16+00:00</updated><id>https://wimcasteels.github.io/feed.xml</id><title type="html">blank</title><subtitle>A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. </subtitle><entry><title type="html">AI als bewaker van fort Europa</title><link href="https://wimcasteels.github.io/blog/2025/fort-europa/" rel="alternate" type="text/html" title="AI als bewaker van fort Europa"/><published>2025-03-16T00:00:00+00:00</published><updated>2025-03-16T00:00:00+00:00</updated><id>https://wimcasteels.github.io/blog/2025/fort-europa</id><content type="html" xml:base="https://wimcasteels.github.io/blog/2025/fort-europa/"><![CDATA[<div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/250316.webp" sizes="95vw"/> <img src="/assets/img/250316.webp" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <p>De inzet van AI voor grensbewaking en immigratiecontrole is een snel groeiende toepassing van deze technologie. Europa investeert miljarden in de ontwikkeling en implementatie van AI-systemen die moeten helpen bij het monitoren en controleren van migratie. Deze ontwikkeling roept belangrijke ethische en praktische vragen op over effectiviteit, mensenrechten en discriminatie.</p> <p>AI wordt veelvuldig toegepast voor surveillance. Bedrijven zoals Amazon gebruiken algoritmisch management om werknemers te monitoren en hun productiviteit automatisch te beoordelen. Bij ondermaatse prestaties kan dit zelfs leiden tot <a href="https://www.theverge.com/2019/4/25/18516004/amazon-warehouse-fulfillment-centers-productivity-firing-terminations">automatisch gegenereerde ontslagbrieven</a>. China zet <a href="https://www.nytimes.com/2022/06/21/world/asia/china-surveillance-investigation.html">grootschalige surveillance</a> in, vooral bij de onderdrukking van de Oeigoerse minderheid in de Xinjiang-regio. Ook de VS heeft <a href="https://www.nytimes.com/2025/01/25/technology/trump-immigration-deportation-surveillance.html">fors geïnvesteerd in deze technologie</a> voor grenscontrole en het opsporen van mensen zonder papieren.</p> <p>Ook Europa zet de laatste jaren sterk in op AI-technologie voor grensbewaking. Dit moet leiden tot kortere verwerkingstijden en minder handmatig werk voor ambtenaren. De totale EU-begroting voor grenzenbeleid is <a href="https://www.statewatch.org/publications/reports-and-books/europe-s-techno-borders/">met 94% gestegen</a> vergeleken met de vorige periode (2014-20) waarvan een aanzienlijk deel bestemd is voor digitale technologieën. Mensenrechtenorganisaties bekritiseren deze systemen vanwege hun gebrek aan transparantie en omdat ze fundamentele rechten bedreigen zoals privacy, non-discriminatie, eerlijk proces en het vermoeden van onschuld.</p> <p>Bij het inzetten van AI-toepassingen voor zulke gevoelige domeinen rijzen er steeds zorgen over de rechtvaardigheid van deze systemen. De algoritmes zijn slechts zo goed als de data waarmee ze worden gevoed, en helaas is neutraliteit geen sterke eigenschap van de mens, iets wat zich weerspiegelt in de data die we genereren. Dit heeft al tot verschillende schandalen geleid, zoals het <a href="https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing">COMPAS systeem</a> dat Amerikaanse rechters hielp bij het bepalen van het risico op recidive, maar systematisch een hoger risico toekende aan mensen met een gekleurde huidskleur. Een ander bekend voorbeeld is de <a href="https://www.bbc.com/news/technology-45809919">seksistische recruiteringstool van Amazon</a>, die bij het automatisch scannen van cv’s vrouwen standaard een lagere score gaf. Deze vooroordelen sluipen vaak zo subtiel in de systemen dat ze pas worden ontdekt als het systeem al in gebruik is.</p> <p>Migratie is een complex beleidsterrein waarbij de overheid via verschillende processen ingrijpt. Het <a href="https://www.rsc.ox.ac.uk/publications/automating-immigration-and-asylum-the-uses-of-new-technologies-in-migration-and-asylum-governance-in-europe">rapport van het Algorithmic Fairness and Asylum Seekers and Refugees (AFAR) Project</a> categoriseert deze AI-toepassingen in drie fasen: voor aankomst, bij aankomst en na aankomst. Hieronder bespreken we enkele voorbeelden samen met de uitdagingen. Deze bespreking is zeker niet volledig, zie bijvoorbeeld het genoemde rapport voor meer voorbeelden.</p> <p>Voor aankomst wordt AI reeds ingezet bij de automatische verwerking van visumaanvragen. Het Britse Home Office gebruikte hiervoor een tool die aanvragen automatisch in drie categorieën sorteerde: groen, oranje of rood. De precieze werking van dit algoritme werd niet gedeeld werd. We weten wel dat nationaliteit een van de beoordelingscriteria was. Verschillende mensenrechtenorganisaties bekritiseerden dat het systeem hierdoor een <a href="https://www.theguardian.com/uk-news/2019/oct/29/ai-system-for-granting-uk-visas-is-biased-rights-groups-claim">“snelle boarding voor witte mensen”</a> creëerde. Dit leidde tot het stopzetten van de tool. Nederland gebruikt een vergelijkbaar systeem dat visumaanvragen automatisch beoordeelt op basis van onder andere nationaliteit, leeftijd en geslacht. De Data Protection Officer (DPO) van het betrokken agentschap heeft dit systeem al meerdere keren <a href="https://www.lighthousereports.com/investigation/ethnic-profiling/">als potentieel discriminerend</a> aangemerkt.</p> <p>Bij aankomst aan de grens kennen de meeste mensen AI van de automatische paspoortcontrole op luchthavens. Hierbij wordt gezichtsherkenning gebruikt om te controleren of een passagier overeenkomt met de persoon op het paspoort. Voor extra betrouwbaarheid worden soms ook irisscans ingezet. De technologie blijkt echter niet feilloos, zoals bleek uit een ‘<a href="https://www.thebulletin.be/fiasco-brussels-airport-scraps-e-passport-gates">fiasco’ op de Brusselse luchthaven</a>. Het systeem slaagde er vaak niet in een match te maken, waardoor de beoogde efficiëntiewinst uitbleef. In één geval liet het systeem zelfs een vrouw door die het paspoort van haar man had gescand. Een andere toepassing op luchthavens zijn camera’s die passagiers scannen en via gezichtsherkenning controleren of er mensen aanwezig zijn die op een ‘zwarte lijst’ staan. Dit gebeurde op de luchthaven van Brussel, grotendeels buiten het zicht van het publiek, totdat het werd <a href="https://www.law.kuleuven.be/citip/blog/facial-recognition-at-brussels-airport-face-down-in-the-mud/">stilgelegd wegens het ontbreken van een juridische basis</a> voor het aanleggen van een biometrische database met gezichtsafbeeldingen.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/250316-1-480.webp 480w,/assets/img/250316-1-800.webp 800w,/assets/img/250316-1-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/250316-1.png" class="img-fluid rounded z-depth-1 mx-auto d-block" width="50%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Poster van de Black Mirror aflevering <a href="https://en.wikipedia.org/wiki/Metalhead_(Black_Mirror)">Metalhead</a> waarin iemand wordt achternagezeten door robothonden. </div> <p>Aan de grens experimenteert men met AI-toepassingen die doen denken aan de dystopische Netflix-serie Black Mirror. Deze worden vaak gefinancierd met Europese subsidies voor onderzoek die bedoeld zijn voor civiele toepassingen, zoals het Horizon-programma. Een voorbeeld is het <a href="https://cordis.europa.eu/project/id/740593">ROBORDER project</a>, dat een volledig autonoom grensbewakingssysteem ontwikkelt met onbemande robots voor lucht, water en land. Een nog controversiëler voorbeeld is het <a href="https://cordis.europa.eu/project/id/700626">iBorderCtrl</a> project. Dit systeem beoordeelt de non-verbale communicatie van reizigers, zoals gezichtsuitdrukking, blik en houding, om te bepalen of zij liegen. Reizigers moeten voor hun reis online vragen beantwoorden van een virtuele grenswacht. Hun reacties worden via de webcam geanalyseerd en beoordeeld op waarheidsgetrouwheid. Bij een hoge ‘leugen-score’ volgt extra onderzoek door grensofficieren. Het project ontving veel kritiek. Zo toonde <a href="https://onlinelibrary.wiley.com/doi/abs/10.1002/acp.1204">onderzoek</a> aan dat het systeem nauwkeuriger is voor Europese mannen dan voor vrouwen en niet-Europeanen. Bovendien staat de onderliggende aanname dat je uit een opname kan bepalen of iemand liegt <a href="https://pubmed.ncbi.nlm.nih.gov/31313636/">wetenschappelijk op losse schroeven</a>. Dit sluit aan bij een <a href="https://www.nature.com/articles/d41586-020-00507-5">breder probleem</a> waarbij AI wordt ingezet voor emotiedetectie, terwijl de wetenschap de effectiviteit hiervan betwijfelt. Een verwant controversieel project is <a href="https://cordis.europa.eu/project/id/787120">TRESSPASS</a>, dat voortbouwt op iBorderCtrl en onderzoekt hoe geautomatiseerde gedragsanalyse kan worden toegepast tijdens interviews met grenswachters.</p> <p>Tot slot wordt AI ook ingezet in het aankomstland. Letland maakt bijvoorbeeld gebruik van automatische spraakherkenning als onderdeel van hun burgerschapsprocedure via het <a href="https://www.pmlp.gov.lv/en/article/artificial-intelligence-support-applicants-citizenship">‘Speak the Anthem’ project</a>. Kandidaten kunnen deze technologie gebruiken om hun uitspraak en kennis van het Letse volkslied te testen, wat een vereiste is voor het verkrijgen van burgerschap. Hoewel de tool niet volledig accuraat is, dient deze alleen als hulpmiddel tijdens het oefenen. De uiteindelijke beoordeling van de uitvoering van het volkslied gebeurt door menselijke beoordelaars.</p> <p>Op andere plaatsen wordt spraaktechnologie minder vrijblijvend ingezet. In Duitsland maakt men als onderdeel van de asielprocedure gebruik van het dialect identificatie assistentie systeem (DIAS). Dit systeem gebruikt AI om talen en dialecten te detecteren van asielzoekers. Het DIAS-systeem analyseert een spraakopname en geeft waarschijnlijkheidspercentages voor verschillende talen (bijvoorbeeld 60% Levantijns Arabisch, 20% Golf-Arabisch, 5% Turks, etc.). Deze resultaten worden toegevoegd aan het asieldossier en kunnen dienen als bewijsmateriaal bij fraudeonderzoek of als bewijsmateriaal voor herkomstlanden voor de terugname van uitgeprocedeerde asielzoekers.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/250316-2-480.webp 480w,/assets/img/250316-2-800.webp 800w,/assets/img/250316-2-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/250316-2.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Proces flow van het Duitse dialect identificatie assistentie systeem (DIAS) (bron: Figuur 7 in het <a href="https://www.rsc.ox.ac.uk/publications/automating-immigration-and-asylum-the-uses-of-new-technologies-in-migration-and-asylum-governance-in-europe">raport van het AFAR Project</a>). </div> <p>Er zijn ernstige vragen over de betrouwbaarheid van deze tool, die door de autoriteiten op 80% werd geschat, al gaven ze aan dat verdere verbetering gepland was. Taalkundigen benadrukken dat het <a href="https://www.dw.com/en/automatic-speech-analysis-software-used-to-verify-refugees-diale">onmogelijk is om met absolute zekerheid een dialect te bepalen</a>. Mensen passen hun spraak immers aan afhankelijk van hun gesprekspartner. Bovendien zijn taal en zeker dialecten dynamisch en constant in verandering. Dit betekent dat de spraakdataset waarop de algoritmes zijn gebaseerd steeds minder relevant wordt en regelmatig zou moeten worden bijgewerkt. Hoewel deze technologie duidelijke tekortkomingen heeft, verschaft ze de autoriteiten wel een modern imago als technologische pionier. Zo werd de DIAS-tool binnen het openbaar bestuur zelfs uitgeroepen tot <a href="https://www.bamf.de/SharedDocs/Meldungen/DE/2018/20180621-am-egovernment.html">beste digitaliseringsproject</a> in 2018.</p> <p>Deze voorbeelden tonen aan dat AI-systemen niet volledig betrouwbaar zijn en kunnen leiden tot discriminatie. Vorig jaar trad de Europese <a href="https://digital-strategy.ec.europa.eu/en/policies/regulatory-framework-ai">AI Act</a> in werking om de risico’s van AI-toepassingen aan te pakken en een juridisch kader te scheppen voor betrouwbare implementatie. Deze treedt stapsgewijs in werking, met een eerste fase begin februari (zie ook <a href="https://wimcasteels.be/blog/2025/AI-Act-stap-1/">Eerste stap van de AI Act. Binnenkort allemaal AI geletterd?</a>) en het grootste deel in augustus 2026. Wat betreft het gebruik van AI-technologieën voor immigratie-, asiel- en grensbewakingsdoeleinden valt in de AI Act vooral het <a href="https://picum.org/blog/a-dangerous-precedent-how-the-eu-ai-act-fails-migrants-and-people-on-the-move/">gebrek aan bescherming voor migranten</a> op. Hoewel de wet automatische emotieherkenning verbiedt wegens gebrek aan wetenschappelijke basis, geldt dit niet voor migratie waardoor bijvoorbeeld het gebruik van AI-leugendetectors aan de grenzen wordt toegestaan. De AI Act is verder alleen van toepassing op systemen die Europese burgers beïnvloeden, niet op Europese bedrijven die AI-tools ontwikkelen voor mensen buiten de EU. Bovendien wordt voor grootschalige IT-systemen van de EU die migrantendata verwerken, zoals <a href="https://www.eulisa.europa.eu/activities/large-scale-it-systems/eurodac">Eurodac</a>, het <a href="https://home-affairs.ec.europa.eu/policies/schengen/schengen-information-system_nl">Schengeninformatiesysteem</a> en <a href="https://travel-europe.europa.eu/etias_en">ETIAS</a>, de AI Act pas in 2030 bindend. Mensenrechtenorganisaties protesteren hiertegen onder de slogan <a href="https://protectnotsurveil.eu/">EU #Protect Not Surveil</a>. Ze pleiten voor een verbod op experimentele technologie tegen grensoverschrijders en dringen aan op effectieve regelgeving die veilig en controleerbaar AI-gebruik garandeert.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/250316-3-480.webp 480w,/assets/img/250316-3-800.webp 800w,/assets/img/250316-3-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/250316-3.png" class="img-fluid rounded z-depth-1 mx-auto d-block" width="50%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Logo van <a href="https://protectnotsurveil.eu/">#Protect Not Surveil</a>. </div> <p>Eind 2023 werd <a href="https://ec.europa.eu/commission/presscorner/detail/en/ip_23_6081">nieuwe Europese wetgeving voorgesteld</a> om op te treden tegen het smokkelen van migranten. Dit bevat een voorstel om de werking van de Europese grensorganisatie Frontex sterk te integreren met de Europese politiedienst Europol waarbij lidstaten verplicht worden data te delen over vluchtelingen. Het doel zou zijn om beter te kunnen optreden tegen illegale smokkelaars maar volgens <a href="https://www.statewatch.org/news/2025/february/eu-digital-and-migrant-rights-groups-call-for-full-rejection-of-new-anti-smuggling-powers/">mensenrechtenorganisaties</a> is het in de praktijk vooral data van de vluchtelingen en hulpverleners die door de politiediensten zullen worden opgevolgd. Mensenrechtenorganisaties argumenteren dat het net dit soort maatregelen zijn die vluchtelingen in de handen van illegale smokkelaars duwen.</p> <p>De toenemende inzet van AI-technologie voor grensbewaking en migratiecontrole in Europa illustreert een belangrijk spanningsveld tussen technologische innovatie en mensenrechten. Hoewel deze systemen efficiëntiewinst beloven, blijken ze in de praktijk vaak onbetrouwbaar en discriminerend. De nieuwe AI Act biedt weliswaar een regelgevend kader, maar laat belangrijke hiaten bestaan in de bescherming van migranten. De recente voorstellen voor nauwere samenwerking tussen Frontex en Europol lijken deze trend voort te zetten, waarbij de focus ligt op surveillance en controle in plaats van humanitaire bescherming. Deze ontwikkelingen roepen fundamentele vragen op over de balans tussen veiligheid en mensenrechten, en de rol die AI zou moeten spelen in het Europese migratiebeleid.</p>]]></content><author><name></name></author><category term="Surveillance"/><category term="Privacy"/><category term="Fort-Europa"/><summary type="html"><![CDATA[De inzet van AI voor grensbewaking en immigratiecontrole is een snel groeiende toepassing van deze technologie. Europa investeert miljarden in de ontwikkeling en implementatie van AI-systemen die moeten helpen bij het monitoren en controleren van migratie. Deze ontwikkeling roept belangrijke ethische en praktische vragen op over effectiviteit, mensenrechten en discriminatie.]]></summary></entry><entry><title type="html">De Groeiende Ecologische Voetafdruk van AI</title><link href="https://wimcasteels.github.io/blog/2025/ecologische-duurzaamheid/" rel="alternate" type="text/html" title="De Groeiende Ecologische Voetafdruk van AI"/><published>2025-02-23T00:00:00+00:00</published><updated>2025-02-23T00:00:00+00:00</updated><id>https://wimcasteels.github.io/blog/2025/ecologische-duurzaamheid</id><content type="html" xml:base="https://wimcasteels.github.io/blog/2025/ecologische-duurzaamheid/"><![CDATA[<div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/250224.webp" sizes="95vw"/> <img src="/assets/img/250224.webp" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <p>Generatieve AI heeft in korte tijd een enorme gebruikersbasis opgebouwd met toepassingen zoals ChatGPT voor gesprekken, Stable Diffusion voor het maken van afbeeldingen en Suno voor muziekgeneratie. Het succes van deze tools is deels te danken aan hun gebruiksvriendelijke interfaces, maar die verbergen de complexe infrastructuur die erachter schuilgaat. Zoals Sam Altman, CEO van OpenAI (het bedrijf achter ChatGPT), het verwoordt: <a href="https://x.com/sama/status/1788989777452408943">’feels like magic’</a>. De realiteit is echter dat deze tools enorme hoeveelheden energie, water en mineralen verbruiken, wat resulteert in een aanzienlijke uitstoot van broeikasgassen.</p> <blockquote class="twitter-tweet"><p lang="en" dir="ltr">not gpt-5, not a search engine, but we’ve been hard at work on some new stuff we think people will love! feels like magic to me.<br/><br/>monday 10am PT. <a href="https://t.co/nqftf6lRL1">https://t.co/nqftf6lRL1</a></p>&mdash; Sam Altman (@sama) <a href="https://twitter.com/sama/status/1788989777452408943?ref_src=twsrc%5Etfw">May 10, 2024</a></blockquote> <script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"></script> <p>Het proces van AI-ontwikkeling gebruikt natuurlijke grondstoffen in verschillende stappen: de ontginning van grondstoffen, de productie van de serverinfrastructuur, de ontwikkeling van het model, het gebruik ervan, en uiteindelijk de afvalverwerking. De ecologische voetafdruk van veel van deze stappen blijft onduidelijk door de complexiteit van de processen en beperkte transparantie van bedrijven. Het meeste onderzoek richt zich op de ontwikkeling en het gebruik van AI-modellen, aangezien deze fasen beter meetbaar zijn.</p> <p>Gedreven door de <a href="https://arxiv.org/abs/2001.08361">schalingswetten</a> worden AI-modellen almaar groter. Deze empirische wetten stellen dat meer data, parameters en computerkracht leiden tot betere nauwkeurigheid. Als gevolg hiervan zijn de modellen de afgelopen jaren exponentieel gegroeid, met een steeds grotere behoefte aan rekenkracht. In de <a href="https://epoch.ai/blog/training-compute-of-frontier-ai-models-grows-by-4-5x-per-year">grafiek van Epoch AI</a> hieronder zien we voor verschillende modellen het aantal benodigde FLOPS voor de ontwikkeling. Een FLOP, wat staat voor Floating Point Operation, is een elementaire computerberekening.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/250224-1-480.webp 480w,/assets/img/250224-1-800.webp 800w,/assets/img/250224-1-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/250224-1.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <p>Het uitvoeren van al deze FLOPs vereist enorme hoeveelheden energie. Hoewel er over de meeste modellen weinig informatie beschikbaar is, biedt <a href="https://arxiv.org/abs/2104.10350">GPT-3</a> een interessant inzicht. Dit OpenAI-model uit 2020, met 175 miljard parameters dat de eerste versie van ChatGPT mogelijk maakte, verbruikte 1.287 MWh en stootte 552 ton CO2 uit tijdens zijn ontwikkeling. Dit energieverbruik staat gelijk aan wat 500 Vlaamse gezinnen jaarlijks verbruiken, terwijl de CO2-uitstoot overeenkomt met die van 120 benzineauto’s per jaar. De nieuwere modellen overtreffen deze cijfers ruimschoots: GPT-4 telt naar schatting 1,8 biljoen parameters, terwijl Gemini Ultra van Google nog eens aanzienlijk groter zou zijn.</p> <p>Zodra een AI-model ontwikkeld is, begint het pas echt: het gebruik ervan wat nog meer energie verbruikt dan de ontwikkeling. Bij <a href="https://arxiv.org/abs/2409.14160">ChatGPT</a>, met zijn miljoenen dagelijkse gebruikers, overtreft het energieverbruik voor gebruik al na enkele weken dat van de training. <a href="https://www.reuters.com/technology/tech-giants-ai-like-bing-bard-poses-billion-dollar-search-problem-2023-02-22/">Google</a> geeft aan dat een vraag via hun AI-model het bedrijf 10 keer meer kost dan een traditionele Google-zoekopdracht. Een typische ChatGPT-vraag verbruikt ongeveer 0,3 wattuur. Dit is minder dan een LED-lamp of laptop gedurende enkele minuten maar varieert wel sterk met de lengte van de vraag (zie onderstaande <a href="https://epoch.ai/gradient-updates/how-much-energy-does-chatgpt-use">figuur van Epoch AI</a>). De impact wordt pas echt duidelijk in de totaalsom: OpenAI heeft wekelijks meer dan <a href="https://www.reuters.com/technology/artificial-intelligence/openais-weekly-active-users-surpass-400-million-2025-02-20/">400 miljoen gebruikers</a> die dagelijks meer dan een miljard berichten versturen. OpenAI is bovendien niet de enige aanbieder: er zijn ook <a href="https://claude.ai/new">Claude</a> van Anthropic, <a href="https://gemini.google.com/app">Gemini</a> van Google en nog vele andere zoals het Chinese Deepseek – dat in januari ChatGPT zelfs onttroonde als <a href="https://techcrunch.com/2025/01/27/deepseek-displaces-chatgpt-as-the-app-stores-top-app/">populairste app</a> in zowel de Android Play Store als de iPhone App Store. AI wordt ook steeds vaker geïntegreerd in andere toepassingen, zoals <a href="https://www.demorgen.be/nieuws/en-de-kbc-werknemer-van-het-jaar-is-kate-hoe-de-ai-assistente-de-bank-naar-nieuwe-hoogtes-stuwt~b60c0b42/">Kate</a>, de AI-assistente van KBC. Het energieverbruik verschilt sterk per taak, waarbij taken met afbeeldingen meer energie vergen. Zo is de energiekost van het genereren van één afbeelding vergelijkbaar met het opladen van een smartphone (220 wattuur).</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/250224-2-480.webp 480w,/assets/img/250224-2-800.webp 800w,/assets/img/250224-2-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/250224-2.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <p>Het geschatte <a href="https://www.iea.org/energy-system/buildings/data-centres-and-data-transmission-networks">wereldwijde elektriciteitsverbruik</a> van datacenters in 2022 was 240-340 TWh, ongeveer 1-1,3% van de mondiale finale elektriciteitsvraag. In 2020 stonden datacenters en de transmissie van data in voor 0,6% van de totale uitstoot van broeikasgassen, vergelijkbaar met de totale uitstoot van de luchtvaartindustrie. Deze datacenters worden natuurlijk niet enkel gebruikt voor AI-toepassingen en er wordt geschat dat AI momenteel instaat voor <a href="https://www.epri.com/research/products/000000003002028905">10-20%</a> van het gebruik, maar dit percentage <a href="https://www.goldmansachs.com/insights/articles/AI-poised-to-drive-160-increase-in-power-demand">stijgt snel</a> (zie <a href="https://www.goldmansachs.com/insights/goldman-sachs-research/generational-growth-ai-data-centers-and-the-coming-us-power-demand-surge">figuur van Goldman Sachs</a> hieronder).</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/250224-3-480.webp 480w,/assets/img/250224-3-800.webp 800w,/assets/img/250224-3-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/250224-3.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <p>Minder dan de helft van de energie die een datacenter verbruikt, gaat naar het voeden van de servers. Een aanzienlijk deel wordt gebruikt voor koeling. Net zoals een laptop tijdens gebruik warm wordt en een ventilator nodig heeft voor koeling of serverruimtes actief gekoeld worden door speciale airco’s. Voor datacenters volgepakt met servers vormt koeling een significante uitdaging: zo’n 30 à 40% van de totale energie gaat hiernaartoe. Dit koelproces vereist grote hoeveelheden water om warmte af te voeren, waarvan een aanzienlijk deel verdampt. <a href="https://arxiv.org/abs/2304.03271">Onderzoek</a> schat dat GPT-3, het AI-model achter ChatGPT, 500ml water verbruikt voor elke 10 tot 50 vragen (al ligt dit voor de nieuwere modellen waarschijnlijk <a href="https://www.thetimes.com/uk/technology-uk/article/thirsty-chatgpt-uses-four-times-more-water-than-previously-thought-bc0pqswdr">4 keer hoger</a>).</p> <p>De enorme energiebehoefte van AI-systemen heeft ervoor gezorgd dat verschillende grote technologiebedrijven zoals <a href="https://www.bloomberg.com/news/articles/2024-05-15/microsoft-s-ai-investment-imperils-climate-goal-as-emissions-jump-30?embedded-checkout=true">Microsoft</a> en <a href="https://www.bloomberg.com/news/articles/2024-07-02/google-s-emissions-shot-up-48-over-five-years-due-to-ai?embedded-checkout=true">Google</a> hun klimaatdoelstellingen niet halen en de vooropgestelde reductie in broeikasgassen niet bereiken. Deze bedrijven zoeken nu naar alternatieve oplossingen om alsnog hun klimaatambities waar te maken zoals het gebruik van groene stroom uit hernieuwbare energie om datacenters te voeden. IJsland is hierdoor een aantrekkelijke locatie geworden voor datacenters: het land beschikt over uitgebreide mogelijkheden voor geothermische en hydroelektrische energie, en door het koude klimaat is er minder energie en water nodig voor koeling. Dit heeft echter ook een <a href="https://www.technologyreview.com/2019/06/18/134902/icelands-data-centers-are-booming-heres-why-thats-a-problem/">keerzijde</a>. Zo vragen milieuactivisten zich af of dit wel een goede besteding van energie is en of deze niet beter gebruikt kan worden voor IJsland zelf.</p> <p>Een andere optie waar de technologiebedrijven in investeren is <a href="https://www.nytimes.com/2024/10/16/business/energy-environment/amazon-google-microsoft-nuclear-energy.html">kernenergie</a>. Hoewel dit een oplossing biedt voor de uitstoot van broeikasgassen, brengt het andere uitdagingen met zich mee, zoals de verwerking van radioactief afval en veiligheidsrisico’s. Een voorbeeld is Microsoft’s overeenkomst om de kerncentrale <a href="https://www.technologyreview.com/2024/09/26/1104516/three-mile-island-microsoft/">Three Mile Island</a> in Pennsylvania te heropenen, een centrale die bekend staat om een gedeeltelijke nucleaire meltdown in 1978.</p> <p>Enkele bedrijven gaan nog verder door datacenters in de ruimte te ontwikkelen, zoals het Europese <a href="https://ascend-horizon.eu/">Ascend</a> en het Amerikaanse <a href="https://www.starcloud.com/">Starcloud</a>. De ruimte biedt twee belangrijke voordelen: ononderbroken toegang tot zonne-energie en natuurlijke koeling door de extreme kou. Voorlopig blijft dit echter science fiction, aangezien het lanceren van de benodigde apparatuur niet rendabel is, ook al dalen deze kosten dankzij bedrijven zoals SpaceX gestaag.</p> <p>Voor de productie van AI-servers zijn verschillende metalen nodig waarvan de ontginning grote ecologische schade veroorzaakt. Sommige van deze metalen, zoals kobalt en wolfraam, zijn conflictmineralen die uit conflictgebieden komen. De ontginning en handel van deze mineralen dragen bij aan mensenrechtenschendingen en gewapende conflicten.</p> <p>De energiehonger van AI-toepassingen blijft onverminderd groeien. De Amerikaanse president Donald Trump kondigde direct na zijn inauguratie het <a href="https://www.forbes.com/sites/moorinsights/2025/01/30/the-stargate-project-trump-touts-500-billion-bid-for-ai-dominance/">Stargate</a> project aan, een ambitieus plan met een geplande investering van 500 miljard dollar in AI-datacenters. Op de AI Action top in Parijs presenteerde de Franse president Emmanuel Macron de overcapaciteit aan kernenergie als Franse troef. Waar volgens hem de VS het motto “drill, baby, drill” hanteert, is het in Frankrijk “<a href="https://www.politico.eu/article/emmanuel-macron-answer-donald-trump-fossil-fuel-drive-artificial-intelligence-ai-action-summit/">plug, baby, plug</a>”. Het <a href="https://www.nytimes.com/2025/01/27/technology/what-is-deepseek-china-ai.html">Chinese Deepseek</a> bewees dat efficiëntere AI-systemen mogelijk zijn, wat een schokgolf door de AI- en financiële wereld stuurde. De langetermijnimpact blijft echter onduidelijk. Volgens Jensen Huang, de CEO van chipmaker NVIDIA, zal de vraag naar servers hierdoor zelfs verder toenemen.</p> <p>Er ontbreken nog veel gegevens voor een volledig beeld van de ecologische voetafdruk van AI. Dit geldt bijvoorbeeld voor informatie over de productie van servers en het <a href="https://restofworld.org/2024/microsoft-data-center-india-mekaguda-industrial-waste/">industrieel afval</a> van datacenters, dat risico’s voor het milieu met zich meebrengt. Daarnaast kan het gebruik van AI voor efficiëntieverbeteringen in vervuilende sectoren paradoxaal genoeg leiden tot meer vervuiling, zoals bij de <a href="https://www.greenpeace.org/usa/oil-in-the-cloud/">exploratie van olie en gas</a>. Daarnaast draagt AI infrastructuur bij aan de groeiende berg e-waste, volgens schattingen tot wel <a href="https://www.technologyreview.com/2024/10/28/1106316/ai-e-waste/">5 miljoen ton in 2030</a>.</p> <p>De uitdagingen rond de ecologische impact van AI vereisen een breed maatschappelijk debat. Technologische vooruitgang hoeft niet ten koste te gaan van het milieu, maar dit vraagt om doordachte keuzes en innovatieve oplossingen. Bedrijven, overheden en consumenten moeten samenwerken om de energietransitie te versnellen en duurzame alternatieven te ontwikkelen. Alleen door de milieukosten volledig mee te rekenen in de ontwikkeling van AI-systemen, kunnen we ervoor zorgen dat artificiële intelligentie bijdraagt aan een duurzame toekomst in plaats van deze te ondermijnen.</p>]]></content><author><name></name></author><category term="Duurzaamheid"/><category term="Uitstoot"/><summary type="html"><![CDATA[De opkomst van AI verbruikt enorme hoeveelheden grondstoffen, waardoor grote technologiebedrijven hun klimaatdoelstellingen niet kunnen halen.]]></summary></entry><entry><title type="html">Wie ligt er nog wakker van de veiligheid van AI?</title><link href="https://wimcasteels.github.io/blog/2025/AI-Veiligheid/" rel="alternate" type="text/html" title="Wie ligt er nog wakker van de veiligheid van AI?"/><published>2025-02-17T00:00:00+00:00</published><updated>2025-02-17T00:00:00+00:00</updated><id>https://wimcasteels.github.io/blog/2025/AI-Veiligheid</id><content type="html" xml:base="https://wimcasteels.github.io/blog/2025/AI-Veiligheid/"><![CDATA[<div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/250218.webp" sizes="95vw"/> <img src="/assets/img/250218.webp" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <p>De lancering van ChatGPT eind 2022 zond een schokgolf door de wereld. Nog nooit bereikte een digitaal hulpmiddel zo snel 100 miljoen gebruikers (in <a href="https://www.theguardian.com/technology/2023/feb/02/chatgpt-100-million-users-open-ai-fastest-growing-app">slechts 2 maanden</a>). Een aanzienlijk deel van de wereldbevolking maakte zo kennis met AI en zijn mogelijkheden. Deze technologie wekte echter ook bezorgdheid op over de veiligheid. De exponentiële vooruitgang riep vragen op over waar dit zou eindigen en of de gevolgen wel positief zouden zijn voor de mensheid. Zorgen ontstonden over de verspreiding van nepnieuws, mogelijke ontwrichting van de arbeidsmarkt en het potentiële verlies van controle over AI-systemen.</p> <p>Het existentiële risico van AI, dat de ontwikkeling ervan zou kunnen leiden tot een humanitaire ramp, spreekt tot de verbeelding. Dit wordt in vaktermen aangeduid als p(doom): de kans dat AI leidt tot een existentiële catastrofe. Uit een <a href="https://wiki.aiimpacts.org/ai_timelines/predictions_of_human-level_ai_timelines/ai_timeline_surveys/2023_expert_survey_on_progress_in_ai">bevraging uit 2023 bij AI-onderzoekers</a> bleek dat ongeveer de helft deze kans hoger inschat dan 10%. De Israëlische historicus Yuval Harari maakte hierover een treffende <a href="https://www.nytimes.com/2023/03/24/opinion/yuval-harari-ai-chatgpt.html">vergelijking met een vliegreis</a>: als de helft van de vliegtuigingenieurs je vertelt dat er 10 procent kans is dat het toestel neerstort, zou je dan instappen? Deze bezorgdheden leidden tot concrete actie. Een <a href="https://futureoflife.org/open-letter/pause-giant-ai-experiments/">open brief</a>, ondertekend door meer dan 30.000 mensen, riep op tot een pauze in de ontwikkeling van grootschalige AI-systemen tot de risico’s beter in kaart zijn gebracht. Ook Sam Altman, CEO van OpenAI (de organisatie achter ChatGPT), <a href="https://www.wired.com/story/sam-altman-world-tour-ai-doomers/">reisde in 2023 de wereld rond</a> om politieke leiders te waarschuwen voor deze gevaren. Al werd dit door velen als een PR-stunt gezien.</p> <p>Het Verenigd Koninkrijk nam onder toenmalig premier Rishi Sunak het initiatief om wereldleiders en vertegenwoordigers uit de industrie samen te brengen tijdens de <a href="https://www.gov.uk/government/topical-events/ai-safety-summit-2023">AI Safety Summit</a>. Deze vond plaats in het symbolische Bletchley Park, waar tijdens de Tweede Wereldoorlog de Duitse code werd gekraakt. De 28 aanwezige landen ondertekenden de <a href="https://www.gov.uk/government/publications/ai-safety-summit-2023-the-bletchley-declaration/the-bletchley-declaration-by-countries-attending-the-ai-safety-summit-1-2-november-2023">Bletchley-verklaring</a>, waarin werd vastgelegd dat AI op een veilige manier moet worden ontworpen, ontwikkeld, ingezet en gebruikt, waarbij de mens centraal staat en betrouwbaarheid en verantwoordelijkheid voorop staan.</p> <p>Verschillende vooraanstaande wetenschappers spraken zich uit over de risico’s van AI, waaronder Geoffrey Hinton en Yoshua Bengio, twee van de drie zogenaamde ‘AI-pioniers’ die in 2018 de <a href="https://awards.acm.org/about/2018-turing">Turing Award</a> wonnen voor hun werk over AI en deep learning. Hinton, die in 2024 nog de Nobelprijs voor natuurkunde ontving, <a href="https://www.theguardian.com/technology/2023/may/02/geoffrey-hinton-godfather-of-ai-quits-google-warns-dangers-of-machine-learning">vertrok bij Google</a> om zich vrij te kunnen uitspreken over de risico’s. Yoshua Bengio werd na de AI Safety top aangesteld door de Britse regering als voorzitter van een wetenschappelijke raad over het thema. Met meer dan 100 wetenschappers uit 30 landen publiceerde hij in januari het <a href="https://www.gov.uk/government/publications/international-ai-safety-report-2025">AI Safety rapport</a>, een document van bijna 300 pagina’s dat uitgebreid ingaat op de risico’s van AI. De derde AI-pionier, Yann LeCun, houdt er als senior wetenschapper bij Meta een <a href="https://www.wsj.com/tech/ai/yann-lecun-ai-meta-aa59e2f5">andere mening</a> op na en denkt dat de nadruk op de existentiële risico’s naast de kwestie zijn.</p> <p>De tweede editie van de AI Safety top vond plaats in Seoul in mei 2024 en resulteerde in een belofte van 27 landen om werk rond ernstige AI-risico’s te verdiepen. Op de derde editie in Parijs vorige week, onder de naam <a href="https://www.elysee.fr/en/sommet-pour-l-action-sur-l-ia">AI Action top</a>, was het oorspronkelijke thema van AI-veiligheid echter vrijwel afwezig. In plaats daarvan lag de nadruk op innovatie. Emmanuel Macron, de president van gastland Frankrijk, opende de top met de aankondiging van Franse AI-investeringen en benadrukte dat Europa en Frankrijk nog volop meedoen in de wereldwijde AI-race. <a href="https://www.euractiv.com/section/tech/news/von-der-leyen-launches-worlds-largest-public-private-partnership-to-win-ai-race/">Ursula von der Leyen</a>, voorzitter van de Europese Commissie<strong>,</strong> sloot zich hierbij aan met Europese investeringsbeloften en de boodschap dat de AI-race nog niet voorbij is. De Amerikaanse vicepresident JD Vance ging nog een stap verder met een pleidooi tegen regulering, waarbij hij waarschuwde dat deze de industrie zou kunnen verstikken. Hoewel de voorzitter van de wetenschappelijke raad Bengio wel in Parijs aanwezig was, sprak hij niet op de hoofdtop maar gaf hij een presentatie op een andere <a href="https://www.iaseai.org/conference">conferentie</a> over het veilig en ethisch gebruik van AI. Opmerkelijk genoeg toonde <a href="https://www.reuters.com/technology/artificial-intelligence/china-is-willing-share-achievements-ai-vice-premier-says-paris-summit-2025-02-11/">China</a>, het land dat vaak wordt gezien als de tegenstander op AI-gebied, de meeste bereidheid tot samenwerking rond veiligheid. Het land gaf aan vorderingen in AI te willen delen om “een gemeenschap met een gedeelde toekomst voor de mensheid” op te bouwen.</p> <p>De VS en het VK <a href="https://www.theguardian.com/technology/2025/feb/11/us-uk-paris-ai-summit-artificial-intelligence-declaration">weigerden</a> de slotverklaring van de Parijse top over ‘inclusieve en duurzame’ AI te ondertekenen. De Amerikaanse vicepresident vertrok zelfs voor het traditionele fotomoment. Kort daarna werd bekend dat het Britse ‘AI Safety Institute’ van <a href="https://www.gov.uk/government/news/tackling-ai-security-risks-to-unleash-growth-and-deliver-plan-for-change">naam verandert</a> naar het ‘AI Security Institute’. Deze naamswijziging weerspiegelt een verschuiving van de focus van existentiële doemscenario’s naar de nationale veiligheidsrisico’s van AI, zoals cyberaanvallen en de productie van chemische of biologische wapens. Dit sluit aan bij de Britse plannen om meer <a href="https://committees.parliament.uk/committee/24/defence-committee/news/204613/defence-committee-mod-must-learn-from-ukraine-and-embrace-ai/">gebruik te maken van AI</a> binnen defensie.</p> <p>In dezelfde week als de top in Parijs <a href="https://www.reuters.com/technology/eu-ditches-plans-regulate-tech-patents-ai-liability-online-privacy-2025-02-12/">schrapte</a> de Europese Commissie de AI-aansprakelijkheidsrichtlijn uit 2022. Deze richtlijn zou consumenten het recht hebben gegeven om schadevergoeding te eisen wanneer ze schade leden door fouten of nalatigheid van AI-aanbieders, -ontwikkelaars of -gebruikers.</p> <p>Het pleidooi van JD Vance’s in Parijs weerspiegelde Donald Trumps visie op AI. Deze richt zich op het positioneren van de VS als wereldleider in AI-ontwikkeling via deregulering, investeringen en innovatie. Tijdens het Wereld Economisch Forum in Davos begin dit jaar verklaarde Trump dat hij van de VS de “<a href="https://www.businesstoday.in/wef-2025/story/trump-outlines-ambitious-vision-for-us-leadership-in-ai-and-cryptocurrency-at-davos-461898-2025-01-24">globale hoofdstad van artificiële intelligentie</a>” wil maken. In lijn met deze visie trok hij een presidentieel besluit van Joe Biden in dat gericht was op het beperken van AI-risico’s voor consumenten, werknemers en de nationale veiligheid. Geruggesteund door deze visie van Trump <a href="https://www.politico.eu/article/google-eu-rules-advanced-ai-artificial-intelligence-step-in-wrong-direction/">bekritiseren</a> de grote technologiebedrijven Meta en Google de Europese AI regulaties als een stap in de verkeerde richting.</p> <p>De zorgen over AI zijn niet verdwenen omdat men de technologie zou onderschatten. Integendeel: tijdens de top in Parijs waarschuwde Dario Amodei, CEO van Anthropic (bekend van chatbot Claude), dat AI-systemen <a href="https://www.anthropic.com/news/paris-ai-summit">tegen 2026</a> mogelijk even krachtig zouden kunnen zijn als een ‘nieuwe natie vol genieën’, met verstrekkende gevolgen voor economie, maatschappij en veiligheid. In een <a href="https://www.bloomberg.com/features/2025-sam-altman-interview/">recent interview</a> voorspelde Sam Altman dat AGI, een AI-systeem dat menselijke intelligentie evenaart, nog tijdens Trumps ambtstermijn gerealiseerd zal worden.</p> <p>Ondertussen pieken de investeringen in het inzetten van AI voor defensie. Bedrijven zoals het controversiële AI-defensiebedrijf Palantir, de beurslieveling die zijn marktwaarde sinds de verkiezing van Trump al met meer dan 180% zag stijgen, hebben de voorbije jaren contracten voor miljarden dollars binnengehaald van de Amerikaanse overheid om de grenzen te bewaken. De CEO, <a href="https://www.wsj.com/tech/who-is-alex-karp-palantir-ceo-dcd66e21">Alex Karp</a>, schreef recent een boek waarin hij pleit dat technologiebedrijven de democratische waarden van het Westen moeten verdedigen. Hij klopt zichzelf op de schouder dat de software van Palantir Amerika dodelijker maakt. Tegelijkertijd heeft OpenAI zijn modellen aangepast en beveiligingen verwijderd om minder te censureren en “<a href="https://techcrunch.com/2025/02/16/openai-tries-to-uncensor-chatgpt/">intellectuele vrijheid meer te omarmen</a>”. Dit betekent dat onderwerpen die tot voor kort werden geweigerd of waar een waarschuwing bij stond, zoals “Black Lives Matter”, nu vrijelijk besproken kunnen worden. Bij verschillende sociale mediabedrijven zoals Meta en X worden veiligheidsteams ontmanteld, wat leidt tot meer tolerantie voor controversiële content.</p> <p>De aandacht voor AI-veiligheid is na de initiële bezorgdheid rond ChatGPT sterk afgenomen. Internationale toppen, oorspronkelijk bedoeld voor veiligheidsdiscussies, zijn verworden tot platforms waar landen vooral hun AI-investeringen en -ambities etaleren. Terwijl de VS onder Trump en de EU onder Von der Leyen inzetten op deregulering en onderlinge competitie, toont China, ironisch genoeg, de meeste bereidheid tot internationale samenwerking op het gebied van veiligheid. Grote technologiebedrijven ontmantelen ondertussen hun veiligheidsteams en verwijderen beveiligingen, terwijl de investeringen in militaire AI-toepassingen een hoogtepunt bereiken. We kunnen alleen maar hopen dat een superintelligente computer niet te snel verschijnt, of op zijn minst menslievend van aard zal zijn.</p>]]></content><author><name></name></author><category term="AI-Veiligheid"/><category term="Europa"/><category term="US"/><summary type="html"><![CDATA[Na de komst van ChatGPT stond AI veiligheid hoog op de (politieke) agenda maar dat lijkt met de AI Action top in Parijs vorige week definitief verleden tijd.]]></summary></entry><entry><title type="html">Eerste stap van de AI Act. Binnenkort allemaal AI geletterd?</title><link href="https://wimcasteels.github.io/blog/2025/AI-Act-stap-1/" rel="alternate" type="text/html" title="Eerste stap van de AI Act. Binnenkort allemaal AI geletterd?"/><published>2025-02-13T00:00:00+00:00</published><updated>2025-02-13T00:00:00+00:00</updated><id>https://wimcasteels.github.io/blog/2025/AI-Act-stap-1</id><content type="html" xml:base="https://wimcasteels.github.io/blog/2025/AI-Act-stap-1/"><![CDATA[<div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/250214.webp" sizes="95vw"/> <img src="/assets/img/250214.webp" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <p>De AI Act reguleert de ontwikkeling en het gebruik van AI binnen de Europese Unie, en geldt ook voor buitenlandse bedrijven die hun producten aan Europeanen aanbieden. De wet heeft een tweeledig doel: enerzijds het bevorderen van veilige en betrouwbare AI-systemen die de fundamentele rechten van EU-burgers respecteren, anderzijds het stimuleren van AI-investeringen en innovatie in Europa. De sancties bij overtreding zijn aanzienlijk: tot 35 miljoen euro of 7% van de jaarlijkse bedrijfsomzet. De AI Act, die op 1 augustus 2024 in werking trad, wordt stapsgewijs ingevoerd. Sinds 2 februari zijn AI-systemen met onacceptabel risico verboden en gelden er verplichtingen rond AI-geletterdheid.</p> <p>De basis van de wet is een indeling van AI-toepassingen in risicoklassen (zie figuur): van onacceptabel (en dus verboden) tot minimaal risico. Systemen in de categorie ‘hoog risico’ moeten voldoen aan strikte verplichtingen, waaronder risicobeoordeling en mitigatie strategieën.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/250214-1-480.webp 480w,/assets/img/250214-1-800.webp 800w,/assets/img/250214-1-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/250214-1.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> De risicoklassen binnen de AI Act (bron: <a href="https://www.adalovelaceinstitute.org/resource/eu-ai-act-explainer/">Ada Lovelace Institute</a>) </div> <p>De risicoklassen in de AI Act zijn niet scherp afgebakend, waardoor er onduidelijkheid bestaat over de classificatie van veel systemen. Om dit te verduidelijken publiceerde de Europese Commissie op 4 februari, twee dagen na de start van het verbod op systemen in de hoogste risicoklasse, een <a href="https://digital-strategy.ec.europa.eu/en/library/commission-publishes-guidelines-prohibited-artificial-intelligence-ai-practices-defined-ai-act">document met richtlijnen</a>. Deze niet-bindende richtlijnen bevatten praktische voorbeelden en toelichtingen voor de interpretatie en naleving van de AI Act. Zo zijn sociale scoringsalgoritmes in het algemeen verboden, maar mogen financiële instellingen wel AI gebruiken om de kredietwaardigheid van klanten te beoordelen. Op 6 februari volgde nog een aanvullende <a href="https://digital-strategy.ec.europa.eu/en/library/commission-publishes-guidelines-ai-system-definition-facilitate-first-ai-acts-rules-application">richtlijn</a> over de definitie van AI en wat er binnen de AI Act onder een AI-systeem valt. Deze tekst stelt vast dat er geen sluitende classificatie of volledige lijst kan worden opgesteld van systemen die wel of niet onder de definitie vallen.</p> <p>De systemen in de hoogste risicoklasse zijn sinds 2 februari in principe verboden, maar de handhaving en sancties van de AI Act treden pas in werking vanaf 2 augustus 2025. Tot die datum blijft het verbod dus zonder actieve handhaving. Er heerst nog veel onduidelijkheid over de implementatie van deze handhaving. Lidstaten moesten voor 2 november 2024 hun nationale bevoegde instanties aanwijzen. Op die deadline hadden slechts <a href="https://artificialintelligenceact.eu/national-implementation-plans/">7 van de 27 lidstaten</a> dit gedaan, en <a href="https://digital-strategy.ec.europa.eu/en/policies/ai-act-governance-and-enforcement">op het moment dat deze post verschijnt</a> zijn er nog steeds 6 lidstaten die in gebreke blijven, waaronder, je raadt het al, België.</p> <p>De AI Act wordt wereldwijd gezien als een van de meest vooruitstrevende AI-wetgevingen, maar de totstandkoming verliep moeizaam. Het proces begon in april 2021 met een eerste <a href="https://digital-strategy.ec.europa.eu/en/library/proposal-regulation-laying-down-harmonised-rules-artificial-intelligence">voorstel van de Europese Commissie</a> en duurde tot eind 2023 voordat de finale tekst werd goedgekeurd. Een belangrijke complicerende factor was de introductie van ChatGPT tijdens het wetgevingsproces. Deze ontwikkeling leidde ertoe dat plotseling veel meer mensen AI gingen gebruiken. De snelle evolutie van de onderliggende taalmodellen, die steeds krachtiger werden, bracht nieuwe risico’s met zich mee die niet in het originele voorstel waren meegenomen. Deze systemen werden uiteindelijk in 2023 in de wetgeving opgenomen onder de bredere term ‘general-purpose AI<em>’</em> (GPAI) modellen.</p> <p>De ontwikkeling van deze GPAI-modellen vereist enorme investeringen. Dit leidde bij de introductie in de AI Act tot intensieve lobbyactiviteiten vanuit de industrie. Het <a href="https://digital-strategy.ec.europa.eu/en/policies/regulatory-framework-ai">Byte to Byte</a> rapport van Corporate Europe Observatory toont aan dat grote technologiebedrijven buitenproportioneel veel toegang hadden tot Europese beleidsmakers in vergelijking met andere belanghebbenden (zie ook figuur). Een sprekend voorbeeld: Google’s CEO Sundar Pichai wist op één dag gesprekken te voeren met drie verschillende Europese commissarissen.</p> <p align="center"><iframe aria-label="Bar chart" data-external="1" frameborder="0" height="205" id="datawrapper-chart-0CcqX" scrolling="no" src="https://datawrapper.dwcdn.net/0CcqX/1/" style="border: none;" title="Top 5 lobbyists on the AI Act in 2023" width="600"></iframe></p> <p>Het lobbywerk tegen de AI Act was succesvol en zwakte de wetgeving aanzienlijk af, maar het was uiteindelijk de <a href="https://corporateeurope.org/en/2024/03/trojan-horses-how-european-startups-teamed-big-tech-gut-ai-act">weerstand vanuit Europa</a> zelf die de doorslag gaf. De Franse startup Mistral AI en de Duitse startup Aleph Alpha vonden gehoor bij hun respectievelijke regeringen. Een Frans-Duits-Italiaans front zorgde er vervolgens voor dat bindende maatregelen uit de AI Act verdwenen en werden vervangen door transparantievereisten. De strengste regels gelden voor <a href="https://artificialintelligenceact.eu/article/51/">GPAI-systemen met een systemisch risico</a>. De enige concrete definitie hiervoor betreft modellen waarvoor bij de ontwikkeling meer dan 10^24 FLOPS aan computerberekeningen nodig waren, een enorme hoeveelheid waar momenteel wereldwijd alleen GPT-4 van OpenAI onder valt. Deze grens lijkt al helemaal achterhaald sinds het <a href="https://www.technologyreview.com/2025/01/24/1110526/china-deepseek-top-ai-despite-sanctions/">Chinese Deepseek</a> aantoonde dat er veel minder computerkracht nodig is voor deze modellen. Hoewel modellen met grote maatschappelijke impact ook onder deze categorie met systemisch risico vallen, blijft vooralsnog onduidelijk hoe dit precies wordt bepaald.</p> <p>Tijdens de <a href="https://www.elysee.fr/en/sommet-pour-l-action-sur-l-ia">AI Action top</a> in Parijs eerder deze week leken sommige Europese leiders gemengde gevoelens te hebben over de AI Act. De Franse president <a href="https://www.nytimes.com/2025/02/10/business/ai-summit-paris.html">Macron</a> benadrukte het belang van innovatie en waarschuwde dat regulering deze kan belemmeren. Hij verklaarde dat Europa nog steeds meedoet in de ‘AI race’ en kondigde <a href="https://www.cnbc.com/2025/02/10/frances-answer-to-stargate-macron-announces-ai-investment.html">Franse investeringen</a> aan ter waarde van 109 miljard euro. <a href="https://www.euractiv.com/section/tech/news/von-der-leyen-launches-worlds-largest-public-private-partnership-to-win-ai-race/">Ursula Von der Leyen</a>, de voorzitter van de Europese Commissie<strong>,</strong> bevestigde dat de AI race nog niet voorbij is en lanceerde InvestAI, een publiek-private samenwerking ter waarde van 200 miljard euro. De Amerikaanse vicepresident <a href="https://www.reuters.com/technology/artificial-intelligence/europe-looks-embrace-ai-paris-summits-2nd-day-while-global-consensus-unclear-2025-02-11/">JD Vance</a> verzette zich nadrukkelijk tegen regulering en stelde dat de Europese wetgeving de technologie ‘wurgt’. De slotverklaring van de top in Parijs over ‘inclusieve en duurzame AI’ werd niet ondertekend door de VS en het VK, waardoor de top algemeen als een gemiste kans wordt beschouwd.</p> <p>Op 2 februari trad ook het artikel over AI-geletterdheid in de AI Act in werking. De originele versie was hier een <a href="https://www.law.kuleuven.be/citip/blog/this-time-humans-learn-about-machines-ai-literacy-in-the-ai-act-part-1/">stuk ambitieuzer</a>: deze verplichtte zowel lidstaten als bedrijven om AI-geletterdheid in alle sectoren van de samenleving te bevorderen. In het <a href="https://artificialintelligenceact.eu/article/4/">finale artikel</a> zijn de lidstaten echter geschrapt en richt de wet zich alleen op AI-bedrijven. Zij moeten ervoor zorgen dat hun personeel en andere betrokkenen een ‘voldoende niveau’ van AI-geletterdheid bereiken. Dit niveau hangt af van de context, zoals de risicoklasse van het AI-systeem, maar wat precies als ‘voldoende’ wordt beschouwd en hoe dit zal worden gehandhaafd, blijft voorlopig onduidelijk.</p> <p>De <a href="https://artificialintelligenceact.eu/article/3/">definitie van AI-geletterdheid</a> in de AI Act reikt verder dan alleen bedrijven en deze vermeld dat ook personen die door AI-systemen worden beïnvloed, moeten beschikken over AI-geletterdheid. In de definitie wordt bij AI geletterdheid onder andere verstaan dat men bewust is van de mogelijkheden, risico’s en potentiële schade van AI. Dit stuk gaat veel breder dan enkel de werknemers van AI bedrijven. Een aanvullende bepaling (<a href="https://artificialintelligenceact.eu/recital/20/"><em>Recital 20</em></a>) benadrukt het belang van een brede implementatie van AI-geletterdheid en de rol van de <a href="https://digital-strategy.ec.europa.eu/en/policies/ai-board">Europese AI Raad</a> hierin. We kunnen dus verwachten dat Europa nog meer initiatieven zal lanceren rond AI-geletterdheid. De Vlaamse AI Academy (VAIA) voorziet alvast enkele <a href="https://www.vaia.be/nl/blog/ai-literacy-eu-ai-act-artikel-4">tips</a> om te werken aan AI geletterdheid.</p> <p>De AI Act is vooruitstrevend en behandelt belangrijke maatschappelijke uitdagingen van AI (hoewel bijvoorbeeld de ecologische voetafdruk buiten beschouwing blijft). De implementatie blijkt echter complex. De wet beoogt innovatie te stimuleren, maar de industrie toonde zich hierover sceptisch. Door krachtige tegenstand is de wetgeving significant afgezwakt. Er zijn nog diverse obstakels te overwinnen, waarbij veel zal afhangen van de uiteindelijke interpretatie en handhaving, aspecten die momenteel nog onduidelijk zijn.</p>]]></content><author><name></name></author><category term="AI-Act"/><category term="Europa"/><summary type="html"><![CDATA[Begin februari trad de eerste fase van de AI Act in werking. Deze Europese wetgeving verbiedt AI-systemen met een onacceptabel risico en stelt verplichtingen over AI-geletterdheid.]]></summary></entry><entry><title type="html">Maakt AI ons dommer?</title><link href="https://wimcasteels.github.io/blog/2025/dommer/" rel="alternate" type="text/html" title="Maakt AI ons dommer?"/><published>2025-02-05T12:00:00+00:00</published><updated>2025-02-05T12:00:00+00:00</updated><id>https://wimcasteels.github.io/blog/2025/dommer</id><content type="html" xml:base="https://wimcasteels.github.io/blog/2025/dommer/"><![CDATA[<div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/250205.webp" sizes="95vw"/> <img src="/assets/img/250205.webp" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <p>Een vaak gehoord cliché over de impact van AI op de arbeidsmarkt is dat niet AI je baan zal afnemen, maar iemand die AI wél gebruikt. Deze uitspraak verwijst naar de efficiëntiewinst die je met AI-tools kunt behalen, waardoor je meer werk verzet en waardevoller wordt voor je werkgever. Dat AI een grondige impact zal hebben op de arbeidsmarkt staat vast, al lopen de voorspellingen soms wild uiteen. Zo voorspelt <a href="https://www.cognizant.com/en_us/insights/documents/new-work-new-world-with-generative-ai-wf2064768.pdf">een studie</a> dat in de komende 10 jaar 90% van de jobs verstoord zullen worden door AI. Het <a href="https://www.imf.org/en/Blogs/Articles/2024/01/14/ai-will-transform-the-global-economy-lets-make-sure-it-benefits-humanity">IMF</a> houdt het bij dat wereldwijd 40% van de banen door AI geïmpacteerd zullen worden. Waar de industriële revolutie vooral effect had op arbeiders, zal AI eerder de kenniseconomie beïnvloeden. Het IMF voorspelt dan ook dat het effect veel groter zal zijn in geavanceerde economieën ten opzichte van lageloonlanden.</p> <p>Er is steeds meer bewijs dat AI de efficiëntie aanzienlijk verhoogt. Uit een <a href="https://www.adeccogroup.com/our-group/media/press-releases/ai-saves-workers-an-average-of-one-hour-each-day">bevraging</a> blijkt dat werknemers gemiddeld een uur per dag besparen door AI-gebruik. Wetenschappelijk onderzoek bevestigt deze trend. In een <a href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4573321">experiment</a> waarbij consultants 18 realistische taken moesten uitvoeren, presteerden degenen met toegang tot de GPT-4 AI-tool significant beter op zowel productiviteit als kwaliteit. De onderzoekers identificeerden twee succesvolle gebruikspatronen: de “Centauren” en de “Cyborgs”. De Centauren, vernoemd naar het mythische wezen dat half mens, half paard is, wisselden bewust af tussen eigen werk en AI-ondersteuning. De Cyborgs daarentegen integreerden AI volledig in hun werkproces en werkten continu samen met de technologie.</p> <p>Een <a href="https://www.upwork.com/research/ai-enhanced-work-models">enquête</a> toont aan dat dit enorme potentieel van AI ook nadelen heeft, zoals een verhoogde druk op werknemers om ermee te werken. Het onderzoek onthult een duidelijke kloof tussen de verwachtingen van werkgevers en werknemers. Waar 96% van de werkgevers gelooft dat AI-tools de productiviteit van hun bedrijf zullen verhogen, worstelen werknemers met de praktijk. Bijna de helft van de werknemers die AI gebruiken, weet niet hoe ze de verwachte productiviteitswinst kunnen behalen. Sterker nog, meer dan drie op de vier werknemers melden dat AI-tools hun productiviteit hebben verlaagd en hun werkdruk hebben verhoogd. Ze besteden bijvoorbeeld veel tijd aan het aanpassen van AI-gegenereerde content, terwijl het bedrijf tegelijkertijd hogere verwachtingen stelt.</p> <p>Deze productiviteitswinst is ook al uitgebreid waargenomen bij leerlingen. Een <a href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4895486">studie</a> met middelbare scholieren toonde aan dat toegang tot GPT-4 hun wiskundeprestaties aanzienlijk verbeterde. Wat echter opmerkelijk was dat wanneer deze toegang later werd weggenomen de leerlingen slechter presteerden dan degenen die nooit toegang hadden gehad. De conclusie was dat toegang tot GPT-4 schadelijk kan zijn voor onderwijsresultaten. De resultaten suggereren dat leerlingen GPT-4 gebruiken als een “kruk” tijdens het oefenen, waardoor ze uiteindelijk minder goed presteren wanneer ze op eigen kracht moeten werken.</p> <p>Een <a href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=5082524">recente studie</a> onderzocht hoe AI-tools zoals ChatGPT het kritisch denken en cognitieve vaardigheden beïnvloeden. Via een enquête werd onderzocht hoe mensen AI-tools gebruiken, hoe goed ze kritisch kunnen denken, en in welke mate ze digitale hulpmiddelen inzetten voor geheugen en probleemoplossing, ook wel cognitieve uitbesteding genoemd. De resultaten toonden aan dat mensen die vaak AI gebruiken minder goed kritisch denken, waarbij een toename in cognitieve uitbesteding een belangrijke verklarende factor was.</p> <p>Dit is niet de eerste keer dat er zorgen zijn over technologie die ons mogelijk dommer zou maken. In de <a href="https://www.washingtonpost.com/archive/local/1986/04/04/math-teachers-stage-a-calculated-protest/c003ddaf-b86f-4f2b-92ca-08533f3a5896/">jaren ‘70 en ‘80</a> vreesden docenten dat rekenmachines zouden leiden tot een afname van basale wiskundige vaardigheden. Nu pleit vrijwel niemand meer voor een verbod op rekenmachines. De smartphone is een vergelijkbaar voorbeeld. Ondanks de vele voordelen maken velen zich zorgen over de impact ervan op onze hersenen. Niet voor niets kreeg het Oxford woord van het jaar ‘<em>brain rot</em>’ (hersenslijtage) de meeste stemmen, een term die verwijst naar de mentale achteruitgang door het eindeloos consumeren van oppervlakkige en weinig stimulerende online inhoud. Mensen blijken ook minder geneigd te zijn om informatie te onthouden als ze weten dat deze online beschikbaar is, het zogenaamde <a href="https://en.wikipedia.org/wiki/Google_effect">Google-effect</a>. Een <a href="https://www.nature.com/articles/s41598-023-36256-4?utm_source=chatgpt.com">studie</a> laat zelfs zien dat alleen al de aanwezigheid van een smartphone leidt tot verminderde aandacht en concentratie. Hoewel smartphones ongetwijfeld gebruikt worden voor domme dingen, is de vraag of we er daadwerkelijk dommer van worden genuanceerder. Ondanks de vele suggesties in die richting bestaat hiervoor <a href="https://www.theguardian.com/lifeandstyle/2025/jan/29/all-in-the-mind-the-surprising-truth-about-brain-rot">geen wetenschappelijk bewijs</a>.</p> <p>De impact van AI op onze cognitieve vaardigheden is een complex vraagstuk zonder eenvoudig antwoord. De productiviteitswinsten door AI zijn weliswaar onmiskenbaar, maar eerste studies wijzen op mogelijke negatieve effecten op ons leervermogen en kritisch denken. Net zoals bij eerdere technologische innovaties, denk aan de rekenmachine en smartphone, moeten we een evenwicht vinden tussen het benutten van de voordelen en het behouden van onze eigen cognitieve capaciteiten. Dit vereist een doordachte integratie van AI in zowel onderwijs als werk, waarbij we verder kijken dan alleen efficiëntiewinst en ons richten op het behoud en de ontwikkeling van essentiële menselijke vaardigheden. Omdat we nog maar aan het begin staan van grootschalig AI-gebruik, is verder onderzoek cruciaal om de langetermijneffecten beter te begrijpen.</p>]]></content><author><name></name></author><category term="werk"/><summary type="html"><![CDATA[AI maakt ons productiever op het werk, maar wat is het effect op de mensen die deze tools gebruiken?]]></summary></entry><entry><title type="html">Chinese startup zet AI en financiële wereld op zijn kop</title><link href="https://wimcasteels.github.io/blog/2025/deepseek/" rel="alternate" type="text/html" title="Chinese startup zet AI en financiële wereld op zijn kop"/><published>2025-01-30T12:00:00+00:00</published><updated>2025-01-30T12:00:00+00:00</updated><id>https://wimcasteels.github.io/blog/2025/deepseek</id><content type="html" xml:base="https://wimcasteels.github.io/blog/2025/deepseek/"><![CDATA[<div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/Deepseek.webp" sizes="95vw"/> <img src="/assets/img/Deepseek.webp" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <p>Deepseek, een jonge Chinese start-up opgericht in 2023, domineert deze week het wereldnieuws. Met hun nieuwe AI-model R1 behalen ze resultaten die de modellen van OpenAI, het bedrijf achter ChatGPT, overtreffen. Het meest verrassende is dat ze dit bereikten met slechts een fractie van de gebruikelijke AI-serverinfrastructuur. Ironisch genoeg viel dit nieuws vrijwel samen met de aankondiging van project Stargate door president Trump, waarin een investering van 500 miljard dollar voor AI-computerinfrastructuur wordt voorzien. Deepseek heeft ChatGPT verdrongen als populairste app. Deze ontwikkeling zorgde voor onrust over het rendement van de enorme AI-investeringen, wat leidde tot een forse beursdaling op maandag waarbij meer dan een biljoen dollar aan beurswaarde verdampte. De cruciale vraag is nu welke blijvende impact Deepseek zal hebben op de ontwikkeling van het AI-domein.</p> <p>Er is weinig bekend over de grote AI-modellen. De grote technologiebedrijven zijn uiterst terughoudend met informatie over hun modellen en stellen dat dit nodig is om misbruik van de technologie te voorkomen. Een andere mogelijke reden voor deze geheimhouding is de vrees voor juridische gevolgen en reputatieschade als zou uitkomen welke data ze gebruiken, zoals persoonsgegevens of auteursrechtelijk beschermd materiaal, of hoe groot hun ecologische voetafdruk werkelijk is. Volgens onafhankelijke schattingen liggen de kosten voor deze geavanceerde modellen rond de 100 miljoen dollar.</p> <p>Toen verscheen Deepseek, een jonge Chinese startup die AI-taalmodellen ontwikkelt. Hun nieuwste R1-model presteert op verschillende tests even goed of zelfs beter dan de modellen van OpenAI. En dit voor slechts een fractie van de kosten. Het opmerkelijke is dat deze doorbraak plaatsvond in China, waar Amerika al jaren exportrestricties handhaaft op computerchips om de ontwikkeling van geavanceerde AI-modellen te belemmeren. NVIDIA, dat met een marktaandeel van 90% de AI-chipmarkt domineert, mag zijn meest geavanceerde chips niet naar China exporteren. Deze exportbeperkingen hadden echter een onverwacht effect: doordat Chinese onderzoekers geen toegang hadden tot de nieuwste hardware, werden ze gedwongen creatief om te gaan met de beschikbare middelen. Dit leidde tot het efficiënter trainen van modellen en uiteindelijk tot lagere kosten.</p> <p>In tegenstelling tot veel Amerikaanse techbedrijven geeft Deepseek openlijk inzicht in hun modellen, die vrij beschikbaar zijn via het online platform HuggingFace. Het R1-model werd in de eerste dagen na lancering al bijna 300.000 keer gedownload. Tot voor kort was open source ook bij Amerikaanse technologiebedrijven de norm voor AI-ontwikkeling. Open source werkt als katalysator omdat iedereen kan bijdragen aan de ontwikkeling. De huidige felle concurrentie tussen deze bedrijven op het gebied van AI-toepassingen heeft deze openheid echter verminderd. Verschillende onderzoekers, ook in de VS, zijn inmiddels aan de slag gegaan met de Deepseek-modellen. Dit kan op termijn gunstig uitpakken voor Chinese bedrijven, waar open source nog steeds de norm is, omdat zij kunnen profiteren van een wereldwijde gemeenschap die hun modellen doorontwikkelt.</p> <p>De ontwikkeling van Deepseeks efficiëntere modellen roept ernstige vragen op over de duurzaamheid van OpenAI’s bedrijfsmodel. Het bedrijf heeft nog geen winst gemaakt door de enorme kosten voor serverinfrastructuur en kan alleen blijven functioneren dankzij miljarden-investeringen van Microsoft. OpenAI verwacht zelf pas in 2029 winstgevend te worden. Samen met Oracle en NVIDIA lanceerde het bedrijf onlangs het Stargate-project: een investering van 500 miljard dollar in serverinfrastructuur om “het Amerikaanse leiderschap in AI veilig te stellen”. De lancering van Deepseeks R1 werpt echter een nieuw licht op deze gigantische investeringen. Dit wordt treffend geïllustreerd door een video uit 2023 die deze week viraal ging, waarin Sam Altman, CEO van OpenAI, beweerde dat “het totaal hopeloos is om met ons te concurreren” met een budget van ‘slechts’ 10 miljoen dollar.</p> <p>Deze ontwikkeling zorgde voor onrust bij investeerders, wat resulteerde in een forse daling op de Amerikaanse technologiebeurs. De Nasdaq Composite index zakte maandag met 3,6%, de grootste daling in vijf maanden. Meer dan 1 biljoen dollar aan wereldwijde beurswaarde ging in rook op. NVIDIA, de favoriet van Wall Street, kreeg de zwaarste klap. Het bedrijf had dankzij zijn dominante positie in de hoogwaardige computerchipmarkt enorm geprofiteerd van de AI-boom. Hun aandelen waren in de twee jaar na de lancering van ChatGPT met wel 800% gestegen, waardoor NVIDIA in november 2024 zelfs kortstondig Apple passeerde als waardevolste bedrijf. Op maandag verloor NVIDIA echter 17% van zijn marktwaarde, wat neerkwam op bijna 600 miljard dollar.</p> <p>Deepseek R1 presteert ook beter dan Amerikaanse modellen in het uitdragen van het socialistische gedachtegoed van de Chinese Communistische Partij. Het model weigert te reageren op vragen over de protesten op het Tiananmenplein in 1989 of vergelijkingen tussen Xi Jinping en Winnie de Pooh. China loopt ook voor op het gebied van AI-regulering. Nieuwe AI-modellen moeten eerst goedkeuring krijgen van de Communistische Partij, die controleert of het model correct omgaat met gevoelige onderwerpen. Deze ontwikkelingen leiden tot zorgen over het wijdverspreide gebruik van de Deepseek-app, met name over mogelijke desinformatie en het potentiële misbruik van gebruikersgegevens door de Chinese overheid.</p> <p>Kunnen deze kleinere, efficiëntere modellen bijdragen aan het behalen van klimaatdoelstellingen? Veel technologiebedrijven slagen er momenteel niet in hun klimaatdoelen te halen vanwege hun energieverslindende AI-modellen. De Jevons-paradox biedt hierbij een interessant perspectief: wanneer technologie efficiënter wordt, neemt het totale verbruik vaak juist toe in plaats van af. Dit zou kunnen betekenen dat efficiëntere AI-modellen paradoxaal genoeg leiden tot een hogere totale vraag en grotere marktgroei.</p> <p>Is dit het einde voor het voorheen onaantastbare NVIDIA? Dit lijkt voorbarig, aangezien NVIDIA nog steeds de onbetwiste leider is op het gebied van computerchips. Deepseek maakt bijvoorbeeld ook gebruik van NVIDIA-infrastructuur. De aandelenkoers herstelde zich dinsdag dan ook al deels met een stijging van 9%.</p> <p>Kan Deepseek de macht van de Amerikaanse Big Tech-bedrijven inperken? De markt voor de grote ‘foundation’-modellen is opengebroken nu het mogelijk is om zeer capabele modellen te ontwikkelen met beperkte middelen. De enorme investeringen die voorheen noodzakelijk leken, waren slechts voor een kleine groep weggelegd. Nu blijkt dat dit kan voor een fractie van de kosten, waardoor er plotseling veel meer potentiële spelers zijn. Deze Chinese doorbraak in de mondiale AI-race zou ook Europese organisaties kunnen helpen om hun eigen modellen te ontwikkelen.</p>]]></content><author><name></name></author><category term="china"/><category term="big-tech"/><summary type="html"><![CDATA[Deepseek, een jonge Chinese start-up opgericht in 2023, domineert deze week het wereldnieuws. Met hun nieuwe AI-model R1 behalen ze resultaten die de modellen van OpenAI, het bedrijf achter ChatGPT, overtreffen. Het meest verrassende is dat ze dit bereikten met slechts een fractie van de gebruikelijke AI-serverinfrastructuur. Ironisch genoeg viel dit nieuws vrijwel samen met de aankondiging van project Stargate door president Trump, waarin een investering van 500 miljard dollar voor AI-computerinfrastructuur wordt voorzien. Deepseek heeft ChatGPT verdrongen als populairste app. Deze ontwikkeling zorgde voor onrust over het rendement van de enorme AI-investeringen, wat leidde tot een forse beursdaling op maandag waarbij meer dan een biljoen dollar aan beurswaarde verdampte. De cruciale vraag is nu welke blijvende impact Deepseek zal hebben op de ontwikkeling van het AI-domein. Er is weinig bekend over de grote AI-modellen. De grote technologiebedrijven zijn uiterst terughoudend met informatie over hun modellen en stellen dat dit nodig is om misbruik van de technologie te voorkomen. Een andere mogelijke reden voor deze geheimhouding is de vrees voor juridische gevolgen en reputatieschade als zou uitkomen welke data ze gebruiken, zoals persoonsgegevens of auteursrechtelijk beschermd materiaal, of hoe groot hun ecologische voetafdruk werkelijk is. Volgens onafhankelijke schattingen liggen de kosten voor deze geavanceerde modellen rond de 100 miljoen dollar. Toen verscheen Deepseek, een jonge Chinese startup die AI-taalmodellen ontwikkelt. Hun nieuwste R1-model presteert op verschillende tests even goed of zelfs beter dan de modellen van OpenAI. En dit voor slechts een fractie van de kosten. Het opmerkelijke is dat deze doorbraak plaatsvond in China, waar Amerika al jaren exportrestricties handhaaft op computerchips om de ontwikkeling van geavanceerde AI-modellen te belemmeren. NVIDIA, dat met een marktaandeel van 90% de AI-chipmarkt domineert, mag zijn meest geavanceerde chips niet naar China exporteren. Deze exportbeperkingen hadden echter een onverwacht effect: doordat Chinese onderzoekers geen toegang hadden tot de nieuwste hardware, werden ze gedwongen creatief om te gaan met de beschikbare middelen. Dit leidde tot het efficiënter trainen van modellen en uiteindelijk tot lagere kosten. In tegenstelling tot veel Amerikaanse techbedrijven geeft Deepseek openlijk inzicht in hun modellen, die vrij beschikbaar zijn via het online platform HuggingFace. Het R1-model werd in de eerste dagen na lancering al bijna 300.000 keer gedownload. Tot voor kort was open source ook bij Amerikaanse technologiebedrijven de norm voor AI-ontwikkeling. Open source werkt als katalysator omdat iedereen kan bijdragen aan de ontwikkeling. De huidige felle concurrentie tussen deze bedrijven op het gebied van AI-toepassingen heeft deze openheid echter verminderd. Verschillende onderzoekers, ook in de VS, zijn inmiddels aan de slag gegaan met de Deepseek-modellen. Dit kan op termijn gunstig uitpakken voor Chinese bedrijven, waar open source nog steeds de norm is, omdat zij kunnen profiteren van een wereldwijde gemeenschap die hun modellen doorontwikkelt. De ontwikkeling van Deepseeks efficiëntere modellen roept ernstige vragen op over de duurzaamheid van OpenAI’s bedrijfsmodel. Het bedrijf heeft nog geen winst gemaakt door de enorme kosten voor serverinfrastructuur en kan alleen blijven functioneren dankzij miljarden-investeringen van Microsoft. OpenAI verwacht zelf pas in 2029 winstgevend te worden. Samen met Oracle en NVIDIA lanceerde het bedrijf onlangs het Stargate-project: een investering van 500 miljard dollar in serverinfrastructuur om “het Amerikaanse leiderschap in AI veilig te stellen”. De lancering van Deepseeks R1 werpt echter een nieuw licht op deze gigantische investeringen. Dit wordt treffend geïllustreerd door een video uit 2023 die deze week viraal ging, waarin Sam Altman, CEO van OpenAI, beweerde dat “het totaal hopeloos is om met ons te concurreren” met een budget van ‘slechts’ 10 miljoen dollar. Deze ontwikkeling zorgde voor onrust bij investeerders, wat resulteerde in een forse daling op de Amerikaanse technologiebeurs. De Nasdaq Composite index zakte maandag met 3,6%, de grootste daling in vijf maanden. Meer dan 1 biljoen dollar aan wereldwijde beurswaarde ging in rook op. NVIDIA, de favoriet van Wall Street, kreeg de zwaarste klap. Het bedrijf had dankzij zijn dominante positie in de hoogwaardige computerchipmarkt enorm geprofiteerd van de AI-boom. Hun aandelen waren in de twee jaar na de lancering van ChatGPT met wel 800% gestegen, waardoor NVIDIA in november 2024 zelfs kortstondig Apple passeerde als waardevolste bedrijf. Op maandag verloor NVIDIA echter 17% van zijn marktwaarde, wat neerkwam op bijna 600 miljard dollar. Deepseek R1 presteert ook beter dan Amerikaanse modellen in het uitdragen van het socialistische gedachtegoed van de Chinese Communistische Partij. Het model weigert te reageren op vragen over de protesten op het Tiananmenplein in 1989 of vergelijkingen tussen Xi Jinping en Winnie de Pooh. China loopt ook voor op het gebied van AI-regulering. Nieuwe AI-modellen moeten eerst goedkeuring krijgen van de Communistische Partij, die controleert of het model correct omgaat met gevoelige onderwerpen. Deze ontwikkelingen leiden tot zorgen over het wijdverspreide gebruik van de Deepseek-app, met name over mogelijke desinformatie en het potentiële misbruik van gebruikersgegevens door de Chinese overheid. Kunnen deze kleinere, efficiëntere modellen bijdragen aan het behalen van klimaatdoelstellingen? Veel technologiebedrijven slagen er momenteel niet in hun klimaatdoelen te halen vanwege hun energieverslindende AI-modellen. De Jevons-paradox biedt hierbij een interessant perspectief: wanneer technologie efficiënter wordt, neemt het totale verbruik vaak juist toe in plaats van af. Dit zou kunnen betekenen dat efficiëntere AI-modellen paradoxaal genoeg leiden tot een hogere totale vraag en grotere marktgroei. Is dit het einde voor het voorheen onaantastbare NVIDIA? Dit lijkt voorbarig, aangezien NVIDIA nog steeds de onbetwiste leider is op het gebied van computerchips. Deepseek maakt bijvoorbeeld ook gebruik van NVIDIA-infrastructuur. De aandelenkoers herstelde zich dinsdag dan ook al deels met een stijging van 9%. Kan Deepseek de macht van de Amerikaanse Big Tech-bedrijven inperken? De markt voor de grote ‘foundation’-modellen is opengebroken nu het mogelijk is om zeer capabele modellen te ontwikkelen met beperkte middelen. De enorme investeringen die voorheen noodzakelijk leken, waren slechts voor een kleine groep weggelegd. Nu blijkt dat dit kan voor een fractie van de kosten, waardoor er plotseling veel meer potentiële spelers zijn. Deze Chinese doorbraak in de mondiale AI-race zou ook Europese organisaties kunnen helpen om hun eigen modellen te ontwikkelen.]]></summary></entry><entry><title type="html">Sociale media voor jongeren</title><link href="https://wimcasteels.github.io/blog/2025/social-media/" rel="alternate" type="text/html" title="Sociale media voor jongeren"/><published>2025-01-26T12:00:00+00:00</published><updated>2025-01-26T12:00:00+00:00</updated><id>https://wimcasteels.github.io/blog/2025/social-media</id><content type="html" xml:base="https://wimcasteels.github.io/blog/2025/social-media/"><![CDATA[<div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/250126.webp" sizes="95vw"/> <img src="/assets/img/250126.webp" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <p>Ik verslikte me dit weekend in mijn koffie toen de nieuwe Vlaamse minister van Media op Radio één haar visie deelde over het gebruik van sociale media door kinderen. Ze vergeleek het met leren fietsen waarbij je start met zijwieltjes. Alsof het gebruik van sociale media niet veel verschilt van een fietstochtje. Ze geeft aan dat volgens haar ouders op zoek zijn naar tools om hun kinderen weerbaar te maken en verwijst hiervoor naar <a href="http://mediawijs.be">mediawijs.be</a>. Dit soort vergelijkingen riskeert de nadelige gevolgen van sociale media te minimaliseren. Als voorbeeld geeft ze nog aan dat ouders willen weten hoe een algoritme werkt. Ik zou de minister graag eens horen uitleggen hoe de algoritmes achter sociale media werken. Sterker nog, ik betwijfel of je bij de sociale mediabedrijven iemand kan vinden die deze kan uitleggen.</p> <p>Wat wel uitgebreid gedocumenteerd is zijn de effecten van deze algoritmes. Voor de platformen zelf gaat het dan vooral om de enorme winsten. De algoritmes lokken zoveel mogelijk mensen naar het platform en tonen hen precies die berichten die de kans maximaliseren dat ze op advertenties klikken. Dit levert inkomsten op van de adverteerders. Veel inkomsten. Sociale media bedrijven verdienen hier jaarlijks tientallen miljarden aan. Dat deze algoritmes menselijke zwakheden zoals verslaving uitbuiten wordt gezien als bijzaak.</p> <p>Ook de maatschappelijke effecten zijn goed gedocumenteerd. Neem bijvoorbeeld Meta, het moederbedrijf van Facebook en Instagram. Een rapport van Amnesty International documenteert uitgebreid de rol van Facebook in de genocide tegen de Rohingya in Myanmar. In 2017 werden duizenden Rohingya gedood, gemarteld, verkracht en verdreven tijdens een etnische zuiveringscampagne. In de aanloop naar deze gruweldaden versterkten Facebook’s algoritmes een golf van haat tegen de Rohingya, wat bijdroeg aan geweld in de echte wereld. Meta’s algoritmes hadden namelijk geleerd dat het promoten van haatdragende inhoud gebruikers langer op het platform hield dan feitelijke content. Hoewel Facebook de anti-Rohingya sentimenten niet heeft gecreëerd, heeft het platform deze wel aangewakkerd voor eigen financieel gewin.</p> <p>The Facebook Files, een onderzoek van interne Facebook documenten door The Wall Street Journal, toont aan dat het platform vol schadelijke mechanismes zit. Zo blijkt bijvoorbeeld dat 12,5% van de gebruikers vindt dat de app hun slaap, relaties of ouderschap negatief beïnvloedt. Het onderzoek onthult ook wat Facebook wist over de negatieve gevolgen voor jongeren en hoe ze deze in het openbaar bagatelliseren. Een interne presentatie vermeldde bijvoorbeeld dat 32% van de tienermeisjes aangaf dat Instagram hun negatieve zelfbeeld over hun lichaam verder versterkte. Ondertussen presenteerde de CEO Mark Zuckerberg publiekelijk enkel de positieve effecten die sociale apps kunnen hebben op de mentale gezondheid.</p> <p>Robert Califf, het hoofd van de Amerikaanse Food and Drug Administration (FDA), stelt dat volgens hem misinformatie (onjuiste of misleidende informatie) de belangrijkste doodsoorzaak is in de VS. Als voorbeelden noemt hij mensen die twijfelen over vaccinatie tijdens de COVID-19-pandemie en de verspreiding van vapen. Onderzoek toont bovendien aan dat sociale media een ideale voedingsbodem is voor misinformatie, die zich sneller, gemakkelijker en breder verspreidt dan feitelijk correcte berichten.</p> <p>Onderzoek van de Wereld Gezondheidsorganisatie toonde aan dat het aantal jongeren dat problematisch gebruik ervaart van sociale media is gestegen tot 11% (Vlaanderen doet het iets beter met 9%). Problematisch gebruik wordt hierbij gedefinieerd als het vertonen van minstens 6 van de 9 problematische factoren, zoals zich slecht voelen wanneer sociale media niet beschikbaar zijn of ernstige conflicten hebben met familieleden door het gebruik van sociale media.</p> <p>Sociale media hebben zeker voordelen, zoals het verbinden van mensen. Toch is voorzichtigheid geboden, vooral bij jongeren die zich in een kwetsbare levensfase bevinden en voor wie sociale media een steeds grotere rol spelen. Deze jongeren zitten in een periode waarin ze ouderlijke sturing vaak afwijzen. De situatie in Vlaanderen is weliswaar niet te vergelijken met die in Myanmar of de VS, maar deze voorbeelden tonen wel aan welke impact deze platformen kunnen hebben. Een uitgebreid maatschappelijk debat is dan ook noodzakelijk, en vergelijkingen met fietsen dragen hier niet constructief aan bij. Hoewel tools op een overheidswebsite als <a href="http://Mediawijs.be">Mediawijs.be</a> zeker waardevol zijn, betwijfel ik of ze toereikend zijn om onze jongeren te beschermen tegen de schadelijke gevolgen van sociale media.</p>]]></content><author><name></name></author><category term="sociale-media"/><summary type="html"><![CDATA[Ik verslikte me dit weekend in mijn koffie toen de nieuwe Vlaamse minister van Media op Radio één haar visie deelde over het gebruik van sociale media door kinderen. Ze vergeleek het met leren fietsen waarbij je start met zijwieltjes. Alsof het gebruik van sociale media niet veel verschilt van een fietstochtje. Ze geeft aan dat volgens haar ouders op zoek zijn naar tools om hun kinderen weerbaar te maken en verwijst hiervoor naar mediawijs.be. Dit soort vergelijkingen riskeert de nadelige gevolgen van sociale media te minimaliseren. Als voorbeeld geeft ze nog aan dat ouders willen weten hoe een algoritme werkt. Ik zou de minister graag eens horen uitleggen hoe de algoritmes achter sociale media werken. Sterker nog, ik betwijfel of je bij de sociale mediabedrijven iemand kan vinden die deze kan uitleggen. Wat wel uitgebreid gedocumenteerd is zijn de effecten van deze algoritmes. Voor de platformen zelf gaat het dan vooral om de enorme winsten. De algoritmes lokken zoveel mogelijk mensen naar het platform en tonen hen precies die berichten die de kans maximaliseren dat ze op advertenties klikken. Dit levert inkomsten op van de adverteerders. Veel inkomsten. Sociale media bedrijven verdienen hier jaarlijks tientallen miljarden aan. Dat deze algoritmes menselijke zwakheden zoals verslaving uitbuiten wordt gezien als bijzaak. Ook de maatschappelijke effecten zijn goed gedocumenteerd. Neem bijvoorbeeld Meta, het moederbedrijf van Facebook en Instagram. Een rapport van Amnesty International documenteert uitgebreid de rol van Facebook in de genocide tegen de Rohingya in Myanmar. In 2017 werden duizenden Rohingya gedood, gemarteld, verkracht en verdreven tijdens een etnische zuiveringscampagne. In de aanloop naar deze gruweldaden versterkten Facebook’s algoritmes een golf van haat tegen de Rohingya, wat bijdroeg aan geweld in de echte wereld. Meta’s algoritmes hadden namelijk geleerd dat het promoten van haatdragende inhoud gebruikers langer op het platform hield dan feitelijke content. Hoewel Facebook de anti-Rohingya sentimenten niet heeft gecreëerd, heeft het platform deze wel aangewakkerd voor eigen financieel gewin. The Facebook Files, een onderzoek van interne Facebook documenten door The Wall Street Journal, toont aan dat het platform vol schadelijke mechanismes zit. Zo blijkt bijvoorbeeld dat 12,5% van de gebruikers vindt dat de app hun slaap, relaties of ouderschap negatief beïnvloedt. Het onderzoek onthult ook wat Facebook wist over de negatieve gevolgen voor jongeren en hoe ze deze in het openbaar bagatelliseren. Een interne presentatie vermeldde bijvoorbeeld dat 32% van de tienermeisjes aangaf dat Instagram hun negatieve zelfbeeld over hun lichaam verder versterkte. Ondertussen presenteerde de CEO Mark Zuckerberg publiekelijk enkel de positieve effecten die sociale apps kunnen hebben op de mentale gezondheid. Robert Califf, het hoofd van de Amerikaanse Food and Drug Administration (FDA), stelt dat volgens hem misinformatie (onjuiste of misleidende informatie) de belangrijkste doodsoorzaak is in de VS. Als voorbeelden noemt hij mensen die twijfelen over vaccinatie tijdens de COVID-19-pandemie en de verspreiding van vapen. Onderzoek toont bovendien aan dat sociale media een ideale voedingsbodem is voor misinformatie, die zich sneller, gemakkelijker en breder verspreidt dan feitelijk correcte berichten. Onderzoek van de Wereld Gezondheidsorganisatie toonde aan dat het aantal jongeren dat problematisch gebruik ervaart van sociale media is gestegen tot 11% (Vlaanderen doet het iets beter met 9%). Problematisch gebruik wordt hierbij gedefinieerd als het vertonen van minstens 6 van de 9 problematische factoren, zoals zich slecht voelen wanneer sociale media niet beschikbaar zijn of ernstige conflicten hebben met familieleden door het gebruik van sociale media. Sociale media hebben zeker voordelen, zoals het verbinden van mensen. Toch is voorzichtigheid geboden, vooral bij jongeren die zich in een kwetsbare levensfase bevinden en voor wie sociale media een steeds grotere rol spelen. Deze jongeren zitten in een periode waarin ze ouderlijke sturing vaak afwijzen. De situatie in Vlaanderen is weliswaar niet te vergelijken met die in Myanmar of de VS, maar deze voorbeelden tonen wel aan welke impact deze platformen kunnen hebben. Een uitgebreid maatschappelijk debat is dan ook noodzakelijk, en vergelijkingen met fietsen dragen hier niet constructief aan bij. Hoewel tools op een overheidswebsite als Mediawijs.be zeker waardevol zijn, betwijfel ik of ze toereikend zijn om onze jongeren te beschermen tegen de schadelijke gevolgen van sociale media.]]></summary></entry></feed>