<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="nl"><generator uri="https://jekyllrb.com/" version="4.3.4">Jekyll</generator><link href="https://wimcasteels.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://wimcasteels.github.io/" rel="alternate" type="text/html" hreflang="nl"/><updated>2025-02-18T10:52:11+00:00</updated><id>https://wimcasteels.github.io/feed.xml</id><title type="html">blank</title><subtitle>A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. </subtitle><entry><title type="html">Wie ligt er nog wakker van de veiligheid van AI?</title><link href="https://wimcasteels.github.io/blog/2025/AI-Veiligheid/" rel="alternate" type="text/html" title="Wie ligt er nog wakker van de veiligheid van AI?"/><published>2025-02-17T00:00:00+00:00</published><updated>2025-02-17T00:00:00+00:00</updated><id>https://wimcasteels.github.io/blog/2025/AI-Veiligheid</id><content type="html" xml:base="https://wimcasteels.github.io/blog/2025/AI-Veiligheid/"><![CDATA[<div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/250218.webp" sizes="95vw"/> <img src="/assets/img/250218.webp" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <p>De lancering van ChatGPT eind 2022 zond een schokgolf door de wereld. Nog nooit bereikte een digitaal hulpmiddel zo snel 100 miljoen gebruikers (in <a href="https://www.theguardian.com/technology/2023/feb/02/chatgpt-100-million-users-open-ai-fastest-growing-app">slechts 2 maanden</a>). Een aanzienlijk deel van de wereldbevolking maakte zo kennis met AI en zijn mogelijkheden. Deze technologie wekte echter ook bezorgdheid op over de veiligheid. De exponentiële vooruitgang riep vragen op over waar dit zou eindigen en of de gevolgen wel positief zouden zijn voor de mensheid. Zorgen ontstonden over de verspreiding van nepnieuws, mogelijke ontwrichting van de arbeidsmarkt en het potentiële verlies van controle over AI-systemen.</p> <p>Het existentiële risico van AI, dat de ontwikkeling ervan zou kunnen leiden tot een humanitaire ramp, spreekt tot de verbeelding. Dit wordt in vaktermen aangeduid als p(doom): de kans dat AI leidt tot een existentiële catastrofe. Uit een <a href="https://wiki.aiimpacts.org/ai_timelines/predictions_of_human-level_ai_timelines/ai_timeline_surveys/2023_expert_survey_on_progress_in_ai">bevraging uit 2023 bij AI-onderzoekers</a> bleek dat ongeveer de helft deze kans hoger inschat dan 10%. De Israëlische historicus Yuval Harari maakte hierover een treffende <a href="https://www.nytimes.com/2023/03/24/opinion/yuval-harari-ai-chatgpt.html">vergelijking met een vliegreis</a>: als de helft van de vliegtuigingenieurs je vertelt dat er 10 procent kans is dat het toestel neerstort, zou je dan instappen? Deze bezorgdheden leidden tot concrete actie. Een <a href="https://futureoflife.org/open-letter/pause-giant-ai-experiments/">open brief</a>, ondertekend door meer dan 30.000 mensen, riep op tot een pauze in de ontwikkeling van grootschalige AI-systemen tot de risico’s beter in kaart zijn gebracht. Ook Sam Altman, CEO van OpenAI (de organisatie achter ChatGPT), <a href="https://www.wired.com/story/sam-altman-world-tour-ai-doomers/">reisde in 2023 de wereld rond</a> om politieke leiders te waarschuwen voor deze gevaren. Al werd dit door velen als een PR-stunt gezien.</p> <p>Het Verenigd Koninkrijk nam onder toenmalig premier Rishi Sunak het initiatief om wereldleiders en vertegenwoordigers uit de industrie samen te brengen tijdens de <a href="https://www.gov.uk/government/topical-events/ai-safety-summit-2023">AI Safety Summit</a>. Deze vond plaats in het symbolische Bletchley Park, waar tijdens de Tweede Wereldoorlog de Duitse code werd gekraakt. De 28 aanwezige landen ondertekenden de <a href="https://www.gov.uk/government/publications/ai-safety-summit-2023-the-bletchley-declaration/the-bletchley-declaration-by-countries-attending-the-ai-safety-summit-1-2-november-2023">Bletchley-verklaring</a>, waarin werd vastgelegd dat AI op een veilige manier moet worden ontworpen, ontwikkeld, ingezet en gebruikt, waarbij de mens centraal staat en betrouwbaarheid en verantwoordelijkheid voorop staan.</p> <p>Verschillende vooraanstaande wetenschappers spraken zich uit over de risico’s van AI, waaronder Geoffrey Hinton en Yoshua Bengio, twee van de drie zogenaamde ‘AI-pioniers’ die in 2018 de <a href="https://awards.acm.org/about/2018-turing">Turing Award</a> wonnen voor hun werk over AI en deep learning. Hinton, die in 2024 nog de Nobelprijs voor natuurkunde ontving, <a href="https://www.theguardian.com/technology/2023/may/02/geoffrey-hinton-godfather-of-ai-quits-google-warns-dangers-of-machine-learning">vertrok bij Google</a> om zich vrij te kunnen uitspreken over de risico’s. Yoshua Bengio werd na de AI Safety top aangesteld door de Britse regering als voorzitter van een wetenschappelijke raad over het thema. Met meer dan 100 wetenschappers uit 30 landen publiceerde hij in januari het <a href="https://www.gov.uk/government/publications/international-ai-safety-report-2025">AI Safety rapport</a>, een document van bijna 300 pagina’s dat uitgebreid ingaat op de risico’s van AI. De derde AI-pionier, Yann LeCun, houdt er als senior wetenschapper bij Meta een <a href="https://www.wsj.com/tech/ai/yann-lecun-ai-meta-aa59e2f5">andere mening</a> op na en denkt dat de nadruk op de existentiële risico’s naast de kwestie zijn.</p> <p>De tweede editie van de AI Safety top vond plaats in Seoul in mei 2024 en resulteerde in een belofte van 27 landen om werk rond ernstige AI-risico’s te verdiepen. Op de derde editie in Parijs vorige week, onder de naam <a href="https://www.elysee.fr/en/sommet-pour-l-action-sur-l-ia">AI Action top</a>, was het oorspronkelijke thema van AI-veiligheid echter vrijwel afwezig. In plaats daarvan lag de nadruk op innovatie. Emmanuel Macron, de president van gastland Frankrijk, opende de top met de aankondiging van Franse AI-investeringen en benadrukte dat Europa en Frankrijk nog volop meedoen in de wereldwijde AI-race. <a href="https://www.euractiv.com/section/tech/news/von-der-leyen-launches-worlds-largest-public-private-partnership-to-win-ai-race/">Ursula von der Leyen</a>, voorzitter van de Europese Commissie<strong>,</strong> sloot zich hierbij aan met Europese investeringsbeloften en de boodschap dat de AI-race nog niet voorbij is. De Amerikaanse vicepresident JD Vance ging nog een stap verder met een pleidooi tegen regulering, waarbij hij waarschuwde dat deze de industrie zou kunnen verstikken. Hoewel de voorzitter van de wetenschappelijke raad Bengio wel in Parijs aanwezig was, sprak hij niet op de hoofdtop maar gaf hij een presentatie op een andere <a href="https://www.iaseai.org/conference">conferentie</a> over het veilig en ethisch gebruik van AI. Opmerkelijk genoeg toonde <a href="https://www.reuters.com/technology/artificial-intelligence/china-is-willing-share-achievements-ai-vice-premier-says-paris-summit-2025-02-11/">China</a>, het land dat vaak wordt gezien als de tegenstander op AI-gebied, de meeste bereidheid tot samenwerking rond veiligheid. Het land gaf aan vorderingen in AI te willen delen om “een gemeenschap met een gedeelde toekomst voor de mensheid” op te bouwen.</p> <p>De VS en het VK <a href="https://www.theguardian.com/technology/2025/feb/11/us-uk-paris-ai-summit-artificial-intelligence-declaration">weigerden</a> de slotverklaring van de Parijse top over ‘inclusieve en duurzame’ AI te ondertekenen. De Amerikaanse vicepresident vertrok zelfs voor het traditionele fotomoment. Kort daarna werd bekend dat het Britse ‘AI Safety Institute’ van <a href="https://www.gov.uk/government/news/tackling-ai-security-risks-to-unleash-growth-and-deliver-plan-for-change">naam verandert</a> naar het ‘AI Security Institute’. Deze naamswijziging weerspiegelt een verschuiving van de focus van existentiële doemscenario’s naar de nationale veiligheidsrisico’s van AI, zoals cyberaanvallen en de productie van chemische of biologische wapens. Dit sluit aan bij de Britse plannen om meer <a href="https://committees.parliament.uk/committee/24/defence-committee/news/204613/defence-committee-mod-must-learn-from-ukraine-and-embrace-ai/">gebruik te maken van AI</a> binnen defensie.</p> <p>In dezelfde week als de top in Parijs <a href="https://www.reuters.com/technology/eu-ditches-plans-regulate-tech-patents-ai-liability-online-privacy-2025-02-12/">schrapte</a> de Europese Commissie de AI-aansprakelijkheidsrichtlijn uit 2022. Deze richtlijn zou consumenten het recht hebben gegeven om schadevergoeding te eisen wanneer ze schade leden door fouten of nalatigheid van AI-aanbieders, -ontwikkelaars of -gebruikers.</p> <p>Het pleidooi van JD Vance’s in Parijs weerspiegelde Donald Trumps visie op AI. Deze richt zich op het positioneren van de VS als wereldleider in AI-ontwikkeling via deregulering, investeringen en innovatie. Tijdens het Wereld Economisch Forum in Davos begin dit jaar verklaarde Trump dat hij van de VS de “<a href="https://www.businesstoday.in/wef-2025/story/trump-outlines-ambitious-vision-for-us-leadership-in-ai-and-cryptocurrency-at-davos-461898-2025-01-24">globale hoofdstad van artificiële intelligentie</a>” wil maken. In lijn met deze visie trok hij een presidentieel besluit van Joe Biden in dat gericht was op het beperken van AI-risico’s voor consumenten, werknemers en de nationale veiligheid. Geruggesteund door deze visie van Trump <a href="https://www.politico.eu/article/google-eu-rules-advanced-ai-artificial-intelligence-step-in-wrong-direction/">bekritiseren</a> de grote technologiebedrijven Meta en Google de Europese AI regulaties als een stap in de verkeerde richting.</p> <p>De zorgen over AI zijn niet verdwenen omdat men de technologie zou onderschatten. Integendeel: tijdens de top in Parijs waarschuwde Dario Amodei, CEO van Anthropic (bekend van chatbot Claude), dat AI-systemen <a href="https://www.anthropic.com/news/paris-ai-summit">tegen 2026</a> mogelijk even krachtig zouden kunnen zijn als een ‘nieuwe natie vol genieën’, met verstrekkende gevolgen voor economie, maatschappij en veiligheid. In een <a href="https://www.bloomberg.com/features/2025-sam-altman-interview/">recent interview</a> voorspelde Sam Altman dat AGI, een AI-systeem dat menselijke intelligentie evenaart, nog tijdens Trumps ambtstermijn gerealiseerd zal worden.</p> <p>Ondertussen pieken de investeringen in het inzetten van AI voor defensie. Bedrijven zoals het controversiële AI-defensiebedrijf Palantir, de beurslieveling die zijn marktwaarde sinds de verkiezing van Trump al met meer dan 180% zag stijgen, hebben de voorbije jaren contracten voor miljarden dollars binnengehaald van de Amerikaanse overheid om de grenzen te bewaken. De CEO, <a href="https://www.wsj.com/tech/who-is-alex-karp-palantir-ceo-dcd66e21">Alex Karp</a>, schreef recent een boek waarin hij pleit dat technologiebedrijven de democratische waarden van het Westen moeten verdedigen. Hij klopt zichzelf op de schouder dat de software van Palantir Amerika dodelijker maakt. Tegelijkertijd heeft OpenAI zijn modellen aangepast en beveiligingen verwijderd om minder te censureren en “<a href="https://techcrunch.com/2025/02/16/openai-tries-to-uncensor-chatgpt/">intellectuele vrijheid meer te omarmen</a>”. Dit betekent dat onderwerpen die tot voor kort werden geweigerd of waar een waarschuwing bij stond, zoals “Black Lives Matter”, nu vrijelijk besproken kunnen worden. Bij verschillende sociale mediabedrijven zoals Meta en X worden veiligheidsteams ontmanteld, wat leidt tot meer tolerantie voor controversiële content.</p> <p>De aandacht voor AI-veiligheid is na de initiële bezorgdheid rond ChatGPT sterk afgenomen. Internationale toppen, oorspronkelijk bedoeld voor veiligheidsdiscussies, zijn verworden tot platforms waar landen vooral hun AI-investeringen en -ambities etaleren. Terwijl de VS onder Trump en de EU onder Von der Leyen inzetten op deregulering en onderlinge competitie, toont China, ironisch genoeg, de meeste bereidheid tot internationale samenwerking op het gebied van veiligheid. Grote technologiebedrijven ontmantelen ondertussen hun veiligheidsteams en verwijderen beveiligingen, terwijl de investeringen in militaire AI-toepassingen een hoogtepunt bereiken. We kunnen alleen maar hopen dat een superintelligente computer niet te snel verschijnt, of op zijn minst menslievend van aard zal zijn.</p>]]></content><author><name></name></author><category term="AI-Veiligheid"/><category term="Europa"/><category term="US"/><summary type="html"><![CDATA[Na de komst van ChatGPT stond AI veiligheid hoog op de (politieke) agenda maar dat lijkt met de AI Action top in Parijs vorige week definitief verleden tijd.]]></summary></entry><entry><title type="html">Eerste stap van de AI Act. Binnenkort allemaal AI geletterd?</title><link href="https://wimcasteels.github.io/blog/2025/AI-Act-stap-1/" rel="alternate" type="text/html" title="Eerste stap van de AI Act. Binnenkort allemaal AI geletterd?"/><published>2025-02-13T00:00:00+00:00</published><updated>2025-02-13T00:00:00+00:00</updated><id>https://wimcasteels.github.io/blog/2025/AI-Act-stap-1</id><content type="html" xml:base="https://wimcasteels.github.io/blog/2025/AI-Act-stap-1/"><![CDATA[<div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/250214.webp" sizes="95vw"/> <img src="/assets/img/250214.webp" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <p>De AI Act reguleert de ontwikkeling en het gebruik van AI binnen de Europese Unie, en geldt ook voor buitenlandse bedrijven die hun producten aan Europeanen aanbieden. De wet heeft een tweeledig doel: enerzijds het bevorderen van veilige en betrouwbare AI-systemen die de fundamentele rechten van EU-burgers respecteren, anderzijds het stimuleren van AI-investeringen en innovatie in Europa. De sancties bij overtreding zijn aanzienlijk: tot 35 miljoen euro of 7% van de jaarlijkse bedrijfsomzet. De AI Act, die op 1 augustus 2024 in werking trad, wordt stapsgewijs ingevoerd. Sinds 2 februari zijn AI-systemen met onacceptabel risico verboden en gelden er verplichtingen rond AI-geletterdheid.</p> <p>De basis van de wet is een indeling van AI-toepassingen in risicoklassen (zie figuur): van onacceptabel (en dus verboden) tot minimaal risico. Systemen in de categorie ‘hoog risico’ moeten voldoen aan strikte verplichtingen, waaronder risicobeoordeling en mitigatie strategieën.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/250214-1-480.webp 480w,/assets/img/250214-1-800.webp 800w,/assets/img/250214-1-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/250214-1.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> De risicoklassen binnen de AI Act (bron: <a href="https://www.adalovelaceinstitute.org/resource/eu-ai-act-explainer/">Ada Lovelace Institute</a>) </div> <p>De risicoklassen in de AI Act zijn niet scherp afgebakend, waardoor er onduidelijkheid bestaat over de classificatie van veel systemen. Om dit te verduidelijken publiceerde de Europese Commissie op 4 februari, twee dagen na de start van het verbod op systemen in de hoogste risicoklasse, een <a href="https://digital-strategy.ec.europa.eu/en/library/commission-publishes-guidelines-prohibited-artificial-intelligence-ai-practices-defined-ai-act">document met richtlijnen</a>. Deze niet-bindende richtlijnen bevatten praktische voorbeelden en toelichtingen voor de interpretatie en naleving van de AI Act. Zo zijn sociale scoringsalgoritmes in het algemeen verboden, maar mogen financiële instellingen wel AI gebruiken om de kredietwaardigheid van klanten te beoordelen. Op 6 februari volgde nog een aanvullende <a href="https://digital-strategy.ec.europa.eu/en/library/commission-publishes-guidelines-ai-system-definition-facilitate-first-ai-acts-rules-application">richtlijn</a> over de definitie van AI en wat er binnen de AI Act onder een AI-systeem valt. Deze tekst stelt vast dat er geen sluitende classificatie of volledige lijst kan worden opgesteld van systemen die wel of niet onder de definitie vallen.</p> <p>De systemen in de hoogste risicoklasse zijn sinds 2 februari in principe verboden, maar de handhaving en sancties van de AI Act treden pas in werking vanaf 2 augustus 2025. Tot die datum blijft het verbod dus zonder actieve handhaving. Er heerst nog veel onduidelijkheid over de implementatie van deze handhaving. Lidstaten moesten voor 2 november 2024 hun nationale bevoegde instanties aanwijzen. Op die deadline hadden slechts <a href="https://artificialintelligenceact.eu/national-implementation-plans/">7 van de 27 lidstaten</a> dit gedaan, en <a href="https://digital-strategy.ec.europa.eu/en/policies/ai-act-governance-and-enforcement">op het moment dat deze post verschijnt</a> zijn er nog steeds 6 lidstaten die in gebreke blijven, waaronder, je raadt het al, België.</p> <p>De AI Act wordt wereldwijd gezien als een van de meest vooruitstrevende AI-wetgevingen, maar de totstandkoming verliep moeizaam. Het proces begon in april 2021 met een eerste <a href="https://digital-strategy.ec.europa.eu/en/library/proposal-regulation-laying-down-harmonised-rules-artificial-intelligence">voorstel van de Europese Commissie</a> en duurde tot eind 2023 voordat de finale tekst werd goedgekeurd. Een belangrijke complicerende factor was de introductie van ChatGPT tijdens het wetgevingsproces. Deze ontwikkeling leidde ertoe dat plotseling veel meer mensen AI gingen gebruiken. De snelle evolutie van de onderliggende taalmodellen, die steeds krachtiger werden, bracht nieuwe risico’s met zich mee die niet in het originele voorstel waren meegenomen. Deze systemen werden uiteindelijk in 2023 in de wetgeving opgenomen onder de bredere term ‘general-purpose AI<em>’</em> (GPAI) modellen.</p> <p>De ontwikkeling van deze GPAI-modellen vereist enorme investeringen. Dit leidde bij de introductie in de AI Act tot intensieve lobbyactiviteiten vanuit de industrie. Het <a href="https://digital-strategy.ec.europa.eu/en/policies/regulatory-framework-ai">Byte to Byte</a> rapport van Corporate Europe Observatory toont aan dat grote technologiebedrijven buitenproportioneel veel toegang hadden tot Europese beleidsmakers in vergelijking met andere belanghebbenden (zie ook figuur). Een sprekend voorbeeld: Google’s CEO Sundar Pichai wist op één dag gesprekken te voeren met drie verschillende Europese commissarissen.</p> <p align="center"><iframe aria-label="Bar chart" data-external="1" frameborder="0" height="205" id="datawrapper-chart-0CcqX" scrolling="no" src="https://datawrapper.dwcdn.net/0CcqX/1/" style="border: none;" title="Top 5 lobbyists on the AI Act in 2023" width="600"></iframe></p> <p>Het lobbywerk tegen de AI Act was succesvol en zwakte de wetgeving aanzienlijk af, maar het was uiteindelijk de <a href="https://corporateeurope.org/en/2024/03/trojan-horses-how-european-startups-teamed-big-tech-gut-ai-act">weerstand vanuit Europa</a> zelf die de doorslag gaf. De Franse startup Mistral AI en de Duitse startup Aleph Alpha vonden gehoor bij hun respectievelijke regeringen. Een Frans-Duits-Italiaans front zorgde er vervolgens voor dat bindende maatregelen uit de AI Act verdwenen en werden vervangen door transparantievereisten. De strengste regels gelden voor <a href="https://artificialintelligenceact.eu/article/51/">GPAI-systemen met een systemisch risico</a>. De enige concrete definitie hiervoor betreft modellen waarvoor bij de ontwikkeling meer dan 10^24 FLOPS aan computerberekeningen nodig waren, een enorme hoeveelheid waar momenteel wereldwijd alleen GPT-4 van OpenAI onder valt. Deze grens lijkt al helemaal achterhaald sinds het <a href="https://www.technologyreview.com/2025/01/24/1110526/china-deepseek-top-ai-despite-sanctions/">Chinese Deepseek</a> aantoonde dat er veel minder computerkracht nodig is voor deze modellen. Hoewel modellen met grote maatschappelijke impact ook onder deze categorie met systemisch risico vallen, blijft vooralsnog onduidelijk hoe dit precies wordt bepaald.</p> <p>Tijdens de <a href="https://www.elysee.fr/en/sommet-pour-l-action-sur-l-ia">AI Action top</a> in Parijs eerder deze week leken sommige Europese leiders gemengde gevoelens te hebben over de AI Act. De Franse president <a href="https://www.nytimes.com/2025/02/10/business/ai-summit-paris.html">Macron</a> benadrukte het belang van innovatie en waarschuwde dat regulering deze kan belemmeren. Hij verklaarde dat Europa nog steeds meedoet in de ‘AI race’ en kondigde <a href="https://www.cnbc.com/2025/02/10/frances-answer-to-stargate-macron-announces-ai-investment.html">Franse investeringen</a> aan ter waarde van 109 miljard euro. <a href="https://www.euractiv.com/section/tech/news/von-der-leyen-launches-worlds-largest-public-private-partnership-to-win-ai-race/">Ursula Von der Leyen</a>, de voorzitter van de Europese Commissie<strong>,</strong> bevestigde dat de AI race nog niet voorbij is en lanceerde InvestAI, een publiek-private samenwerking ter waarde van 200 miljard euro. De Amerikaanse vicepresident <a href="https://www.reuters.com/technology/artificial-intelligence/europe-looks-embrace-ai-paris-summits-2nd-day-while-global-consensus-unclear-2025-02-11/">JD Vance</a> verzette zich nadrukkelijk tegen regulering en stelde dat de Europese wetgeving de technologie ‘wurgt’. De slotverklaring van de top in Parijs over ‘inclusieve en duurzame AI’ werd niet ondertekend door de VS en het VK, waardoor de top algemeen als een gemiste kans wordt beschouwd.</p> <p>Op 2 februari trad ook het artikel over AI-geletterdheid in de AI Act in werking. De originele versie was hier een <a href="https://www.law.kuleuven.be/citip/blog/this-time-humans-learn-about-machines-ai-literacy-in-the-ai-act-part-1/">stuk ambitieuzer</a>: deze verplichtte zowel lidstaten als bedrijven om AI-geletterdheid in alle sectoren van de samenleving te bevorderen. In het <a href="https://artificialintelligenceact.eu/article/4/">finale artikel</a> zijn de lidstaten echter geschrapt en richt de wet zich alleen op AI-bedrijven. Zij moeten ervoor zorgen dat hun personeel en andere betrokkenen een ‘voldoende niveau’ van AI-geletterdheid bereiken. Dit niveau hangt af van de context, zoals de risicoklasse van het AI-systeem, maar wat precies als ‘voldoende’ wordt beschouwd en hoe dit zal worden gehandhaafd, blijft voorlopig onduidelijk.</p> <p>De <a href="https://artificialintelligenceact.eu/article/3/">definitie van AI-geletterdheid</a> in de AI Act reikt verder dan alleen bedrijven en deze vermeld dat ook personen die door AI-systemen worden beïnvloed, moeten beschikken over AI-geletterdheid. In de definitie wordt bij AI geletterdheid onder andere verstaan dat men bewust is van de mogelijkheden, risico’s en potentiële schade van AI. Dit stuk gaat veel breder dan enkel de werknemers van AI bedrijven. Een aanvullende bepaling (<a href="https://artificialintelligenceact.eu/recital/20/"><em>Recital 20</em></a>) benadrukt het belang van een brede implementatie van AI-geletterdheid en de rol van de <a href="https://digital-strategy.ec.europa.eu/en/policies/ai-board">Europese AI Raad</a> hierin. We kunnen dus verwachten dat Europa nog meer initiatieven zal lanceren rond AI-geletterdheid. De Vlaamse AI Academy (VAIA) voorziet alvast enkele <a href="https://www.vaia.be/nl/blog/ai-literacy-eu-ai-act-artikel-4">tips</a> om te werken aan AI geletterdheid.</p> <p>De AI Act is vooruitstrevend en behandelt belangrijke maatschappelijke uitdagingen van AI (hoewel bijvoorbeeld de ecologische voetafdruk buiten beschouwing blijft). De implementatie blijkt echter complex. De wet beoogt innovatie te stimuleren, maar de industrie toonde zich hierover sceptisch. Door krachtige tegenstand is de wetgeving significant afgezwakt. Er zijn nog diverse obstakels te overwinnen, waarbij veel zal afhangen van de uiteindelijke interpretatie en handhaving, aspecten die momenteel nog onduidelijk zijn.</p>]]></content><author><name></name></author><category term="AI-Act"/><category term="Europa"/><summary type="html"><![CDATA[Begin februari trad de eerste fase van de AI Act in werking. Deze Europese wetgeving verbiedt AI-systemen met een onacceptabel risico en stelt verplichtingen over AI-geletterdheid.]]></summary></entry><entry><title type="html">Maakt AI ons dommer?</title><link href="https://wimcasteels.github.io/blog/2025/dommer/" rel="alternate" type="text/html" title="Maakt AI ons dommer?"/><published>2025-02-05T12:00:00+00:00</published><updated>2025-02-05T12:00:00+00:00</updated><id>https://wimcasteels.github.io/blog/2025/dommer</id><content type="html" xml:base="https://wimcasteels.github.io/blog/2025/dommer/"><![CDATA[<div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/250205.webp" sizes="95vw"/> <img src="/assets/img/250205.webp" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <p>Een vaak gehoord cliché over de impact van AI op de arbeidsmarkt is dat niet AI je baan zal afnemen, maar iemand die AI wél gebruikt. Deze uitspraak verwijst naar de efficiëntiewinst die je met AI-tools kunt behalen, waardoor je meer werk verzet en waardevoller wordt voor je werkgever. Dat AI een grondige impact zal hebben op de arbeidsmarkt staat vast, al lopen de voorspellingen soms wild uiteen. Zo voorspelt <a href="https://www.cognizant.com/en_us/insights/documents/new-work-new-world-with-generative-ai-wf2064768.pdf">een studie</a> dat in de komende 10 jaar 90% van de jobs verstoord zullen worden door AI. Het <a href="https://www.imf.org/en/Blogs/Articles/2024/01/14/ai-will-transform-the-global-economy-lets-make-sure-it-benefits-humanity">IMF</a> houdt het bij dat wereldwijd 40% van de banen door AI geïmpacteerd zullen worden. Waar de industriële revolutie vooral effect had op arbeiders, zal AI eerder de kenniseconomie beïnvloeden. Het IMF voorspelt dan ook dat het effect veel groter zal zijn in geavanceerde economieën ten opzichte van lageloonlanden.</p> <p>Er is steeds meer bewijs dat AI de efficiëntie aanzienlijk verhoogt. Uit een <a href="https://www.adeccogroup.com/our-group/media/press-releases/ai-saves-workers-an-average-of-one-hour-each-day">bevraging</a> blijkt dat werknemers gemiddeld een uur per dag besparen door AI-gebruik. Wetenschappelijk onderzoek bevestigt deze trend. In een <a href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4573321">experiment</a> waarbij consultants 18 realistische taken moesten uitvoeren, presteerden degenen met toegang tot de GPT-4 AI-tool significant beter op zowel productiviteit als kwaliteit. De onderzoekers identificeerden twee succesvolle gebruikspatronen: de “Centauren” en de “Cyborgs”. De Centauren, vernoemd naar het mythische wezen dat half mens, half paard is, wisselden bewust af tussen eigen werk en AI-ondersteuning. De Cyborgs daarentegen integreerden AI volledig in hun werkproces en werkten continu samen met de technologie.</p> <p>Een <a href="https://www.upwork.com/research/ai-enhanced-work-models">enquête</a> toont aan dat dit enorme potentieel van AI ook nadelen heeft, zoals een verhoogde druk op werknemers om ermee te werken. Het onderzoek onthult een duidelijke kloof tussen de verwachtingen van werkgevers en werknemers. Waar 96% van de werkgevers gelooft dat AI-tools de productiviteit van hun bedrijf zullen verhogen, worstelen werknemers met de praktijk. Bijna de helft van de werknemers die AI gebruiken, weet niet hoe ze de verwachte productiviteitswinst kunnen behalen. Sterker nog, meer dan drie op de vier werknemers melden dat AI-tools hun productiviteit hebben verlaagd en hun werkdruk hebben verhoogd. Ze besteden bijvoorbeeld veel tijd aan het aanpassen van AI-gegenereerde content, terwijl het bedrijf tegelijkertijd hogere verwachtingen stelt.</p> <p>Deze productiviteitswinst is ook al uitgebreid waargenomen bij leerlingen. Een <a href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4895486">studie</a> met middelbare scholieren toonde aan dat toegang tot GPT-4 hun wiskundeprestaties aanzienlijk verbeterde. Wat echter opmerkelijk was dat wanneer deze toegang later werd weggenomen de leerlingen slechter presteerden dan degenen die nooit toegang hadden gehad. De conclusie was dat toegang tot GPT-4 schadelijk kan zijn voor onderwijsresultaten. De resultaten suggereren dat leerlingen GPT-4 gebruiken als een “kruk” tijdens het oefenen, waardoor ze uiteindelijk minder goed presteren wanneer ze op eigen kracht moeten werken.</p> <p>Een <a href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=5082524">recente studie</a> onderzocht hoe AI-tools zoals ChatGPT het kritisch denken en cognitieve vaardigheden beïnvloeden. Via een enquête werd onderzocht hoe mensen AI-tools gebruiken, hoe goed ze kritisch kunnen denken, en in welke mate ze digitale hulpmiddelen inzetten voor geheugen en probleemoplossing, ook wel cognitieve uitbesteding genoemd. De resultaten toonden aan dat mensen die vaak AI gebruiken minder goed kritisch denken, waarbij een toename in cognitieve uitbesteding een belangrijke verklarende factor was.</p> <p>Dit is niet de eerste keer dat er zorgen zijn over technologie die ons mogelijk dommer zou maken. In de <a href="https://www.washingtonpost.com/archive/local/1986/04/04/math-teachers-stage-a-calculated-protest/c003ddaf-b86f-4f2b-92ca-08533f3a5896/">jaren ‘70 en ‘80</a> vreesden docenten dat rekenmachines zouden leiden tot een afname van basale wiskundige vaardigheden. Nu pleit vrijwel niemand meer voor een verbod op rekenmachines. De smartphone is een vergelijkbaar voorbeeld. Ondanks de vele voordelen maken velen zich zorgen over de impact ervan op onze hersenen. Niet voor niets kreeg het Oxford woord van het jaar ‘<em>brain rot</em>’ (hersenslijtage) de meeste stemmen, een term die verwijst naar de mentale achteruitgang door het eindeloos consumeren van oppervlakkige en weinig stimulerende online inhoud. Mensen blijken ook minder geneigd te zijn om informatie te onthouden als ze weten dat deze online beschikbaar is, het zogenaamde <a href="https://en.wikipedia.org/wiki/Google_effect">Google-effect</a>. Een <a href="https://www.nature.com/articles/s41598-023-36256-4?utm_source=chatgpt.com">studie</a> laat zelfs zien dat alleen al de aanwezigheid van een smartphone leidt tot verminderde aandacht en concentratie. Hoewel smartphones ongetwijfeld gebruikt worden voor domme dingen, is de vraag of we er daadwerkelijk dommer van worden genuanceerder. Ondanks de vele suggesties in die richting bestaat hiervoor <a href="https://www.theguardian.com/lifeandstyle/2025/jan/29/all-in-the-mind-the-surprising-truth-about-brain-rot">geen wetenschappelijk bewijs</a>.</p> <p>De impact van AI op onze cognitieve vaardigheden is een complex vraagstuk zonder eenvoudig antwoord. De productiviteitswinsten door AI zijn weliswaar onmiskenbaar, maar eerste studies wijzen op mogelijke negatieve effecten op ons leervermogen en kritisch denken. Net zoals bij eerdere technologische innovaties, denk aan de rekenmachine en smartphone, moeten we een evenwicht vinden tussen het benutten van de voordelen en het behouden van onze eigen cognitieve capaciteiten. Dit vereist een doordachte integratie van AI in zowel onderwijs als werk, waarbij we verder kijken dan alleen efficiëntiewinst en ons richten op het behoud en de ontwikkeling van essentiële menselijke vaardigheden. Omdat we nog maar aan het begin staan van grootschalig AI-gebruik, is verder onderzoek cruciaal om de langetermijneffecten beter te begrijpen.</p>]]></content><author><name></name></author><category term="werk"/><summary type="html"><![CDATA[AI maakt ons productiever op het werk, maar wat is het effect op de mensen die deze tools gebruiken?]]></summary></entry><entry><title type="html">Chinese startup zet AI en financiële wereld op zijn kop</title><link href="https://wimcasteels.github.io/blog/2025/deepseek/" rel="alternate" type="text/html" title="Chinese startup zet AI en financiële wereld op zijn kop"/><published>2025-01-30T12:00:00+00:00</published><updated>2025-01-30T12:00:00+00:00</updated><id>https://wimcasteels.github.io/blog/2025/deepseek</id><content type="html" xml:base="https://wimcasteels.github.io/blog/2025/deepseek/"><![CDATA[<div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/Deepseek.webp" sizes="95vw"/> <img src="/assets/img/Deepseek.webp" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <p>Deepseek, een jonge Chinese start-up opgericht in 2023, domineert deze week het wereldnieuws. Met hun nieuwe AI-model R1 behalen ze resultaten die de modellen van OpenAI, het bedrijf achter ChatGPT, overtreffen. Het meest verrassende is dat ze dit bereikten met slechts een fractie van de gebruikelijke AI-serverinfrastructuur. Ironisch genoeg viel dit nieuws vrijwel samen met de aankondiging van project Stargate door president Trump, waarin een investering van 500 miljard dollar voor AI-computerinfrastructuur wordt voorzien. Deepseek heeft ChatGPT verdrongen als populairste app. Deze ontwikkeling zorgde voor onrust over het rendement van de enorme AI-investeringen, wat leidde tot een forse beursdaling op maandag waarbij meer dan een biljoen dollar aan beurswaarde verdampte. De cruciale vraag is nu welke blijvende impact Deepseek zal hebben op de ontwikkeling van het AI-domein.</p> <p>Er is weinig bekend over de grote AI-modellen. De grote technologiebedrijven zijn uiterst terughoudend met informatie over hun modellen en stellen dat dit nodig is om misbruik van de technologie te voorkomen. Een andere mogelijke reden voor deze geheimhouding is de vrees voor juridische gevolgen en reputatieschade als zou uitkomen welke data ze gebruiken, zoals persoonsgegevens of auteursrechtelijk beschermd materiaal, of hoe groot hun ecologische voetafdruk werkelijk is. Volgens onafhankelijke schattingen liggen de kosten voor deze geavanceerde modellen rond de 100 miljoen dollar.</p> <p>Toen verscheen Deepseek, een jonge Chinese startup die AI-taalmodellen ontwikkelt. Hun nieuwste R1-model presteert op verschillende tests even goed of zelfs beter dan de modellen van OpenAI. En dit voor slechts een fractie van de kosten. Het opmerkelijke is dat deze doorbraak plaatsvond in China, waar Amerika al jaren exportrestricties handhaaft op computerchips om de ontwikkeling van geavanceerde AI-modellen te belemmeren. NVIDIA, dat met een marktaandeel van 90% de AI-chipmarkt domineert, mag zijn meest geavanceerde chips niet naar China exporteren. Deze exportbeperkingen hadden echter een onverwacht effect: doordat Chinese onderzoekers geen toegang hadden tot de nieuwste hardware, werden ze gedwongen creatief om te gaan met de beschikbare middelen. Dit leidde tot het efficiënter trainen van modellen en uiteindelijk tot lagere kosten.</p> <p>In tegenstelling tot veel Amerikaanse techbedrijven geeft Deepseek openlijk inzicht in hun modellen, die vrij beschikbaar zijn via het online platform HuggingFace. Het R1-model werd in de eerste dagen na lancering al bijna 300.000 keer gedownload. Tot voor kort was open source ook bij Amerikaanse technologiebedrijven de norm voor AI-ontwikkeling. Open source werkt als katalysator omdat iedereen kan bijdragen aan de ontwikkeling. De huidige felle concurrentie tussen deze bedrijven op het gebied van AI-toepassingen heeft deze openheid echter verminderd. Verschillende onderzoekers, ook in de VS, zijn inmiddels aan de slag gegaan met de Deepseek-modellen. Dit kan op termijn gunstig uitpakken voor Chinese bedrijven, waar open source nog steeds de norm is, omdat zij kunnen profiteren van een wereldwijde gemeenschap die hun modellen doorontwikkelt.</p> <p>De ontwikkeling van Deepseeks efficiëntere modellen roept ernstige vragen op over de duurzaamheid van OpenAI’s bedrijfsmodel. Het bedrijf heeft nog geen winst gemaakt door de enorme kosten voor serverinfrastructuur en kan alleen blijven functioneren dankzij miljarden-investeringen van Microsoft. OpenAI verwacht zelf pas in 2029 winstgevend te worden. Samen met Oracle en NVIDIA lanceerde het bedrijf onlangs het Stargate-project: een investering van 500 miljard dollar in serverinfrastructuur om “het Amerikaanse leiderschap in AI veilig te stellen”. De lancering van Deepseeks R1 werpt echter een nieuw licht op deze gigantische investeringen. Dit wordt treffend geïllustreerd door een video uit 2023 die deze week viraal ging, waarin Sam Altman, CEO van OpenAI, beweerde dat “het totaal hopeloos is om met ons te concurreren” met een budget van ‘slechts’ 10 miljoen dollar.</p> <p>Deze ontwikkeling zorgde voor onrust bij investeerders, wat resulteerde in een forse daling op de Amerikaanse technologiebeurs. De Nasdaq Composite index zakte maandag met 3,6%, de grootste daling in vijf maanden. Meer dan 1 biljoen dollar aan wereldwijde beurswaarde ging in rook op. NVIDIA, de favoriet van Wall Street, kreeg de zwaarste klap. Het bedrijf had dankzij zijn dominante positie in de hoogwaardige computerchipmarkt enorm geprofiteerd van de AI-boom. Hun aandelen waren in de twee jaar na de lancering van ChatGPT met wel 800% gestegen, waardoor NVIDIA in november 2024 zelfs kortstondig Apple passeerde als waardevolste bedrijf. Op maandag verloor NVIDIA echter 17% van zijn marktwaarde, wat neerkwam op bijna 600 miljard dollar.</p> <p>Deepseek R1 presteert ook beter dan Amerikaanse modellen in het uitdragen van het socialistische gedachtegoed van de Chinese Communistische Partij. Het model weigert te reageren op vragen over de protesten op het Tiananmenplein in 1989 of vergelijkingen tussen Xi Jinping en Winnie de Pooh. China loopt ook voor op het gebied van AI-regulering. Nieuwe AI-modellen moeten eerst goedkeuring krijgen van de Communistische Partij, die controleert of het model correct omgaat met gevoelige onderwerpen. Deze ontwikkelingen leiden tot zorgen over het wijdverspreide gebruik van de Deepseek-app, met name over mogelijke desinformatie en het potentiële misbruik van gebruikersgegevens door de Chinese overheid.</p> <p>Kunnen deze kleinere, efficiëntere modellen bijdragen aan het behalen van klimaatdoelstellingen? Veel technologiebedrijven slagen er momenteel niet in hun klimaatdoelen te halen vanwege hun energieverslindende AI-modellen. De Jevons-paradox biedt hierbij een interessant perspectief: wanneer technologie efficiënter wordt, neemt het totale verbruik vaak juist toe in plaats van af. Dit zou kunnen betekenen dat efficiëntere AI-modellen paradoxaal genoeg leiden tot een hogere totale vraag en grotere marktgroei.</p> <p>Is dit het einde voor het voorheen onaantastbare NVIDIA? Dit lijkt voorbarig, aangezien NVIDIA nog steeds de onbetwiste leider is op het gebied van computerchips. Deepseek maakt bijvoorbeeld ook gebruik van NVIDIA-infrastructuur. De aandelenkoers herstelde zich dinsdag dan ook al deels met een stijging van 9%.</p> <p>Kan Deepseek de macht van de Amerikaanse Big Tech-bedrijven inperken? De markt voor de grote ‘foundation’-modellen is opengebroken nu het mogelijk is om zeer capabele modellen te ontwikkelen met beperkte middelen. De enorme investeringen die voorheen noodzakelijk leken, waren slechts voor een kleine groep weggelegd. Nu blijkt dat dit kan voor een fractie van de kosten, waardoor er plotseling veel meer potentiële spelers zijn. Deze Chinese doorbraak in de mondiale AI-race zou ook Europese organisaties kunnen helpen om hun eigen modellen te ontwikkelen.</p>]]></content><author><name></name></author><category term="china"/><category term="big-tech"/><summary type="html"><![CDATA[Deepseek, een jonge Chinese start-up opgericht in 2023, domineert deze week het wereldnieuws. Met hun nieuwe AI-model R1 behalen ze resultaten die de modellen van OpenAI, het bedrijf achter ChatGPT, overtreffen. Het meest verrassende is dat ze dit bereikten met slechts een fractie van de gebruikelijke AI-serverinfrastructuur. Ironisch genoeg viel dit nieuws vrijwel samen met de aankondiging van project Stargate door president Trump, waarin een investering van 500 miljard dollar voor AI-computerinfrastructuur wordt voorzien. Deepseek heeft ChatGPT verdrongen als populairste app. Deze ontwikkeling zorgde voor onrust over het rendement van de enorme AI-investeringen, wat leidde tot een forse beursdaling op maandag waarbij meer dan een biljoen dollar aan beurswaarde verdampte. De cruciale vraag is nu welke blijvende impact Deepseek zal hebben op de ontwikkeling van het AI-domein. Er is weinig bekend over de grote AI-modellen. De grote technologiebedrijven zijn uiterst terughoudend met informatie over hun modellen en stellen dat dit nodig is om misbruik van de technologie te voorkomen. Een andere mogelijke reden voor deze geheimhouding is de vrees voor juridische gevolgen en reputatieschade als zou uitkomen welke data ze gebruiken, zoals persoonsgegevens of auteursrechtelijk beschermd materiaal, of hoe groot hun ecologische voetafdruk werkelijk is. Volgens onafhankelijke schattingen liggen de kosten voor deze geavanceerde modellen rond de 100 miljoen dollar. Toen verscheen Deepseek, een jonge Chinese startup die AI-taalmodellen ontwikkelt. Hun nieuwste R1-model presteert op verschillende tests even goed of zelfs beter dan de modellen van OpenAI. En dit voor slechts een fractie van de kosten. Het opmerkelijke is dat deze doorbraak plaatsvond in China, waar Amerika al jaren exportrestricties handhaaft op computerchips om de ontwikkeling van geavanceerde AI-modellen te belemmeren. NVIDIA, dat met een marktaandeel van 90% de AI-chipmarkt domineert, mag zijn meest geavanceerde chips niet naar China exporteren. Deze exportbeperkingen hadden echter een onverwacht effect: doordat Chinese onderzoekers geen toegang hadden tot de nieuwste hardware, werden ze gedwongen creatief om te gaan met de beschikbare middelen. Dit leidde tot het efficiënter trainen van modellen en uiteindelijk tot lagere kosten. In tegenstelling tot veel Amerikaanse techbedrijven geeft Deepseek openlijk inzicht in hun modellen, die vrij beschikbaar zijn via het online platform HuggingFace. Het R1-model werd in de eerste dagen na lancering al bijna 300.000 keer gedownload. Tot voor kort was open source ook bij Amerikaanse technologiebedrijven de norm voor AI-ontwikkeling. Open source werkt als katalysator omdat iedereen kan bijdragen aan de ontwikkeling. De huidige felle concurrentie tussen deze bedrijven op het gebied van AI-toepassingen heeft deze openheid echter verminderd. Verschillende onderzoekers, ook in de VS, zijn inmiddels aan de slag gegaan met de Deepseek-modellen. Dit kan op termijn gunstig uitpakken voor Chinese bedrijven, waar open source nog steeds de norm is, omdat zij kunnen profiteren van een wereldwijde gemeenschap die hun modellen doorontwikkelt. De ontwikkeling van Deepseeks efficiëntere modellen roept ernstige vragen op over de duurzaamheid van OpenAI’s bedrijfsmodel. Het bedrijf heeft nog geen winst gemaakt door de enorme kosten voor serverinfrastructuur en kan alleen blijven functioneren dankzij miljarden-investeringen van Microsoft. OpenAI verwacht zelf pas in 2029 winstgevend te worden. Samen met Oracle en NVIDIA lanceerde het bedrijf onlangs het Stargate-project: een investering van 500 miljard dollar in serverinfrastructuur om “het Amerikaanse leiderschap in AI veilig te stellen”. De lancering van Deepseeks R1 werpt echter een nieuw licht op deze gigantische investeringen. Dit wordt treffend geïllustreerd door een video uit 2023 die deze week viraal ging, waarin Sam Altman, CEO van OpenAI, beweerde dat “het totaal hopeloos is om met ons te concurreren” met een budget van ‘slechts’ 10 miljoen dollar. Deze ontwikkeling zorgde voor onrust bij investeerders, wat resulteerde in een forse daling op de Amerikaanse technologiebeurs. De Nasdaq Composite index zakte maandag met 3,6%, de grootste daling in vijf maanden. Meer dan 1 biljoen dollar aan wereldwijde beurswaarde ging in rook op. NVIDIA, de favoriet van Wall Street, kreeg de zwaarste klap. Het bedrijf had dankzij zijn dominante positie in de hoogwaardige computerchipmarkt enorm geprofiteerd van de AI-boom. Hun aandelen waren in de twee jaar na de lancering van ChatGPT met wel 800% gestegen, waardoor NVIDIA in november 2024 zelfs kortstondig Apple passeerde als waardevolste bedrijf. Op maandag verloor NVIDIA echter 17% van zijn marktwaarde, wat neerkwam op bijna 600 miljard dollar. Deepseek R1 presteert ook beter dan Amerikaanse modellen in het uitdragen van het socialistische gedachtegoed van de Chinese Communistische Partij. Het model weigert te reageren op vragen over de protesten op het Tiananmenplein in 1989 of vergelijkingen tussen Xi Jinping en Winnie de Pooh. China loopt ook voor op het gebied van AI-regulering. Nieuwe AI-modellen moeten eerst goedkeuring krijgen van de Communistische Partij, die controleert of het model correct omgaat met gevoelige onderwerpen. Deze ontwikkelingen leiden tot zorgen over het wijdverspreide gebruik van de Deepseek-app, met name over mogelijke desinformatie en het potentiële misbruik van gebruikersgegevens door de Chinese overheid. Kunnen deze kleinere, efficiëntere modellen bijdragen aan het behalen van klimaatdoelstellingen? Veel technologiebedrijven slagen er momenteel niet in hun klimaatdoelen te halen vanwege hun energieverslindende AI-modellen. De Jevons-paradox biedt hierbij een interessant perspectief: wanneer technologie efficiënter wordt, neemt het totale verbruik vaak juist toe in plaats van af. Dit zou kunnen betekenen dat efficiëntere AI-modellen paradoxaal genoeg leiden tot een hogere totale vraag en grotere marktgroei. Is dit het einde voor het voorheen onaantastbare NVIDIA? Dit lijkt voorbarig, aangezien NVIDIA nog steeds de onbetwiste leider is op het gebied van computerchips. Deepseek maakt bijvoorbeeld ook gebruik van NVIDIA-infrastructuur. De aandelenkoers herstelde zich dinsdag dan ook al deels met een stijging van 9%. Kan Deepseek de macht van de Amerikaanse Big Tech-bedrijven inperken? De markt voor de grote ‘foundation’-modellen is opengebroken nu het mogelijk is om zeer capabele modellen te ontwikkelen met beperkte middelen. De enorme investeringen die voorheen noodzakelijk leken, waren slechts voor een kleine groep weggelegd. Nu blijkt dat dit kan voor een fractie van de kosten, waardoor er plotseling veel meer potentiële spelers zijn. Deze Chinese doorbraak in de mondiale AI-race zou ook Europese organisaties kunnen helpen om hun eigen modellen te ontwikkelen.]]></summary></entry><entry><title type="html">Sociale media voor jongeren</title><link href="https://wimcasteels.github.io/blog/2025/social-media/" rel="alternate" type="text/html" title="Sociale media voor jongeren"/><published>2025-01-26T12:00:00+00:00</published><updated>2025-01-26T12:00:00+00:00</updated><id>https://wimcasteels.github.io/blog/2025/social-media</id><content type="html" xml:base="https://wimcasteels.github.io/blog/2025/social-media/"><![CDATA[<div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/250126.webp" sizes="95vw"/> <img src="/assets/img/250126.webp" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <p>Ik verslikte me dit weekend in mijn koffie toen de nieuwe Vlaamse minister van Media op Radio één haar visie deelde over het gebruik van sociale media door kinderen. Ze vergeleek het met leren fietsen waarbij je start met zijwieltjes. Alsof het gebruik van sociale media niet veel verschilt van een fietstochtje. Ze geeft aan dat volgens haar ouders op zoek zijn naar tools om hun kinderen weerbaar te maken en verwijst hiervoor naar <a href="http://mediawijs.be">mediawijs.be</a>. Dit soort vergelijkingen riskeert de nadelige gevolgen van sociale media te minimaliseren. Als voorbeeld geeft ze nog aan dat ouders willen weten hoe een algoritme werkt. Ik zou de minister graag eens horen uitleggen hoe de algoritmes achter sociale media werken. Sterker nog, ik betwijfel of je bij de sociale mediabedrijven iemand kan vinden die deze kan uitleggen.</p> <p>Wat wel uitgebreid gedocumenteerd is zijn de effecten van deze algoritmes. Voor de platformen zelf gaat het dan vooral om de enorme winsten. De algoritmes lokken zoveel mogelijk mensen naar het platform en tonen hen precies die berichten die de kans maximaliseren dat ze op advertenties klikken. Dit levert inkomsten op van de adverteerders. Veel inkomsten. Sociale media bedrijven verdienen hier jaarlijks tientallen miljarden aan. Dat deze algoritmes menselijke zwakheden zoals verslaving uitbuiten wordt gezien als bijzaak.</p> <p>Ook de maatschappelijke effecten zijn goed gedocumenteerd. Neem bijvoorbeeld Meta, het moederbedrijf van Facebook en Instagram. Een rapport van Amnesty International documenteert uitgebreid de rol van Facebook in de genocide tegen de Rohingya in Myanmar. In 2017 werden duizenden Rohingya gedood, gemarteld, verkracht en verdreven tijdens een etnische zuiveringscampagne. In de aanloop naar deze gruweldaden versterkten Facebook’s algoritmes een golf van haat tegen de Rohingya, wat bijdroeg aan geweld in de echte wereld. Meta’s algoritmes hadden namelijk geleerd dat het promoten van haatdragende inhoud gebruikers langer op het platform hield dan feitelijke content. Hoewel Facebook de anti-Rohingya sentimenten niet heeft gecreëerd, heeft het platform deze wel aangewakkerd voor eigen financieel gewin.</p> <p>The Facebook Files, een onderzoek van interne Facebook documenten door The Wall Street Journal, toont aan dat het platform vol schadelijke mechanismes zit. Zo blijkt bijvoorbeeld dat 12,5% van de gebruikers vindt dat de app hun slaap, relaties of ouderschap negatief beïnvloedt. Het onderzoek onthult ook wat Facebook wist over de negatieve gevolgen voor jongeren en hoe ze deze in het openbaar bagatelliseren. Een interne presentatie vermeldde bijvoorbeeld dat 32% van de tienermeisjes aangaf dat Instagram hun negatieve zelfbeeld over hun lichaam verder versterkte. Ondertussen presenteerde de CEO Mark Zuckerberg publiekelijk enkel de positieve effecten die sociale apps kunnen hebben op de mentale gezondheid.</p> <p>Robert Califf, het hoofd van de Amerikaanse Food and Drug Administration (FDA), stelt dat volgens hem misinformatie (onjuiste of misleidende informatie) de belangrijkste doodsoorzaak is in de VS. Als voorbeelden noemt hij mensen die twijfelen over vaccinatie tijdens de COVID-19-pandemie en de verspreiding van vapen. Onderzoek toont bovendien aan dat sociale media een ideale voedingsbodem is voor misinformatie, die zich sneller, gemakkelijker en breder verspreidt dan feitelijk correcte berichten.</p> <p>Onderzoek van de Wereld Gezondheidsorganisatie toonde aan dat het aantal jongeren dat problematisch gebruik ervaart van sociale media is gestegen tot 11% (Vlaanderen doet het iets beter met 9%). Problematisch gebruik wordt hierbij gedefinieerd als het vertonen van minstens 6 van de 9 problematische factoren, zoals zich slecht voelen wanneer sociale media niet beschikbaar zijn of ernstige conflicten hebben met familieleden door het gebruik van sociale media.</p> <p>Sociale media hebben zeker voordelen, zoals het verbinden van mensen. Toch is voorzichtigheid geboden, vooral bij jongeren die zich in een kwetsbare levensfase bevinden en voor wie sociale media een steeds grotere rol spelen. Deze jongeren zitten in een periode waarin ze ouderlijke sturing vaak afwijzen. De situatie in Vlaanderen is weliswaar niet te vergelijken met die in Myanmar of de VS, maar deze voorbeelden tonen wel aan welke impact deze platformen kunnen hebben. Een uitgebreid maatschappelijk debat is dan ook noodzakelijk, en vergelijkingen met fietsen dragen hier niet constructief aan bij. Hoewel tools op een overheidswebsite als <a href="http://Mediawijs.be">Mediawijs.be</a> zeker waardevol zijn, betwijfel ik of ze toereikend zijn om onze jongeren te beschermen tegen de schadelijke gevolgen van sociale media.</p>]]></content><author><name></name></author><category term="sociale-media"/><summary type="html"><![CDATA[Ik verslikte me dit weekend in mijn koffie toen de nieuwe Vlaamse minister van Media op Radio één haar visie deelde over het gebruik van sociale media door kinderen. Ze vergeleek het met leren fietsen waarbij je start met zijwieltjes. Alsof het gebruik van sociale media niet veel verschilt van een fietstochtje. Ze geeft aan dat volgens haar ouders op zoek zijn naar tools om hun kinderen weerbaar te maken en verwijst hiervoor naar mediawijs.be. Dit soort vergelijkingen riskeert de nadelige gevolgen van sociale media te minimaliseren. Als voorbeeld geeft ze nog aan dat ouders willen weten hoe een algoritme werkt. Ik zou de minister graag eens horen uitleggen hoe de algoritmes achter sociale media werken. Sterker nog, ik betwijfel of je bij de sociale mediabedrijven iemand kan vinden die deze kan uitleggen. Wat wel uitgebreid gedocumenteerd is zijn de effecten van deze algoritmes. Voor de platformen zelf gaat het dan vooral om de enorme winsten. De algoritmes lokken zoveel mogelijk mensen naar het platform en tonen hen precies die berichten die de kans maximaliseren dat ze op advertenties klikken. Dit levert inkomsten op van de adverteerders. Veel inkomsten. Sociale media bedrijven verdienen hier jaarlijks tientallen miljarden aan. Dat deze algoritmes menselijke zwakheden zoals verslaving uitbuiten wordt gezien als bijzaak. Ook de maatschappelijke effecten zijn goed gedocumenteerd. Neem bijvoorbeeld Meta, het moederbedrijf van Facebook en Instagram. Een rapport van Amnesty International documenteert uitgebreid de rol van Facebook in de genocide tegen de Rohingya in Myanmar. In 2017 werden duizenden Rohingya gedood, gemarteld, verkracht en verdreven tijdens een etnische zuiveringscampagne. In de aanloop naar deze gruweldaden versterkten Facebook’s algoritmes een golf van haat tegen de Rohingya, wat bijdroeg aan geweld in de echte wereld. Meta’s algoritmes hadden namelijk geleerd dat het promoten van haatdragende inhoud gebruikers langer op het platform hield dan feitelijke content. Hoewel Facebook de anti-Rohingya sentimenten niet heeft gecreëerd, heeft het platform deze wel aangewakkerd voor eigen financieel gewin. The Facebook Files, een onderzoek van interne Facebook documenten door The Wall Street Journal, toont aan dat het platform vol schadelijke mechanismes zit. Zo blijkt bijvoorbeeld dat 12,5% van de gebruikers vindt dat de app hun slaap, relaties of ouderschap negatief beïnvloedt. Het onderzoek onthult ook wat Facebook wist over de negatieve gevolgen voor jongeren en hoe ze deze in het openbaar bagatelliseren. Een interne presentatie vermeldde bijvoorbeeld dat 32% van de tienermeisjes aangaf dat Instagram hun negatieve zelfbeeld over hun lichaam verder versterkte. Ondertussen presenteerde de CEO Mark Zuckerberg publiekelijk enkel de positieve effecten die sociale apps kunnen hebben op de mentale gezondheid. Robert Califf, het hoofd van de Amerikaanse Food and Drug Administration (FDA), stelt dat volgens hem misinformatie (onjuiste of misleidende informatie) de belangrijkste doodsoorzaak is in de VS. Als voorbeelden noemt hij mensen die twijfelen over vaccinatie tijdens de COVID-19-pandemie en de verspreiding van vapen. Onderzoek toont bovendien aan dat sociale media een ideale voedingsbodem is voor misinformatie, die zich sneller, gemakkelijker en breder verspreidt dan feitelijk correcte berichten. Onderzoek van de Wereld Gezondheidsorganisatie toonde aan dat het aantal jongeren dat problematisch gebruik ervaart van sociale media is gestegen tot 11% (Vlaanderen doet het iets beter met 9%). Problematisch gebruik wordt hierbij gedefinieerd als het vertonen van minstens 6 van de 9 problematische factoren, zoals zich slecht voelen wanneer sociale media niet beschikbaar zijn of ernstige conflicten hebben met familieleden door het gebruik van sociale media. Sociale media hebben zeker voordelen, zoals het verbinden van mensen. Toch is voorzichtigheid geboden, vooral bij jongeren die zich in een kwetsbare levensfase bevinden en voor wie sociale media een steeds grotere rol spelen. Deze jongeren zitten in een periode waarin ze ouderlijke sturing vaak afwijzen. De situatie in Vlaanderen is weliswaar niet te vergelijken met die in Myanmar of de VS, maar deze voorbeelden tonen wel aan welke impact deze platformen kunnen hebben. Een uitgebreid maatschappelijk debat is dan ook noodzakelijk, en vergelijkingen met fietsen dragen hier niet constructief aan bij. Hoewel tools op een overheidswebsite als Mediawijs.be zeker waardevol zijn, betwijfel ik of ze toereikend zijn om onze jongeren te beschermen tegen de schadelijke gevolgen van sociale media.]]></summary></entry></feed>