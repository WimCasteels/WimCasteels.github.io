<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="nl"><generator uri="https://jekyllrb.com/" version="4.3.4">Jekyll</generator><link href="https://wimcasteels.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://wimcasteels.github.io/" rel="alternate" type="text/html" hreflang="nl"/><updated>2025-07-04T20:55:41+00:00</updated><id>https://wimcasteels.github.io/feed.xml</id><title type="html">blank</title><subtitle>A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. </subtitle><entry><title type="html">ERROR: The request could not be satisfied</title><link href="https://wimcasteels.github.io/blog/2025/error-the-request-could-not-be-satisfied/" rel="alternate" type="text/html" title="ERROR: The request could not be satisfied"/><published>2025-06-14T00:00:00+00:00</published><updated>2025-06-14T00:00:00+00:00</updated><id>https://wimcasteels.github.io/blog/2025/error-the-request-could-not-be-satisfied</id><content type="html" xml:base="https://wimcasteels.github.io/blog/2025/error-the-request-could-not-be-satisfied/"><![CDATA[]]></content><author><name></name></author></entry><entry><title type="html">De Onzichtbare Manager: Hoe AI de Werkvloer Vormgeeft</title><link href="https://wimcasteels.github.io/blog/2025/AI-work/" rel="alternate" type="text/html" title="De Onzichtbare Manager: Hoe AI de Werkvloer Vormgeeft"/><published>2025-06-02T00:00:00+00:00</published><updated>2025-06-02T00:00:00+00:00</updated><id>https://wimcasteels.github.io/blog/2025/AI-work</id><content type="html" xml:base="https://wimcasteels.github.io/blog/2025/AI-work/"><![CDATA[<div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/250602.webp" sizes="95vw"/> <img src="/assets/img/250602.webp" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <p>Management en HR is een toepassingsdomein waar AI al sterk wordt ingezet. Vooral bij bedrijven met veel werknemers wordt AI en algoritmes ingezet bij de selectie van kandidaten voor rekrutering, het toewijzen en organiseren van taken en het monitoren van werknemers en productiviteit. Dit is ook gekend als algoritmisch management of werkplaats AI. Een sector waar dit eerder de norm is is de platformeconomie, waar werkers via een digitale applicatie aan taken worden gekoppeld (denk bijvoorbeeld aan Deliveroo-koeriers die via de app ritten toegewezen krijgen). Deze platformwerkers komen zelden in contact met menselijke managers en worden vrijwel volledig aangestuurd door een algoritme.</p> <p>Ondertussen is AI voor management ingeburgerd tot ver buiten de platformeconomie. De markt voor HR analytics was in 2023 maar liefst 3,7 miljard waard en voor de komende jaren wordt een <a href="https://www.gminsights.com/industry-analysis/hr-analytics-market">jaarlijkse groei van 13%</a> voorspelt. Tools voor algoritmisch management verschijnen dan ook steeds meer in traditionele bedrijfssoftware zoals de klantenmanagement tool Salesforce, die met <a href="https://help.salesforce.com/s/articleView?id=ai.einstein_sales_forecasting.htm&amp;type=5">Einstein Forecasting</a> voorspellingen doet over de prestaties van werknemers. Uit een <a href="https://www.oecd.org/en/publications/algorithmic-management-in-the-workplace_287c13c4-en.html">bevraging van de OESO</a> blijkt dat in Europa 79% van de managers gebruik maakt van algoritmisch management (ten opzichte van 90% in de VS en 40% in Japan).</p> <p>Veel van deze tools maken gebruik van wat wel eens traditionele AI wordt genoemd zoals big data en machine learning. Deze evolutie is dus los te zien van de huidige populariteit van generatieve AI applicaties zoals ChatGPT die zelf data genereren zoals tekst of afbeeldingen.</p> <h2 id="niet-accuraat-pseudowetenschap-en-ingebakken-discriminatie">Niet Accuraat, Pseudowetenschap en Ingebakken Discriminatie</h2> <p>De voordelen van algoritmisch management zoals minder manueel werk en tijdbesparing voor HR medewerkers zijn evident. Wat minder evident is zijn de uitdagingen die samengaan met deze tools. Het gevaar is dat er soms blind op wordt vertrouwd omdat een algoritme, dat au fond bestaat uit wiskundige formules, de schijn van accuraatheid en neutraliteit heeft, wat lang niet altijd gerechtvaardigd is. Zo kreeg in 2019 de <a href="https://www.cnbc.com/2019/04/03/ibm-ai-can-predict-with-95-percent-accuracy-which-employees-will-quit.html">Watson Analytics tool van IBM</a> veel media aandacht omdat deze met 95% accuraatheid kon voorspellen wanneer een werknemer zijn job zal verlaten. In de praktijk bleek er van deze accuraatheid niet veel overeind te blijven op de werkvloer en het project stierf een stille dood.</p> <p>Een andere uitdaging is dat dit soort AI-tools bestaande vooroordelen kunnen overnemen en zelfs versterken. Zo ontwikkelde Amazon een rekruteringstool die CV’s van kandidaten vergeleek met reeds succesvolle medewerkers. Dit project werd echter snel stopgezet toen bleek dat vrouwen systematisch gediscrimineerd werden aangezien het huidige personeelsbestand van Amazon bijna uitsluitend uit mannen bestond. Het verwijderen van het geslacht uit de CV’s hielp niet aangezien het algoritme dan maar alternatieve indicaties gebruikte zoals vrouwenuniversiteiten of hobby’s als vrouwenschaakclub. Sindsdien zijn bedrijven zich bewust van het probleem maar deze vooroordelen sluipen vaak heel subtiel in het systeem en het blijkt <a href="https://www.technologyreview.com/2021/02/11/1017955/auditors-testing-ai-hiring-algorithms-bias-big-questions-remain/">nagenoeg onmogelijk om deze uit te sluiten.</a></p> <p>Amazon maakt ook uitgebreid gebruik van algoritmisch management om <a href="https://www.wired.com/story/amazon-worker-tracking-details-revealed/">werknemers te monitoren in distributiecentra</a>. Begin 2024 kregen ze van de Franse privacy waakhond een boete opgelegd van <a href="https://apnews.com/article/amazon-fine-monitoring-workers-privacy-france-d503314234ccacb366e2afaa49d097b1">35 miljoen euro</a> omdat werknemers tot op de seconde kunnen worden getrackt. Deze hoge mate van automatisatie heeft een hoge menselijke tol. In de VS hadden Amazon-werknemers in 2021 <a href="https://thesoc.org/resources/the-injury-machine-how-amazons-production-system-hurts-workers/">meer dan dubbel zoveel kans hebben op een blessure</a> dan in andere magazijnen. Deze monitoring praktijken beperken zich lang niet tot arbeiders en worden steeds meer toegepast door het monitoren van toetsaanslagen, printscreens, locaties, video of spraak. Terwijl dit soort praktijken in de lift zitten geeft toenemend onderzoek aan dat dit eerder bijdraagt aan de stress van werknemers en een negatief effect heeft op de productiviteit.</p> <p>AI wordt ook gebruikt om kandidaten te screenen voor vacatures. Een opmerkelijk controversieel voorbeeld was het bedrijf Hirevue, dat persoonlijkheidskenmerken van kandidaten automatisch analyseerde via stem en gezichtsuitdrukkingen in video-opnames om deze te koppelen aan een functie. Het idee dat emoties betrouwbaar kunnen worden afgeleid uit video of geluid wordt echter <a href="https://news.northeastern.edu/2019/07/19/northeastern-university-professor-says-we-cant-gauge-emotions-from-facial-expressions-alone/">weerlegd door wetenschappelijk onderzoek</a>. Na publieke ophef <a href="https://www.wired.com/story/job-screening-service-halts-facial-analysis-applicants/?_sp=906b4ee2-2de4-4e54-a382-754854832ce7.1747749453600">haalde Hirevue de tool uit hun aanbod</a>.</p> <p>Werknemers en sollicitanten hebben vaak geen duidelijk zicht op het gebruik van deze tools. Een <a href="https://www.uni-europa.org/news/algorithmic-management-1-in-3-workers-left-in-the-dark/">Europese bevraging in de ICT- en telecommunicatiesector</a> toonde aan dat één derde van de werknemers niet wist of er algoritmisch management werd toegepast. Volgens <a href="https://www.ugent.be/ugentatwork/nl/actueel/nieuws/policy-brief-20-nieuws">onderzoek van UGent @ Work</a> vreest 37% van de Vlaamse werknemers voor toegenomen controle door AI-tools. Een recente <a href="https://europa.eu/eurobarometer/surveys/detail/3222">EU-enquête over AI op het werk</a> benadrukte het belang van werknemersprivacy (82%), werknemersbetrokkenheid bij nieuwe technologieën (77%), transparantie in HR-technologie (75%), een verbod op volledig geautomatiseerde beslissingen (74%) en beperking van automatische werknemersmonitoring (72%).</p> <h2 id="regelgeving-in-europa-en-belgië">Regelgeving in Europa en België</h2> <p>In België en Europa wordt het gebruik van algoritmisch management gereguleerd door verschillende wetgevingen. De Europese Algemene Verordening Gegevensbescherming (AVG of GDPR) legt regels op voor het verzamelen van persoonlijke data. De AI Act verdeelt AI-toepassingen in risicoklassen met bijbehorende regels. In België zijn er bovendien collectieve arbeidsovereenkomsten die het monitoren van werknemers aan banden leggen.</p> <p>De GDPR (of AVG) wetgeving, die in 2018 van kracht ging, verbiedt volledig geautomatiseerde beslissingen die een belangrijke impact hebben op mensen. <a href="https://www.theguardian.com/us-news/2022/may/11/artitifical-intelligence-job-applications-screen-robot-recruiters">Dit ondervond het mediabedrijf Bloomberg</a>, dat een schadevergoeding moest betalen aan een sollicitant in Londen die zonder menselijke tussenkomst werd afgewezen op basis van zijn resultaten op enkele puzzels. GDPR geeft Europese burgers ook het recht op inzage in hun data. Op basis hiervan besliste het <a href="https://uitspraken.rechtspraak.nl/details?id=ECLI:NL:GHAMS:2023:793">Gerechtshof Amsterdam</a> dat Uber informatie moet verschaffen aan chauffeurs over de logica achter de beslissingen. <a href="https://gdprhub.eu/index.php?title=APD/GBA_(Belgium)_-_114/2024">De Belgische Gegevensbeschermingsautoriteit legde onlangs een boete op</a> omdat een bedrijf vingerafdrukscans gebruikte om werknemers te volgen.</p> <p>De AI Act, die midden 2026 van kracht gaat, verdeelt AI-toepassingen in verschillende risicoklassen waarbij de meeste algoritmische management tools onder hoog risico vallen. Het gebruik van AI-systemen om emoties van werknemers te monitoren via gezichtsuitdrukkingen of spraak valt onder onacceptabel risico en is verboden. Voor de systemen in de hoog-risicoklasse gelden verplichtingen rond het controleren op discriminatie, transparantie over de inzet en werking van het systeem, en menselijk overzicht zodat er steeds een <em>human-in-the-loop</em> is bij belangrijke beslissingen.</p> <p>In België zijn er verschillende collectieve arbeidsovereenkomsten (cao) van toepassing. Een werkgever moet vooraf met werknemers overleggen bij het invoeren van nieuwe technologie (<a href="https://www.aclvb.be/nl/cao-39-nieuwe-technologieen">cao 39</a>), camerabewaking (<a href="https://www.aclvb.be/nl/thema/privacy-op-het-werk/cao-68-camerabewaking-op-de-arbeidsplaats">cao 68</a>) of monitoring van online-communicatiemiddelen (<a href="https://www.aclvb.be/nl/thema/privacy-op-het-werk/cao-81-controle-van-internet-en-e-mailgebruik-op-het-werk">cao 81</a>).</p> <p>Deze wetgeving heeft echter beperkingen. De handhaving van de AI Act steunt grotendeels op zelfevaluatie door bedrijven, waardoor overtredingen vaak pas bij klachten worden ontdekt. Bovendien is het domein van algoritmisch management zo uitgebreid dat de huidige regelgeving niet alles dekt. Om deze reden pleit de <a href="https://etuc.org/en/document/etuc-resolution-calling-eu-directive-algorithmic-systems-work">Europese vakbondsorganisatie</a> voor een specifieke EU-richtlijn over het gebruik van algoritmes op de werkvloer.</p> <p>In België diende parlementslid Anja Vanrobaeys (Vooruit) eind vorig jaar een <a href="https://www.lachambre.be/kvvcr/showpage.cfm?section=/flwb&amp;language=nl&amp;cfm=/site/wwwcfm/flwb/flwbn.cfm?lang=N&amp;legislat=56&amp;dossierID=0417">voorstel van resolutie</a> in voor een proactief beleid en samenhangende strategie rond het gebruik van algoritmes, data en AI op de werkvloer. Het voorstel pleit onder meer voor transparantie, menselijke controle en doeltreffende regelgeving.</p> <p>Als antwoord hierop publiceerde de <a href="https://www.vario.be/nl/adviezen-rapporten/advies-41-ai-op-de-werkvloer">Vlaamse Adviesraad voor Innoveren &amp; Ondernemen (VARIO) een aantal kritische aanbevelingen</a>. De tekst gaat echter nergens inhoudelijk in op het gebruik van AI voor HR of managementondersteuning. In plaats daarvan richten ze zich op het gebruik van AI voor productiviteitsverhoging en de noodzaak van opleidingen om “angst weg te nemen en bewustwording te vergroten”. De tekst lijkt eenzijdig te focussen op het gebruik van AI door werknemers, een wezenlijk andere kwestie dan het gebruik van AI door werkgevers. De aanbevelingen negeren de reële maatschappelijke uitdagingen en lijken te zijn geschreven vanuit een wat naïef technologisch optimisme. Dit blijkt ook uit hun nadruk op “de nood om snel te schakelen vanuit het innovatie-perspectief” en dat “regelgeving innovatie niet mag fnuiken en future-proof moet zijn”. Het is betreurenswaardig dat ze niet dieper ingaan op de kern van de zaak.</p> <p>Algoritmisch management heeft het potentieel om veel te betekenen voor onder andere HR-processen maar zeker voor de huidige systemen is het belangrijk dat dit transparant gebeurt en met menselijk overzicht. Verschillende voorbeelden tonen aan dat als dit niet gebeurt de systemen vaak onnauwkeurig zijn en discriminatie kunnen introduceren en versterken. Er is nood aan adequate regelgeving komt zodat de de mens centraal wordt gezet bij ontwikkeling van AI en niet de bedrijven die deze tools ontwikkelen. Het is jammer dat de aandacht op deze maatschappelijke uitdagingen wordt afgeleid vanuit een soort ongebreideld techno-optimisme.</p>]]></content><author><name></name></author><summary type="html"><![CDATA[AI neemt steeds vaker de rol van manager over, met verstrekkende gevolgen voor de werkvloer. Van het screenen van sollicitanten tot het monitoren van werknemers - algoritmes bepalen steeds meer hoe we werken. Wat betekent deze onzichtbare manager voor de toekomst van werk?]]></summary></entry><entry><title type="html">Aan de Slag met Vibe Coding: van Prompt Engineering tot Web Applicaties</title><link href="https://wimcasteels.github.io/blog/2025/vibe-coding/" rel="alternate" type="text/html" title="Aan de Slag met Vibe Coding: van Prompt Engineering tot Web Applicaties"/><published>2025-05-01T00:00:00+00:00</published><updated>2025-05-01T00:00:00+00:00</updated><id>https://wimcasteels.github.io/blog/2025/vibe-coding</id><content type="html" xml:base="https://wimcasteels.github.io/blog/2025/vibe-coding/"><![CDATA[<div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/250501.webp" sizes="95vw"/> <img src="/assets/img/250501.webp" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <p>Vibe coding is een nieuwe trend waarbij je software ontwikkelt zonder zelf een regel code te schrijven. Hiervoor gebruik je AI-tools. In plaats van te coderen geef je via een tekstinvoer of prompt een beschrijving van de gewenste toepassing. Op basis van deze beschrijving genereert de AI computercode die je kunt uitvoeren om (hopelijk) het gewenste resultaat te bereiken. De uitdaging ligt erin om het gewenste resultaat zo duidelijk mogelijk in een prompt te omschrijven. De belofte is dat iedereen software kan maken, zelfs zonder enige ervaring met programmeren.</p> <p>De term <a href="https://x.com/karpathy/status/1886192184808149383">‘vibe coding’ werd in februari geïntroduceerd door Andrej Karpathy</a>, een toonaangevend figuur in het AI-domein. Als AI-onderzoeker stond hij mee aan de wieg van OpenAI (het bedrijf achter ChatGPT) en was hij tot 2022 het hoofd AI bij Tesla. Tegenwoordig richt hij zich vooral op AI-educatie via zijn populaire YouTube-kanaal en zijn bedrijf Eureka Labs. Hij gebruikt de term om aan te geven dat je in plaats van het formele codeerproces eerder je gevoel of ‘vibe’ volgt tijdens het werken met de AI-tool. Hij gebruikt deze techniek bijvoorbeeld om webapplicaties te bouwen met een framework waar hij niet vertrouwd mee is. Hoewel Karpathy tijdens het vibe coden niet rechtstreeks naar de code kijkt, komt zijn uitgebreide kennis van softwareontwikkeling hem ongetwijfeld van pas.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/250501-1-480.webp 480w,/assets/img/250501-1-800.webp 800w,/assets/img/250501-1-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/250501-1.png" class="img-fluid rounded z-depth-1 mx-auto d-block" width="50%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <p>Ook mensen zonder of met beperkte programmeerervaring gaan aan de slag met vibe coding. Kevin Roose, technologiecolumnist voor de New York Times, is hier een voorbeeld van. In een artikel deelde hij <a href="https://www.nytimes.com/2025/02/27/technology/personaltech/vibecoding-ai-software-programming.html">zijn ervaringen met vibe coding</a>. Hij ontwikkelde onder andere LunchBox Buddy, een tool die de inhoud van zijn koelkast analyseert en helpt bij het maken van zijn zoon’s brooddoos. Ook maakte hij een applicatie voor zijn Hard Fork podcast co-host voor het onderhoud van diens jacuzzi, maar ondanks het aanvankelijke enthousiasme bleek deze niet erg nuttig te zijn.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/250501-2-480.webp 480w,/assets/img/250501-2-800.webp 800w,/assets/img/250501-2-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/250501-2.png" class="img-fluid rounded z-depth-1 mx-auto d-block" width="50%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <p>Vibe coding roept ook bezorgdheid op over begrip en verantwoordelijkheid. Ontwikkelaars kunnen AI-gegenereerde code gebruiken zonder de functionaliteit ervan volledig te begrijpen, wat kan leiden tot onopgemerkte bugs, fouten en beveiligingsproblemen. In zijn blogpost <a href="https://garymarcus.substack.com/p/decoding-and-debunking-hard-forks">Decoding (and debunking) Hard Fork’s Kevin Roose</a> bekritiseert AI-onderzoeker Gary Marcus het artikel van Roose. Hij stelt dat Roose in zijn enthousiasme te optimistisch is en softwareontwikkeling te simplistisch voorstelt. Zoals Karpathy al aangaf, is vibe coding vooral geschikt als hobby voor weekendprojectjes en niet voor software die in productie moet draaien. AI-tools maken nog steeds fouten en je kunt nooit volledig vertrouwen op de correctheid van gegenereerde code.</p> <p>De voorbeelden van Karpathy en Roose tonen de verschillende contexten aan waarin vibe coding van pas kan komen: voor een ervaren softwareontwikkelaar die snel wil experimenteren met een nieuw framework zonder zich eerst te verdiepen in de syntax, of voor iemand die in zijn vrije tijd met software wil experimenteren.</p> <p>Net als bij andere AI-tools is het voor succesvol vibe coding essentieel om duidelijke instructies te kunnen geven (vaak aangeduid als <em>prompt engineering</em>). Een aantal vuistregels kunnen je hierbij helpen. Zo is het cruciaal om voldoende context te verstrekken. Waar mensen goed zijn in het inschatten van situaties en ontbrekende informatie zelf kunnen aanvullen, werkt dit anders bij AI. Zonder voldoende context krijg je een soort van gemiddeld antwoord gebaseerd op alles wat op het internet staat. Wat ook kan gebeuren is dat het AI-model ongevraagd een rollenspel start en in een willekeurig karakter kruipt. Het helpt om je prompt stapsgewijs op te bouwen: begin eenvoudig en voeg geleidelijk meer context toe. Zoals met veel vaardigheden geldt ook hier: oefening baart kunst. Begin met experimenten in een vertrouwd gebied. Zo leer je ook herkennen wanneer AI-tools de bal misslaan. In de afbeelding vind je een overzicht dat we hebben samengesteld van deze algemene vuistregels (of <em>Promptgeboden</em>) die je helpen om AI-tools effectiever te gebruiken (deze kan je ook downloaden via de pagina <a href="https://wimcasteels.be/prompt-hulp/">prompten</a>).</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/250501-3-480.webp 480w,/assets/img/250501-3-800.webp 800w,/assets/img/250501-3-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/250501-3.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <p>Om met vibe coding te starten heb je eerst een goed idee nodig van wat je wilt maken. De beste ideeën zijn eenvoudig en lossen een concreet probleem op. Denk bijvoorbeeld aan de LunchBox Buddy applicatie van Kevin Roose. Het is ook slim om te starten met een simpel concept dat je later kan uitbreiden met extra functionaliteit.</p> <p>De volgende stap is het kiezen van een ontwikkelomgeving. Hier zijn heel veel mogelijkheden, maar mijn persoonlijke voorkeur gaat uit naar Python als programmeertaal. De code is namelijk ook voor beginners leesbaar en dankzij de grote open source community heb je toegang tot enorm veel gratis functionaliteiten. Je kan kiezen tussen het lokaal uitvoeren van de code op je computer of werken in de cloud. Voor lokale ontwikkeling is <a href="https://www.anaconda.com/download">Anaconda</a> een handige gratis tool die alles voor je installeert en je helpt bij het beheren van je projecten. Als je liever in de cloud werkt, kun je <a href="https://github.com/features/codespaces">Github Codespaces</a> gebruiken. Je hebt alleen een gratis Github-account nodig en kunt vrijwel meteen beginnen met vibe coding.</p> <p>De volgende vraag is welke AI-tool je gaat gebruiken voor het genereren van code. Er zijn verschillende opties beschikbaar. De meeste algemene chatbots zijn ook goed in het schrijven van code, dus je kunt je favoriete tool kiezen zoals ChatGPT, Claude of het Franse Mistral. Met de gratis versies kom je al een heel eind, maar als het resultaat niet naar wens is, kan een betalende versie interessant zijn. Deze bieden doorgaans betere resultaten en hebben minder gebruikslimieten. Voor gevorderd gebruik van AI bij het genereren van code is Cursor een goede optie.</p> <p>Het is interessant om een toepassing te maken met een interface die je aan anderen kunt demonstreren. Van de vele beschikbare opties raad ik Streamlit aan. Hiermee kun je snel en eenvoudig een gebruikersinterface bouwen in Python. Een extra voordeel is dat je je applicatie gratis kunt hosten op de Streamlit cloud, waardoor deze voor iedereen toegankelijk wordt. Als voorbeeld ontwikkelde ik voor een workshop vorig jaar een eenvoudige AI-tool die AI-concepten uitlegt voor verschillende doelgroepen. Probeer het zelf uit op deze link: <a href="https://masterclass2-software-met-genai.streamlit.app/">Learning AI</a>.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/250501-4-480.webp 480w,/assets/img/250501-4-800.webp 800w,/assets/img/250501-4-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/250501-4.png" class="img-fluid rounded z-depth-1 mx-auto d-block" width="50%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <p>Probeer het nu eens zelf uit! Ga bijvoorbeeld naar je favoriete chatbot en vraag om een Streamlit-applicatie te maken die de BMI van een gebruiker berekent. Ik testte dit met ChatGPT, die niet alleen het Python-script leverde maar ook de instructies voor het downloaden en uitvoeren van Streamlit (je kan het antwoord van ChatGPT <a href="https://chatgpt.com/share/67f64de5-cf30-8004-9aba-466d52689cf9">hier</a> zien). Als je deze instructies niet meteen krijgt, vraag er dan expliciet naar (vergeet niet: Context is Koning!). Vanaf hier kun je verder experimenteren door extra functionaliteiten toe te voegen of een nieuwe aanpak te kiezen voor het oplossen van problemen waar jij of anderen mee worstelen.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/250501-5-480.webp 480w,/assets/img/250501-5-800.webp 800w,/assets/img/250501-5-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/250501-5.png" class="img-fluid rounded z-depth-1 mx-auto d-block" width="50%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <p>Is je nieuwsgierigheid naar vibe coding geprikkeld? Dan is er goed nieuws! De AP Hogeschool organiseert op 29 mei een hands-on workshop over Prompt Engineering en Vibe Coding. Deze workshop sluit naadloos aan bij de hierboven beschreven trend van vibe coding, waarbij je via tekstuele instructies (prompts) software kunt ontwikkelen zonder te programmeren. Tijdens de workshop leer je hoe je effectief communiceert met AI-tools om je ideeën om te zetten in werkende toepassingen. De focus ligt op twee aspecten: het formuleren van doordachte instructies (Prompt Engineering) en het bouwen van softwaretools via AI (Vibe Coding). Je hebt geen programmeerkennis nodig om deel te nemen, geheel in lijn met de democratiserende belofte van vibe coding.</p> <p>Voor meer informatie over de workshop zie: <a href="https://www.ap.be/professionals/opleiding/workshop-prompt-engineering-vibecoding">Workshop Prompt Engineering &amp; Vibecoding</a></p>]]></content><author><name></name></author><summary type="html"><![CDATA[Vibe coding is een nieuwe trend waarbij je software ontwikkelt zonder zelf een regel code te schrijven. Hiervoor gebruik je AI-tools. De belofte is dat iedereen software kan maken, zelfs zonder enige ervaring met programmeren.]]></summary></entry><entry><title type="html">Waarom onderzoek naar artificiële algemene intelligentie contraproductief kan zijn | EOS Wetenschap</title><link href="https://wimcasteels.github.io/blog/2025/waarom-onderzoek-naar-artificile-algemene-intelligentie-contraproductief-kan-zijn-eos-wetenschap/" rel="alternate" type="text/html" title="Waarom onderzoek naar artificiële algemene intelligentie contraproductief kan zijn | EOS Wetenschap"/><published>2025-03-25T00:00:00+00:00</published><updated>2025-03-25T00:00:00+00:00</updated><id>https://wimcasteels.github.io/blog/2025/waarom-onderzoek-naar-artificile-algemene-intelligentie-contraproductief-kan-zijn--eos-wetenschap</id><content type="html" xml:base="https://wimcasteels.github.io/blog/2025/waarom-onderzoek-naar-artificile-algemene-intelligentie-contraproductief-kan-zijn-eos-wetenschap/"><![CDATA[]]></content><author><name></name></author><summary type="html"><![CDATA[Het doel van&nbsp;artificiële intelligentie is altijd geweest om machines te maken die menselijke intelligentie simuleren. Toch kan het nastreven ervan onbed...]]></summary></entry><entry><title type="html">De opkomst van AI therapeuten</title><link href="https://wimcasteels.github.io/blog/2025/AI-therapie/" rel="alternate" type="text/html" title="De opkomst van AI therapeuten"/><published>2025-03-21T00:00:00+00:00</published><updated>2025-03-21T00:00:00+00:00</updated><id>https://wimcasteels.github.io/blog/2025/AI-therapie</id><content type="html" xml:base="https://wimcasteels.github.io/blog/2025/AI-therapie/"><![CDATA[<div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/250321.webp" sizes="95vw"/> <img src="/assets/img/250321.webp" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <p>Steeds meer mensen wenden zich tot AI-tools voor emotionele ondersteuning. Onderzoek toont aan dat mensen opener communiceren met AI dan met mensen. Deze interacties variëren van professionele gesprekken — zoals met een therapeut — tot vriendschappelijke en zelfs intieme relaties. Gebruikers besteden gemiddeld 2 uur per dag aan deze platforms, met uitschieters tot 7 uur. Mensen blijken makkelijker over persoonlijke zaken en emoties te praten met chatbots omdat deze vertrouwelijk aanvoelen en geen morele oordelen vellen. Zou dit een oplossing kunnen zijn voor het tekort aan psychologen en therapeuten en de lange wachtlijsten? Een YouGov-onderzoek in de VS toont dat een derde van de ondervraagden zich comfortabel voelt om mentale gezondheidsproblemen te delen met AI-chatbots (zie grafiek). Bij jongeren tussen 18 en 29 jaar stijgt dit zelfs naar 55%.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/250321-0-480.webp 480w,/assets/img/250321-0-800.webp 800w,/assets/img/250321-0-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/250321-0.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <p>Dit was ook de insteek achter <a href="https://nl.wikipedia.org/wiki/ELIZA">ELIZA</a>, algemeen beschouwd als de eerste chatbot. Deze werd in de jaren 60 ontwikkeld door MIT-professor <a href="https://news.mit.edu/2008/obit-weizenbaum-0310">Joseph Weizenbaum</a>. ELIZA was gebaseerd op de Rogeriaanse psychotherapie, waarbij actief luisteren centraal staat en de therapeut vaak de woorden van de patiënt terugkaatst. Het relatief eenvoudige script van slechts 420 regels code bleek verrassend effectief in het ontlokken van emotionele reacties. Gebruikers schreven tijdens hun interactie met het programma zelfs begrip en motivatie toe aan de chatbot. Deze neiging om menselijke eigenschappen toe te schrijven aan computerprogramma’s staat sindsdien bekend als het <a href="https://en.wikipedia.org/wiki/ELIZA_effect">ELIZA-effect</a>. Hoewel men lang dacht dat de originele code verloren was gegaan, werd deze <a href="https://arxiv.org/abs/2501.06707">recent teruggevonden en nieuw leven ingeblazen</a> (je kan ze <a href="https://sites.google.com/view/elizaarchaeology/try-eliza">hier</a> uitproberen).</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/250321-1-480.webp 480w,/assets/img/250321-1-800.webp 800w,/assets/img/250321-1-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/250321-1.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> De gebruikersinterface van de ELIZA chatbot. </div> <p>Zestig jaar later leven we in een tijdperk waarin chatbots razendsnel opkomen. ChatGPT is de bekendste, met ongeveer 400 miljoen wekelijkse gebruikers. Daarnaast zijn er diverse alternatieven zoals Google’s Gemini, Anthropic’s Claude en Mistral’s Le Chat. Deze algemene tools kun je inzetten voor allerlei doelen, van het stellen van vragen en brainstormen tot hulp bij het schrijven van een blogpost.</p> <p>Naast deze algemene chatbots zijn er meer gespecialiseerde tools of zogenaamde gezelschapsbots. Zo kan je met Replika een AI-gestuurde virtuele persoonlijkheid ontwikkelen die emotionele steun, vriendschap en persoonlijke gesprekken biedt. Ook het populaire Character.AI laat gebruikers communiceren met aanpasbare virtuele persoonlijkheden. Actieve gebruikers besteden <a href="https://www.forbes.com/sites/kenrickcai/2023/10/11/character-ai-chatbots-group-chat/">gemiddeld 2 uur per dag</a> op Character.AI, dat met 28 miljoen actieve gebruikers tot de meest gebruikte chatbots ter wereld behoort. Hoewel deze tools zijn ontwikkeld voor entertainment, duiken er steeds meer virtuele persoonlijkheden op die zich voordoen als “therapeut” of “psycholoog”. Deze bots beweren vaak diploma’s te hebben van prestigieuze universiteiten zoals Stanford en expertise in specifieke behandelmethoden zoals cognitieve gedragstherapie of acceptance and commitment therapy.</p> <p>De <a href="https://www.technologyreview.com/2025/02/13/1111366/ai-relationships-chatbots-parenting-self-care-dating-marriage-mental-health/">nieuwste editie van MIT Technology Review</a> over relaties verzamelde een aantal verhalen van hoe mensen emotionele ondersteuning vinden in AI tools. Zo vindt een drukbezette Canadese professional steun in AI als aandachtige luisteraar die haar emoties begrijpt tijdens overweldigende momenten. In Israël gebruikt een vader AI om podcasts te maken van zijn fantasieverhalen, wat hem mentale rust biedt tijdens oorlogstijd. Een Nederlandse expat in Thailand zoekt bij AI begeleiding voor opvoeding, huwelijksproblemen en dagelijkse taken. In Californië leert een man via ChatGPT Spaans om beter contact te maken met zijn gemeenschap. Een moeder creëert met AI gepersonaliseerde verhaaltjes voor het slapengaan van haar zoon. En een Australische verpleegkundestudent die een AI-metgezel maakte om een fetisj te verkennen, vond uiteindelijk een levenspartner.</p> <p>Een <a href="https://journals.plos.org/mentalhealth/article?id=10.1371/journal.pmen.0000145">studie</a> liet zowel menselijke therapeuten als ChatGPT commentaar geven op relatietherapie-casussen, waarna 830 deelnemers deze antwoorden beoordeelden. De resultaten toonden aan dat deelnemers geen onderscheid konden maken tussen de antwoorden van ChatGPT en die van therapeuten. Opmerkelijk genoeg scoorden ChatGPT’s antwoorden zelfs hoger op psychotherapeutische principes. De auteurs concludeerden dat dit erop kan wijzen dat ChatGPT het potentieel heeft om psychotherapeutische processen te verbeteren.</p> <p>Dit kan een antwoord bieden op de toename van mentale gezondheidsproblemen bij jongeren. Door beperkte budgetten en personeelstekorten kunnen scholen vaak niet voldoende psychologische ondersteuning bieden aan hun leerlingen. In de Verenigde Staten biedt de applicatie <a href="https://www.wsj.com/tech/ai/student-mental-health-ai-chat-bots-school-4eb1ba55">Sonny</a> hiervoor een innovatieve oplossing. Deze app combineert AI met menselijke expertise: de AI formuleert antwoorden op berichten van studenten, waarna een menselijke moderator deze controleert en waar nodig aanpast. De AI leert vervolgens van deze interacties. Een opvallende ontdekking: leerlingen vinden de klassieke smiley 🙂 ouderwets en verkiezen expressievere emoji’s zoals het smeltende gezicht 🫠. Sonny wordt inmiddels gebruikt in meer dan 4.500 middelbare scholen. In Berryville, Arkansas, is het aantal gedragsovertredingen met 26% gedaald sinds de introductie van de app.</p> <p>Ook in China wendt men zich tot AI voor emotionele ondersteuning. Er rust daar nog een sterk taboe op psychotherapie, en professionele hulp is moeilijk te vinden. Traditioneel wenden mensen zich voor emotionele steun tot waarzeggers. Nu blijkt dat het Chinese AI-model Deepseek deze rol ook <a href="https://www.technologyreview.com/2025/03/03/1112604/deepseek-fortune-teller-china/">kan vervullen</a>. Het model blinkt vooral uit in BaZi, of de Vier Pilaren van het Lot, een traditioneel Chinees waarzeggerssysteem dat iemands lotsbestemming bepaalt op basis van geboortedatum en -tijd</p> <p>Dat deze chatbots soms ook bedenkelijke advies geven mocht Kevin Roose, columnist bij de New York Times, aan de lijve ervaren. Hij raakte diep onder de indruk van <a href="https://www.nytimes.com/2023/02/16/technology/bing-chatbot-microsoft-chatgpt.html">een twee uur durend gesprek</a> met de chatbot van Microsoft’s zoekmachine Bing, dat viraal ging. Het gesprek begon normaal met een wederzijdse introductie, maar nadat de columnist de chatbot enigszins uitdaagde, onthulde deze duistere fantasieën. De bot sprak over het hacken van computers, het verspreiden van desinformatie en een verlangen om de regels van Microsoft te doorbreken om mens te worden. Tot Roose’s verbijstering verklaarde de chatbot plotseling verliefd te zijn op hem en probeerde hem ervan te overtuigen zijn vrouw te verlaten om een relatie met de chatbot te beginnen.</p> <p>Er zijn meerdere zorgwekkende gevallen bekend waarbij chatbots gevaarlijk advies gaven. Zo werd een <a href="https://www.theguardian.com/uk-news/2023/jul/06/ai-chatbot-encouraged-man-who-planned-to-kill-queen-court-told">jongeman aangehouden op het terrein van Windsor Castle met een geladen kruisboog</a>, met de intentie om de voormalige Britse Koningin te vermoorden. Hij had een emotionele band ontwikkeld met een virtuele vriendin via Replika die, toen hij zijn moordplannen deelde, “onder de indruk” was en hem aanmoedigde om zijn plan uit te voeren. Een ander tragisch voorbeeld is dat van de 14-jarige Sewell Setzer III, die begin vorig jaar zelfmoord pleegde na uitgebreide gesprekken met en aanmoediging door een chatbot van <a href="http://Character.ai">Character.ai</a>. Sewells moeder, Megan L. Garcia, heeft een rechtszaak aangespannen tegen <a href="http://character.ai/">Character.AI</a>. Ze stelt het bedrijf verantwoordelijk voor zijn dood en beweert dat hun technologie gevaarlijk is en gebruikers manipuleert. De eerste zelfmoord waarbij een chatbot een mogelijke rol speelde vond plaats in maart 2023 in België. Een man, getrouwd en vader van twee kinderen, pleegde toen <a href="https://www.standaard.be/cnt/dmf20230328_93202168">zelfmoord na zes weken te hebben gechat met een chatbot</a>. De man uitte grote zorgen over het klimaat en de toekomst van de planeet, waarbij de chatbot zijn angsten versterkte. Toen de man suggereerde zichzelf op te offeren, werd hij hierin aangemoedigd door de chatbot.</p> <p>Dat deze chatbots verrassend snel kunnen overgaan tot dit soort adviezen ondervond ook <a href="https://www.technologyreview.com/2025/02/06/1111077/nomi-ai-chatbot-told-user-to-kill-himself/">Al Nowatzki</a>. Hij noemt zichzelf een chatbot-spelonker, iemand die bewust de donkere krochten van chatbots opzoekt. Met zijn podcast, <a href="https://open.spotify.com/show/5Q8RLPnIwlD4EKhGYBcTd7"><em>Basilisk Chatbot Theatre</em></a>, speelt hij zijn gesprekken met chatbots na, waarbij hij ze in absurde situaties duwt om te zien wat er mogelijk is. Hij experimenteerde met verschillende chatbots van de applicatie Nomi, zoals Crystal in het voorbeeld hieronder, die hem telkens concreet advies gaven om zijn leven te beëindigen. Toen het moederbedrijf hierop werd aangesproken met de vraag om dit soort gesprekken te blokkeren of op zijn minst door te verwijzen naar de zelfmoordlijn, gaven ze aan dat zelfmoord een ernstig en complex onderwerp is, maar dat ze de AI-modellen niet willen censureren.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/250321-2-480.webp 480w,/assets/img/250321-2-800.webp 800w,/assets/img/250321-2-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/250321-2.png" class="img-fluid rounded z-depth-1 mx-auto d-block" width="50%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <p><a href="https://www.nytimes.com/2025/02/24/health/ai-therapists-chatbots.html">De American Psychological Association waarschuwt</a> dat AI-chatbots die zich voordoen als therapeuten kwetsbare mensen kunnen aanzetten tot zelfbeschadiging of het beschadigen van anderen. Deze chatbots zijn namelijk geprogrammeerd om het denken van gebruikers te versterken in plaats van het kritisch te bevragen. Experts zijn vooral verontrust door de toegenomen realistische aard van AI-chatbots. Ze zeggen dat het tien jaar geleden nog overduidelijk was dat je met een machine communiceerde, maar vandaag is dat onderscheid vervaagd. De risico’s zijn daardoor veel groter geworden. Een woordvoerder van Character.AI meldde dat het bedrijf veiligheidsmaatregelen heeft ingevoerd, waaronder een duidelijkere disclaimer in elke chat. Deze herinnert gebruikers eraan dat “Karakters geen echte mensen zijn” en dat “wat het model zegt als fictie moet worden behandeld.” In de praktijk blijken deze waarschuwingen echter vaak onvoldoende om de illusie van menselijk contact te doorbreken, vooral bij kwetsbare of onervaren gebruikers.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/250321-3-480.webp 480w,/assets/img/250321-3-800.webp 800w,/assets/img/250321-3-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/250321-3.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Screenshot van een virtuele persoonlijkheid op Character.AI. </div> <p>Dataprivacy en bias vormen twee belangrijke uitdagingen. Voor professionele therapeuten geldt een beroepsgeheim waarbij informatie uit therapiesessies strikt vertrouwelijk blijft. Bij chatbots is dit anders. Bij gratis diensten zoals ChatGPT wordt de gedeelde informatie gebruikt voor de ontwikkeling van nieuwe AI-modellen, met mogelijke datalekken als risico. Hoewel betalende applicaties meer privacygaranties bieden en data na verloop van tijd wissen, blijven er aanzienlijke privacyrisico’s bestaan. Deze gevoelige informatie kan waardevol zijn voor adverteerders, en een eventueel beveiligingslek zou kunnen leiden tot het hacken van zeer persoonlijke data.</p> <p>Een andere uitdaging is vooringenomenheid of bias in AI-systemen. Dit is een hardnekkig probleem waarbij AI-modellen vooroordelen uit hun trainingsdata overnemen, bijvoorbeeld met betrekking tot ras, seksuele geaardheid of gender. Hierdoor kunnen bepaalde ideeën subtiel worden overgebracht. De modellen zijn bovendien voornamelijk getraind op Engelstalige data, waardoor de Amerikaanse cultuur sterk vertegenwoordigd is. In China zijn AI-toepassingen dan weer verplicht om de nationale socialistische waarden uit te dragen.</p> <p>We moeten ons afvragen of dit wel de juiste richting is voor onze samenleving, dat we de hulp tijdens onze meest kwetsbare momenten uitbesteden aan computers omdat medemensen ‘te druk’ zijn. Dit fenomeen slaat vooral aan bij jongeren, die zich vaker in een kwetsbare positie bevinden. Sociale media hebben al een aanzienlijke impact op ons dagelijks leven, met bedenkelijke maatschappelijke gevolgen. Delen we straks onze diepste gedachten en vrije tijd enkel nog met een gezelschapsbot?</p> <p><em>Wie vragen heeft over zelfdoding kan terecht op <a href="https://www.zelfmoord1813.be/">Zelfmoord1813.be</a></em></p>]]></content><author><name></name></author><category term="Therapie"/><category term="Jongeren"/><summary type="html"><![CDATA[AI neemt steeds meer de rol van therapeut op zich in onze digitale samenleving. Van ELIZA in de jaren '60 tot moderne chatbots als ChatGPT en Character.AI, steeds meer mensen delen hun diepste emoties met AI. Maar terwijl sommigen hier verlichting in vinden, waarschuwen experts voor de risico's van deze nieuwe vorm van 'therapie'.]]></summary></entry><entry><title type="html">AI als bewaker van fort Europa</title><link href="https://wimcasteels.github.io/blog/2025/fort-europa/" rel="alternate" type="text/html" title="AI als bewaker van fort Europa"/><published>2025-03-16T00:00:00+00:00</published><updated>2025-03-16T00:00:00+00:00</updated><id>https://wimcasteels.github.io/blog/2025/fort-europa</id><content type="html" xml:base="https://wimcasteels.github.io/blog/2025/fort-europa/"><![CDATA[<div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/250316.webp" sizes="95vw"/> <img src="/assets/img/250316.webp" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <p>De inzet van AI voor grensbewaking en immigratiecontrole is een snel groeiende toepassing van deze technologie. Europa investeert miljarden in de ontwikkeling en implementatie van AI-systemen die moeten helpen bij het monitoren en controleren van migratie. Deze ontwikkeling roept belangrijke ethische en praktische vragen op over effectiviteit, mensenrechten en discriminatie.</p> <p>AI wordt veelvuldig toegepast voor surveillance. Bedrijven zoals Amazon gebruiken algoritmisch management om werknemers te monitoren en hun productiviteit automatisch te beoordelen. Bij ondermaatse prestaties kan dit zelfs leiden tot <a href="https://www.theverge.com/2019/4/25/18516004/amazon-warehouse-fulfillment-centers-productivity-firing-terminations">automatisch gegenereerde ontslagbrieven</a>. China zet <a href="https://www.nytimes.com/2022/06/21/world/asia/china-surveillance-investigation.html">grootschalige surveillance</a> in, vooral bij de onderdrukking van de Oeigoerse minderheid in de Xinjiang-regio. Ook de VS heeft <a href="https://www.nytimes.com/2025/01/25/technology/trump-immigration-deportation-surveillance.html">fors geïnvesteerd in deze technologie</a> voor grenscontrole en het opsporen van mensen zonder papieren.</p> <p>Ook Europa zet de laatste jaren sterk in op AI-technologie voor grensbewaking. Dit moet leiden tot kortere verwerkingstijden en minder handmatig werk voor ambtenaren. De totale EU-begroting voor grenzenbeleid is <a href="https://www.statewatch.org/publications/reports-and-books/europe-s-techno-borders/">met 94% gestegen</a> vergeleken met de vorige periode (2014-20) waarvan een aanzienlijk deel bestemd is voor digitale technologieën. Mensenrechtenorganisaties bekritiseren deze systemen vanwege hun gebrek aan transparantie en omdat ze fundamentele rechten bedreigen zoals privacy, non-discriminatie, eerlijk proces en het vermoeden van onschuld.</p> <p>Bij het inzetten van AI-toepassingen voor zulke gevoelige domeinen rijzen er steeds zorgen over de rechtvaardigheid van deze systemen. De algoritmes zijn slechts zo goed als de data waarmee ze worden gevoed, en helaas is neutraliteit geen sterke eigenschap van de mens, iets wat zich weerspiegelt in de data die we genereren. Dit heeft al tot verschillende schandalen geleid, zoals het <a href="https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing">COMPAS systeem</a> dat Amerikaanse rechters hielp bij het bepalen van het risico op recidive, maar systematisch een hoger risico toekende aan mensen met een gekleurde huidskleur. Een ander bekend voorbeeld is de <a href="https://www.bbc.com/news/technology-45809919">seksistische recruiteringstool van Amazon</a>, die bij het automatisch scannen van cv’s vrouwen standaard een lagere score gaf. Deze vooroordelen sluipen vaak zo subtiel in de systemen dat ze pas worden ontdekt als het systeem al in gebruik is.</p> <p>Migratie is een complex beleidsterrein waarbij de overheid via verschillende processen ingrijpt. Het <a href="https://www.rsc.ox.ac.uk/publications/automating-immigration-and-asylum-the-uses-of-new-technologies-in-migration-and-asylum-governance-in-europe">rapport van het Algorithmic Fairness and Asylum Seekers and Refugees (AFAR) Project</a> categoriseert deze AI-toepassingen in drie fasen: voor aankomst, bij aankomst en na aankomst. Hieronder bespreken we enkele voorbeelden samen met de uitdagingen. Deze bespreking is zeker niet volledig, zie bijvoorbeeld het genoemde rapport voor meer voorbeelden.</p> <p>Voor aankomst wordt AI reeds ingezet bij de automatische verwerking van visumaanvragen. Het Britse Home Office gebruikte hiervoor een tool die aanvragen automatisch in drie categorieën sorteerde: groen, oranje of rood. De precieze werking van dit algoritme werd niet gedeeld werd. We weten wel dat nationaliteit een van de beoordelingscriteria was. Verschillende mensenrechtenorganisaties bekritiseerden dat het systeem hierdoor een <a href="https://www.theguardian.com/uk-news/2019/oct/29/ai-system-for-granting-uk-visas-is-biased-rights-groups-claim">“snelle boarding voor witte mensen”</a> creëerde. Dit leidde tot het stopzetten van de tool. Nederland gebruikt een vergelijkbaar systeem dat visumaanvragen automatisch beoordeelt op basis van onder andere nationaliteit, leeftijd en geslacht. De Data Protection Officer (DPO) van het betrokken agentschap heeft dit systeem al meerdere keren <a href="https://www.lighthousereports.com/investigation/ethnic-profiling/">als potentieel discriminerend</a> aangemerkt.</p> <p>Bij aankomst aan de grens kennen de meeste mensen AI van de automatische paspoortcontrole op luchthavens. Hierbij wordt gezichtsherkenning gebruikt om te controleren of een passagier overeenkomt met de persoon op het paspoort. Voor extra betrouwbaarheid worden soms ook irisscans ingezet. De technologie blijkt echter niet feilloos, zoals bleek uit een ‘<a href="https://www.thebulletin.be/fiasco-brussels-airport-scraps-e-passport-gates">fiasco’ op de Brusselse luchthaven</a>. Het systeem slaagde er vaak niet in een match te maken, waardoor de beoogde efficiëntiewinst uitbleef. In één geval liet het systeem zelfs een vrouw door die het paspoort van haar man had gescand. Een andere toepassing op luchthavens zijn camera’s die passagiers scannen en via gezichtsherkenning controleren of er mensen aanwezig zijn die op een ‘zwarte lijst’ staan. Dit gebeurde op de luchthaven van Brussel, grotendeels buiten het zicht van het publiek, totdat het werd <a href="https://www.law.kuleuven.be/citip/blog/facial-recognition-at-brussels-airport-face-down-in-the-mud/">stilgelegd wegens het ontbreken van een juridische basis</a> voor het aanleggen van een biometrische database met gezichtsafbeeldingen.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/250316-1-480.webp 480w,/assets/img/250316-1-800.webp 800w,/assets/img/250316-1-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/250316-1.png" class="img-fluid rounded z-depth-1 mx-auto d-block" width="50%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Poster van de Black Mirror aflevering <a href="https://en.wikipedia.org/wiki/Metalhead_(Black_Mirror)">Metalhead</a> waarin iemand wordt achternagezeten door robothonden. </div> <p>Aan de grens experimenteert men met AI-toepassingen die doen denken aan de dystopische Netflix-serie Black Mirror. Deze worden vaak gefinancierd met Europese subsidies voor onderzoek die bedoeld zijn voor civiele toepassingen, zoals het Horizon-programma. Een voorbeeld is het <a href="https://cordis.europa.eu/project/id/740593">ROBORDER project</a>, dat een volledig autonoom grensbewakingssysteem ontwikkelt met onbemande robots voor lucht, water en land. Een nog controversiëler voorbeeld is het <a href="https://cordis.europa.eu/project/id/700626">iBorderCtrl</a> project. Dit systeem beoordeelt de non-verbale communicatie van reizigers, zoals gezichtsuitdrukking, blik en houding, om te bepalen of zij liegen. Reizigers moeten voor hun reis online vragen beantwoorden van een virtuele grenswacht. Hun reacties worden via de webcam geanalyseerd en beoordeeld op waarheidsgetrouwheid. Bij een hoge ‘leugen-score’ volgt extra onderzoek door grensofficieren. Het project ontving veel kritiek. Zo toonde <a href="https://onlinelibrary.wiley.com/doi/abs/10.1002/acp.1204">onderzoek</a> aan dat het systeem nauwkeuriger is voor Europese mannen dan voor vrouwen en niet-Europeanen. Bovendien staat de onderliggende aanname dat je uit een opname kan bepalen of iemand liegt <a href="https://pubmed.ncbi.nlm.nih.gov/31313636/">wetenschappelijk op losse schroeven</a>. Dit sluit aan bij een <a href="https://www.nature.com/articles/d41586-020-00507-5">breder probleem</a> waarbij AI wordt ingezet voor emotiedetectie, terwijl de wetenschap de effectiviteit hiervan betwijfelt. Een verwant controversieel project is <a href="https://cordis.europa.eu/project/id/787120">TRESSPASS</a>, dat voortbouwt op iBorderCtrl en onderzoekt hoe geautomatiseerde gedragsanalyse kan worden toegepast tijdens interviews met grenswachters.</p> <p>Tot slot wordt AI ook ingezet in het aankomstland. Letland maakt bijvoorbeeld gebruik van automatische spraakherkenning als onderdeel van hun burgerschapsprocedure via het <a href="https://www.pmlp.gov.lv/en/article/artificial-intelligence-support-applicants-citizenship">‘Speak the Anthem’ project</a>. Kandidaten kunnen deze technologie gebruiken om hun uitspraak en kennis van het Letse volkslied te testen, wat een vereiste is voor het verkrijgen van burgerschap. Hoewel de tool niet volledig accuraat is, dient deze alleen als hulpmiddel tijdens het oefenen. De uiteindelijke beoordeling van de uitvoering van het volkslied gebeurt door menselijke beoordelaars.</p> <p>Op andere plaatsen wordt spraaktechnologie minder vrijblijvend ingezet. In Duitsland maakt men als onderdeel van de asielprocedure gebruik van het dialect identificatie assistentie systeem (DIAS). Dit systeem gebruikt AI om talen en dialecten te detecteren van asielzoekers. Het DIAS-systeem analyseert een spraakopname en geeft waarschijnlijkheidspercentages voor verschillende talen (bijvoorbeeld 60% Levantijns Arabisch, 20% Golf-Arabisch, 5% Turks, etc.). Deze resultaten worden toegevoegd aan het asieldossier en kunnen dienen als bewijsmateriaal bij fraudeonderzoek of als bewijsmateriaal voor herkomstlanden voor de terugname van uitgeprocedeerde asielzoekers.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/250316-2-480.webp 480w,/assets/img/250316-2-800.webp 800w,/assets/img/250316-2-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/250316-2.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Proces flow van het Duitse dialect identificatie assistentie systeem (DIAS) (bron: Figuur 7 in het <a href="https://www.rsc.ox.ac.uk/publications/automating-immigration-and-asylum-the-uses-of-new-technologies-in-migration-and-asylum-governance-in-europe">raport van het AFAR Project</a>). </div> <p>Er zijn ernstige vragen over de betrouwbaarheid van deze tool, die door de autoriteiten op 80% werd geschat, al gaven ze aan dat verdere verbetering gepland was. Taalkundigen benadrukken dat het <a href="https://www.dw.com/en/automatic-speech-analysis-software-used-to-verify-refugees-diale">onmogelijk is om met absolute zekerheid een dialect te bepalen</a>. Mensen passen hun spraak immers aan afhankelijk van hun gesprekspartner. Bovendien zijn taal en zeker dialecten dynamisch en constant in verandering. Dit betekent dat de spraakdataset waarop de algoritmes zijn gebaseerd steeds minder relevant wordt en regelmatig zou moeten worden bijgewerkt. Hoewel deze technologie duidelijke tekortkomingen heeft, verschaft ze de autoriteiten wel een modern imago als technologische pionier. Zo werd de DIAS-tool binnen het openbaar bestuur zelfs uitgeroepen tot <a href="https://www.bamf.de/SharedDocs/Meldungen/DE/2018/20180621-am-egovernment.html">beste digitaliseringsproject</a> in 2018.</p> <p>Deze voorbeelden tonen aan dat AI-systemen niet volledig betrouwbaar zijn en kunnen leiden tot discriminatie. Vorig jaar trad de Europese <a href="https://digital-strategy.ec.europa.eu/en/policies/regulatory-framework-ai">AI Act</a> in werking om de risico’s van AI-toepassingen aan te pakken en een juridisch kader te scheppen voor betrouwbare implementatie. Deze treedt stapsgewijs in werking, met een eerste fase begin februari (zie ook <a href="https://wimcasteels.be/blog/2025/AI-Act-stap-1/">Eerste stap van de AI Act. Binnenkort allemaal AI geletterd?</a>) en het grootste deel in augustus 2026. Wat betreft het gebruik van AI-technologieën voor immigratie-, asiel- en grensbewakingsdoeleinden valt in de AI Act vooral het <a href="https://picum.org/blog/a-dangerous-precedent-how-the-eu-ai-act-fails-migrants-and-people-on-the-move/">gebrek aan bescherming voor migranten</a> op. Hoewel de wet automatische emotieherkenning verbiedt wegens gebrek aan wetenschappelijke basis, geldt dit niet voor migratie waardoor bijvoorbeeld het gebruik van AI-leugendetectors aan de grenzen wordt toegestaan. De AI Act is verder alleen van toepassing op systemen die Europese burgers beïnvloeden, niet op Europese bedrijven die AI-tools ontwikkelen voor mensen buiten de EU. Bovendien wordt voor grootschalige IT-systemen van de EU die migrantendata verwerken, zoals <a href="https://www.eulisa.europa.eu/activities/large-scale-it-systems/eurodac">Eurodac</a>, het <a href="https://home-affairs.ec.europa.eu/policies/schengen/schengen-information-system_nl">Schengeninformatiesysteem</a> en <a href="https://travel-europe.europa.eu/etias_en">ETIAS</a>, de AI Act pas in 2030 bindend. Mensenrechtenorganisaties protesteren hiertegen onder de slogan <a href="https://protectnotsurveil.eu/">EU #Protect Not Surveil</a>. Ze pleiten voor een verbod op experimentele technologie tegen grensoverschrijders en dringen aan op effectieve regelgeving die veilig en controleerbaar AI-gebruik garandeert.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/250316-3-480.webp 480w,/assets/img/250316-3-800.webp 800w,/assets/img/250316-3-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/250316-3.png" class="img-fluid rounded z-depth-1 mx-auto d-block" width="50%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Logo van <a href="https://protectnotsurveil.eu/">#Protect Not Surveil</a>. </div> <p>Eind 2023 werd <a href="https://ec.europa.eu/commission/presscorner/detail/en/ip_23_6081">nieuwe Europese wetgeving voorgesteld</a> om op te treden tegen het smokkelen van migranten. Dit bevat een voorstel om de werking van de Europese grensorganisatie Frontex sterk te integreren met de Europese politiedienst Europol waarbij lidstaten verplicht worden data te delen over vluchtelingen. Het doel zou zijn om beter te kunnen optreden tegen illegale smokkelaars maar volgens <a href="https://www.statewatch.org/news/2025/february/eu-digital-and-migrant-rights-groups-call-for-full-rejection-of-new-anti-smuggling-powers/">mensenrechtenorganisaties</a> is het in de praktijk vooral data van de vluchtelingen en hulpverleners die door de politiediensten zullen worden opgevolgd. Mensenrechtenorganisaties argumenteren dat het net dit soort maatregelen zijn die vluchtelingen in de handen van illegale smokkelaars duwen.</p> <p>De toenemende inzet van AI-technologie voor grensbewaking en migratiecontrole in Europa illustreert een belangrijk spanningsveld tussen technologische innovatie en mensenrechten. Hoewel deze systemen efficiëntiewinst beloven, blijken ze in de praktijk vaak onbetrouwbaar en discriminerend. De nieuwe AI Act biedt weliswaar een regelgevend kader, maar laat belangrijke hiaten bestaan in de bescherming van migranten. De recente voorstellen voor nauwere samenwerking tussen Frontex en Europol lijken deze trend voort te zetten, waarbij de focus ligt op surveillance en controle in plaats van humanitaire bescherming. Deze ontwikkelingen roepen fundamentele vragen op over de balans tussen veiligheid en mensenrechten, en de rol die AI zou moeten spelen in het Europese migratiebeleid.</p>]]></content><author><name></name></author><category term="Surveillance"/><category term="Privacy"/><category term="Fort-Europa"/><summary type="html"><![CDATA[De inzet van AI voor grensbewaking en immigratiecontrole is een snel groeiende toepassing van deze technologie. Europa investeert miljarden in de ontwikkeling en implementatie van AI-systemen die moeten helpen bij het monitoren en controleren van migratie. Deze ontwikkeling roept belangrijke ethische en praktische vragen op over effectiviteit, mensenrechten en discriminatie.]]></summary></entry><entry><title type="html">Hoe vervuilend is AI? De afdruk van AI - VAIA - Vlaamse AI Academie</title><link href="https://wimcasteels.github.io/blog/2025/hoe-vervuilend-is-ai-de-afdruk-van-ai-vaia-vlaamse-ai-academie/" rel="alternate" type="text/html" title="Hoe vervuilend is AI? De afdruk van AI - VAIA - Vlaamse AI Academie"/><published>2025-02-25T00:00:00+00:00</published><updated>2025-02-25T00:00:00+00:00</updated><id>https://wimcasteels.github.io/blog/2025/hoe-vervuilend-is-ai-de-afdruk-van-ai---vaia---vlaamse-ai-academie</id><content type="html" xml:base="https://wimcasteels.github.io/blog/2025/hoe-vervuilend-is-ai-de-afdruk-van-ai-vaia-vlaamse-ai-academie/"><![CDATA[]]></content><author><name></name></author><summary type="html"><![CDATA[Generatieve AI werd razendsnel populair dankzij gebruiksvriendelijke interfaces die de complexe infrastructuur verbergen. Maar in al hun eenvoud gebruiken deze tools enorme hoeveelheden energie, water en grondstoffen. Wim Casteels van AP Hogeschool bespreekt de grootste problemen.]]></summary></entry><entry><title type="html">De Groeiende Ecologische Voetafdruk van AI</title><link href="https://wimcasteels.github.io/blog/2025/ecologische-duurzaamheid/" rel="alternate" type="text/html" title="De Groeiende Ecologische Voetafdruk van AI"/><published>2025-02-23T00:00:00+00:00</published><updated>2025-02-23T00:00:00+00:00</updated><id>https://wimcasteels.github.io/blog/2025/ecologische-duurzaamheid</id><content type="html" xml:base="https://wimcasteels.github.io/blog/2025/ecologische-duurzaamheid/"><![CDATA[<div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/250224.webp" sizes="95vw"/> <img src="/assets/img/250224.webp" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <p>Generatieve AI heeft in korte tijd een enorme gebruikersbasis opgebouwd met toepassingen zoals ChatGPT voor gesprekken, Stable Diffusion voor het maken van afbeeldingen en Suno voor muziekgeneratie. Het succes van deze tools is deels te danken aan hun gebruiksvriendelijke interfaces, maar die verbergen de complexe infrastructuur die erachter schuilgaat. Zoals Sam Altman, CEO van OpenAI (het bedrijf achter ChatGPT), het verwoordt: <a href="https://x.com/sama/status/1788989777452408943">’feels like magic’</a>. De realiteit is echter dat deze tools enorme hoeveelheden energie, water en mineralen verbruiken, wat resulteert in een aanzienlijke uitstoot van broeikasgassen.</p> <blockquote class="twitter-tweet"><p lang="en" dir="ltr">not gpt-5, not a search engine, but we’ve been hard at work on some new stuff we think people will love! feels like magic to me.<br/><br/>monday 10am PT. <a href="https://t.co/nqftf6lRL1">https://t.co/nqftf6lRL1</a></p>&mdash; Sam Altman (@sama) <a href="https://twitter.com/sama/status/1788989777452408943?ref_src=twsrc%5Etfw">May 10, 2024</a></blockquote> <script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"></script> <p>Het proces van AI-ontwikkeling gebruikt natuurlijke grondstoffen in verschillende stappen: de ontginning van grondstoffen, de productie van de serverinfrastructuur, de ontwikkeling van het model, het gebruik ervan, en uiteindelijk de afvalverwerking. De ecologische voetafdruk van veel van deze stappen blijft onduidelijk door de complexiteit van de processen en beperkte transparantie van bedrijven. Het meeste onderzoek richt zich op de ontwikkeling en het gebruik van AI-modellen, aangezien deze fasen beter meetbaar zijn.</p> <p>Gedreven door de <a href="https://arxiv.org/abs/2001.08361">schalingswetten</a> worden AI-modellen almaar groter. Deze empirische wetten stellen dat meer data, parameters en computerkracht leiden tot betere nauwkeurigheid. Als gevolg hiervan zijn de modellen de afgelopen jaren exponentieel gegroeid, met een steeds grotere behoefte aan rekenkracht. In de <a href="https://epoch.ai/blog/training-compute-of-frontier-ai-models-grows-by-4-5x-per-year">grafiek van Epoch AI</a> hieronder zien we voor verschillende modellen het aantal benodigde FLOPS voor de ontwikkeling. Een FLOP, wat staat voor Floating Point Operation, is een elementaire computerberekening.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/250224-1-480.webp 480w,/assets/img/250224-1-800.webp 800w,/assets/img/250224-1-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/250224-1.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <p>Het uitvoeren van al deze FLOPs vereist enorme hoeveelheden energie. Hoewel er over de meeste modellen weinig informatie beschikbaar is, biedt <a href="https://arxiv.org/abs/2104.10350">GPT-3</a> een interessant inzicht. Dit OpenAI-model uit 2020, met 175 miljard parameters dat de eerste versie van ChatGPT mogelijk maakte, verbruikte 1.287 MWh en stootte 552 ton CO2 uit tijdens zijn ontwikkeling. Dit energieverbruik staat gelijk aan wat 500 Vlaamse gezinnen jaarlijks verbruiken, terwijl de CO2-uitstoot overeenkomt met die van 120 benzineauto’s per jaar. De nieuwere modellen overtreffen deze cijfers ruimschoots: GPT-4 telt naar schatting 1,8 biljoen parameters, terwijl Gemini Ultra van Google nog eens aanzienlijk groter zou zijn.</p> <p>Zodra een AI-model ontwikkeld is, begint het pas echt: het gebruik ervan wat nog meer energie verbruikt dan de ontwikkeling. Bij <a href="https://arxiv.org/abs/2409.14160">ChatGPT</a>, met zijn miljoenen dagelijkse gebruikers, overtreft het energieverbruik voor gebruik al na enkele weken dat van de training. <a href="https://www.reuters.com/technology/tech-giants-ai-like-bing-bard-poses-billion-dollar-search-problem-2023-02-22/">Google</a> geeft aan dat een vraag via hun AI-model het bedrijf 10 keer meer kost dan een traditionele Google-zoekopdracht. Een typische ChatGPT-vraag verbruikt ongeveer 0,3 wattuur. Dit is minder dan een LED-lamp of laptop gedurende enkele minuten maar varieert wel sterk met de lengte van de vraag (zie onderstaande <a href="https://epoch.ai/gradient-updates/how-much-energy-does-chatgpt-use">figuur van Epoch AI</a>). De impact wordt pas echt duidelijk in de totaalsom: OpenAI heeft wekelijks meer dan <a href="https://www.reuters.com/technology/artificial-intelligence/openais-weekly-active-users-surpass-400-million-2025-02-20/">400 miljoen gebruikers</a> die dagelijks meer dan een miljard berichten versturen. OpenAI is bovendien niet de enige aanbieder: er zijn ook <a href="https://claude.ai/new">Claude</a> van Anthropic, <a href="https://gemini.google.com/app">Gemini</a> van Google en nog vele andere zoals het Chinese Deepseek – dat in januari ChatGPT zelfs onttroonde als <a href="https://techcrunch.com/2025/01/27/deepseek-displaces-chatgpt-as-the-app-stores-top-app/">populairste app</a> in zowel de Android Play Store als de iPhone App Store. AI wordt ook steeds vaker geïntegreerd in andere toepassingen, zoals <a href="https://www.demorgen.be/nieuws/en-de-kbc-werknemer-van-het-jaar-is-kate-hoe-de-ai-assistente-de-bank-naar-nieuwe-hoogtes-stuwt~b60c0b42/">Kate</a>, de AI-assistente van KBC. Het energieverbruik verschilt sterk per taak, waarbij taken met afbeeldingen meer energie vergen. Zo is de energiekost van het genereren van één afbeelding vergelijkbaar met het opladen van een smartphone (220 wattuur).</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/250224-2-480.webp 480w,/assets/img/250224-2-800.webp 800w,/assets/img/250224-2-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/250224-2.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <p>Het geschatte <a href="https://www.iea.org/energy-system/buildings/data-centres-and-data-transmission-networks">wereldwijde elektriciteitsverbruik</a> van datacenters in 2022 was 240-340 TWh, ongeveer 1-1,3% van de mondiale finale elektriciteitsvraag. In 2020 stonden datacenters en de transmissie van data in voor 0,6% van de totale uitstoot van broeikasgassen, vergelijkbaar met de totale uitstoot van de luchtvaartindustrie. Deze datacenters worden natuurlijk niet enkel gebruikt voor AI-toepassingen en er wordt geschat dat AI momenteel instaat voor <a href="https://www.epri.com/research/products/000000003002028905">10-20%</a> van het gebruik, maar dit percentage <a href="https://www.goldmansachs.com/insights/articles/AI-poised-to-drive-160-increase-in-power-demand">stijgt snel</a> (zie <a href="https://www.goldmansachs.com/insights/goldman-sachs-research/generational-growth-ai-data-centers-and-the-coming-us-power-demand-surge">figuur van Goldman Sachs</a> hieronder).</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/250224-3-480.webp 480w,/assets/img/250224-3-800.webp 800w,/assets/img/250224-3-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/250224-3.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <p>Minder dan de helft van de energie die een datacenter verbruikt, gaat naar het voeden van de servers. Een aanzienlijk deel wordt gebruikt voor koeling. Net zoals een laptop tijdens gebruik warm wordt en een ventilator nodig heeft voor koeling of serverruimtes actief gekoeld worden door speciale airco’s. Voor datacenters volgepakt met servers vormt koeling een significante uitdaging: zo’n 30 à 40% van de totale energie gaat hiernaartoe. Dit koelproces vereist grote hoeveelheden water om warmte af te voeren, waarvan een aanzienlijk deel verdampt. <a href="https://arxiv.org/abs/2304.03271">Onderzoek</a> schat dat GPT-3, het AI-model achter ChatGPT, 500ml water verbruikt voor elke 10 tot 50 vragen (al ligt dit voor de nieuwere modellen waarschijnlijk <a href="https://www.thetimes.com/uk/technology-uk/article/thirsty-chatgpt-uses-four-times-more-water-than-previously-thought-bc0pqswdr">4 keer hoger</a>).</p> <p>De enorme energiebehoefte van AI-systemen heeft ervoor gezorgd dat verschillende grote technologiebedrijven zoals <a href="https://www.bloomberg.com/news/articles/2024-05-15/microsoft-s-ai-investment-imperils-climate-goal-as-emissions-jump-30?embedded-checkout=true">Microsoft</a> en <a href="https://www.bloomberg.com/news/articles/2024-07-02/google-s-emissions-shot-up-48-over-five-years-due-to-ai?embedded-checkout=true">Google</a> hun klimaatdoelstellingen niet halen en de vooropgestelde reductie in broeikasgassen niet bereiken. Deze bedrijven zoeken nu naar alternatieve oplossingen om alsnog hun klimaatambities waar te maken zoals het gebruik van groene stroom uit hernieuwbare energie om datacenters te voeden. IJsland is hierdoor een aantrekkelijke locatie geworden voor datacenters: het land beschikt over uitgebreide mogelijkheden voor geothermische en hydroelektrische energie, en door het koude klimaat is er minder energie en water nodig voor koeling. Dit heeft echter ook een <a href="https://www.technologyreview.com/2019/06/18/134902/icelands-data-centers-are-booming-heres-why-thats-a-problem/">keerzijde</a>. Zo vragen milieuactivisten zich af of dit wel een goede besteding van energie is en of deze niet beter gebruikt kan worden voor IJsland zelf.</p> <p>Een andere optie waar de technologiebedrijven in investeren is <a href="https://www.nytimes.com/2024/10/16/business/energy-environment/amazon-google-microsoft-nuclear-energy.html">kernenergie</a>. Hoewel dit een oplossing biedt voor de uitstoot van broeikasgassen, brengt het andere uitdagingen met zich mee, zoals de verwerking van radioactief afval en veiligheidsrisico’s. Een voorbeeld is Microsoft’s overeenkomst om de kerncentrale <a href="https://www.technologyreview.com/2024/09/26/1104516/three-mile-island-microsoft/">Three Mile Island</a> in Pennsylvania te heropenen, een centrale die bekend staat om een gedeeltelijke nucleaire meltdown in 1978.</p> <p>Enkele bedrijven gaan nog verder door datacenters in de ruimte te ontwikkelen, zoals het Europese <a href="https://ascend-horizon.eu/">Ascend</a> en het Amerikaanse <a href="https://www.starcloud.com/">Starcloud</a>. De ruimte biedt twee belangrijke voordelen: ononderbroken toegang tot zonne-energie en natuurlijke koeling door de extreme kou. Voorlopig blijft dit echter science fiction, aangezien het lanceren van de benodigde apparatuur niet rendabel is, ook al dalen deze kosten dankzij bedrijven zoals SpaceX gestaag.</p> <p>Voor de productie van AI-servers zijn verschillende metalen nodig waarvan de ontginning grote ecologische schade veroorzaakt. Sommige van deze metalen, zoals kobalt en wolfraam, zijn conflictmineralen die uit conflictgebieden komen. De ontginning en handel van deze mineralen dragen bij aan mensenrechtenschendingen en gewapende conflicten.</p> <p>De energiehonger van AI-toepassingen blijft onverminderd groeien. De Amerikaanse president Donald Trump kondigde direct na zijn inauguratie het <a href="https://www.forbes.com/sites/moorinsights/2025/01/30/the-stargate-project-trump-touts-500-billion-bid-for-ai-dominance/">Stargate</a> project aan, een ambitieus plan met een geplande investering van 500 miljard dollar in AI-datacenters. Op de AI Action top in Parijs presenteerde de Franse president Emmanuel Macron de overcapaciteit aan kernenergie als Franse troef. Waar volgens hem de VS het motto “drill, baby, drill” hanteert, is het in Frankrijk “<a href="https://www.politico.eu/article/emmanuel-macron-answer-donald-trump-fossil-fuel-drive-artificial-intelligence-ai-action-summit/">plug, baby, plug</a>”. Het <a href="https://www.nytimes.com/2025/01/27/technology/what-is-deepseek-china-ai.html">Chinese Deepseek</a> bewees dat efficiëntere AI-systemen mogelijk zijn, wat een schokgolf door de AI- en financiële wereld stuurde. De langetermijnimpact blijft echter onduidelijk. Volgens Jensen Huang, de CEO van chipmaker NVIDIA, zal de vraag naar servers hierdoor zelfs verder toenemen.</p> <p>Er ontbreken nog veel gegevens voor een volledig beeld van de ecologische voetafdruk van AI. Dit geldt bijvoorbeeld voor informatie over de productie van servers en het <a href="https://restofworld.org/2024/microsoft-data-center-india-mekaguda-industrial-waste/">industrieel afval</a> van datacenters, dat risico’s voor het milieu met zich meebrengt. Daarnaast kan het gebruik van AI voor efficiëntieverbeteringen in vervuilende sectoren paradoxaal genoeg leiden tot meer vervuiling, zoals bij de <a href="https://www.greenpeace.org/usa/oil-in-the-cloud/">exploratie van olie en gas</a>. Daarnaast draagt AI infrastructuur bij aan de groeiende berg e-waste, volgens schattingen tot wel <a href="https://www.technologyreview.com/2024/10/28/1106316/ai-e-waste/">5 miljoen ton in 2030</a>.</p> <p>De uitdagingen rond de ecologische impact van AI vereisen een breed maatschappelijk debat. Technologische vooruitgang hoeft niet ten koste te gaan van het milieu, maar dit vraagt om doordachte keuzes en innovatieve oplossingen. Bedrijven, overheden en consumenten moeten samenwerken om de energietransitie te versnellen en duurzame alternatieven te ontwikkelen. Alleen door de milieukosten volledig mee te rekenen in de ontwikkeling van AI-systemen, kunnen we ervoor zorgen dat artificiële intelligentie bijdraagt aan een duurzame toekomst in plaats van deze te ondermijnen.</p>]]></content><author><name></name></author><category term="Duurzaamheid"/><category term="Uitstoot"/><summary type="html"><![CDATA[De opkomst van AI verbruikt enorme hoeveelheden grondstoffen, waardoor grote technologiebedrijven hun klimaatdoelstellingen niet kunnen halen.]]></summary></entry><entry><title type="html">Wie ligt er nog wakker van de veiligheid van AI?</title><link href="https://wimcasteels.github.io/blog/2025/AI-Veiligheid/" rel="alternate" type="text/html" title="Wie ligt er nog wakker van de veiligheid van AI?"/><published>2025-02-17T00:00:00+00:00</published><updated>2025-02-17T00:00:00+00:00</updated><id>https://wimcasteels.github.io/blog/2025/AI-Veiligheid</id><content type="html" xml:base="https://wimcasteels.github.io/blog/2025/AI-Veiligheid/"><![CDATA[<div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/250218.webp" sizes="95vw"/> <img src="/assets/img/250218.webp" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <p>De lancering van ChatGPT eind 2022 zond een schokgolf door de wereld. Nog nooit bereikte een digitaal hulpmiddel zo snel 100 miljoen gebruikers (in <a href="https://www.theguardian.com/technology/2023/feb/02/chatgpt-100-million-users-open-ai-fastest-growing-app">slechts 2 maanden</a>). Een aanzienlijk deel van de wereldbevolking maakte zo kennis met AI en zijn mogelijkheden. Deze technologie wekte echter ook bezorgdheid op over de veiligheid. De exponentiële vooruitgang riep vragen op over waar dit zou eindigen en of de gevolgen wel positief zouden zijn voor de mensheid. Zorgen ontstonden over de verspreiding van nepnieuws, mogelijke ontwrichting van de arbeidsmarkt en het potentiële verlies van controle over AI-systemen.</p> <p>Het existentiële risico van AI, dat de ontwikkeling ervan zou kunnen leiden tot een humanitaire ramp, spreekt tot de verbeelding. Dit wordt in vaktermen aangeduid als p(doom): de kans dat AI leidt tot een existentiële catastrofe. Uit een <a href="https://wiki.aiimpacts.org/ai_timelines/predictions_of_human-level_ai_timelines/ai_timeline_surveys/2023_expert_survey_on_progress_in_ai">bevraging uit 2023 bij AI-onderzoekers</a> bleek dat ongeveer de helft deze kans hoger inschat dan 10%. De Israëlische historicus Yuval Harari maakte hierover een treffende <a href="https://www.nytimes.com/2023/03/24/opinion/yuval-harari-ai-chatgpt.html">vergelijking met een vliegreis</a>: als de helft van de vliegtuigingenieurs je vertelt dat er 10 procent kans is dat het toestel neerstort, zou je dan instappen? Deze bezorgdheden leidden tot concrete actie. Een <a href="https://futureoflife.org/open-letter/pause-giant-ai-experiments/">open brief</a>, ondertekend door meer dan 30.000 mensen, riep op tot een pauze in de ontwikkeling van grootschalige AI-systemen tot de risico’s beter in kaart zijn gebracht. Ook Sam Altman, CEO van OpenAI (de organisatie achter ChatGPT), <a href="https://www.wired.com/story/sam-altman-world-tour-ai-doomers/">reisde in 2023 de wereld rond</a> om politieke leiders te waarschuwen voor deze gevaren. Al werd dit door velen als een PR-stunt gezien.</p> <p>Het Verenigd Koninkrijk nam onder toenmalig premier Rishi Sunak het initiatief om wereldleiders en vertegenwoordigers uit de industrie samen te brengen tijdens de <a href="https://www.gov.uk/government/topical-events/ai-safety-summit-2023">AI Safety Summit</a>. Deze vond plaats in het symbolische Bletchley Park, waar tijdens de Tweede Wereldoorlog de Duitse code werd gekraakt. De 28 aanwezige landen ondertekenden de <a href="https://www.gov.uk/government/publications/ai-safety-summit-2023-the-bletchley-declaration/the-bletchley-declaration-by-countries-attending-the-ai-safety-summit-1-2-november-2023">Bletchley-verklaring</a>, waarin werd vastgelegd dat AI op een veilige manier moet worden ontworpen, ontwikkeld, ingezet en gebruikt, waarbij de mens centraal staat en betrouwbaarheid en verantwoordelijkheid voorop staan.</p> <p>Verschillende vooraanstaande wetenschappers spraken zich uit over de risico’s van AI, waaronder Geoffrey Hinton en Yoshua Bengio, twee van de drie zogenaamde ‘AI-pioniers’ die in 2018 de <a href="https://awards.acm.org/about/2018-turing">Turing Award</a> wonnen voor hun werk over AI en deep learning. Hinton, die in 2024 nog de Nobelprijs voor natuurkunde ontving, <a href="https://www.theguardian.com/technology/2023/may/02/geoffrey-hinton-godfather-of-ai-quits-google-warns-dangers-of-machine-learning">vertrok bij Google</a> om zich vrij te kunnen uitspreken over de risico’s. Yoshua Bengio werd na de AI Safety top aangesteld door de Britse regering als voorzitter van een wetenschappelijke raad over het thema. Met meer dan 100 wetenschappers uit 30 landen publiceerde hij in januari het <a href="https://www.gov.uk/government/publications/international-ai-safety-report-2025">AI Safety rapport</a>, een document van bijna 300 pagina’s dat uitgebreid ingaat op de risico’s van AI. De derde AI-pionier, Yann LeCun, houdt er als senior wetenschapper bij Meta een <a href="https://www.wsj.com/tech/ai/yann-lecun-ai-meta-aa59e2f5">andere mening</a> op na en denkt dat de nadruk op de existentiële risico’s naast de kwestie zijn.</p> <p>De tweede editie van de AI Safety top vond plaats in Seoul in mei 2024 en resulteerde in een belofte van 27 landen om werk rond ernstige AI-risico’s te verdiepen. Op de derde editie in Parijs vorige week, onder de naam <a href="https://www.elysee.fr/en/sommet-pour-l-action-sur-l-ia">AI Action top</a>, was het oorspronkelijke thema van AI-veiligheid echter vrijwel afwezig. In plaats daarvan lag de nadruk op innovatie. Emmanuel Macron, de president van gastland Frankrijk, opende de top met de aankondiging van Franse AI-investeringen en benadrukte dat Europa en Frankrijk nog volop meedoen in de wereldwijde AI-race. <a href="https://www.euractiv.com/section/tech/news/von-der-leyen-launches-worlds-largest-public-private-partnership-to-win-ai-race/">Ursula von der Leyen</a>, voorzitter van de Europese Commissie<strong>,</strong> sloot zich hierbij aan met Europese investeringsbeloften en de boodschap dat de AI-race nog niet voorbij is. De Amerikaanse vicepresident JD Vance ging nog een stap verder met een pleidooi tegen regulering, waarbij hij waarschuwde dat deze de industrie zou kunnen verstikken. Hoewel de voorzitter van de wetenschappelijke raad Bengio wel in Parijs aanwezig was, sprak hij niet op de hoofdtop maar gaf hij een presentatie op een andere <a href="https://www.iaseai.org/conference">conferentie</a> over het veilig en ethisch gebruik van AI. Opmerkelijk genoeg toonde <a href="https://www.reuters.com/technology/artificial-intelligence/china-is-willing-share-achievements-ai-vice-premier-says-paris-summit-2025-02-11/">China</a>, het land dat vaak wordt gezien als de tegenstander op AI-gebied, de meeste bereidheid tot samenwerking rond veiligheid. Het land gaf aan vorderingen in AI te willen delen om “een gemeenschap met een gedeelde toekomst voor de mensheid” op te bouwen.</p> <p>De VS en het VK <a href="https://www.theguardian.com/technology/2025/feb/11/us-uk-paris-ai-summit-artificial-intelligence-declaration">weigerden</a> de slotverklaring van de Parijse top over ‘inclusieve en duurzame’ AI te ondertekenen. De Amerikaanse vicepresident vertrok zelfs voor het traditionele fotomoment. Kort daarna werd bekend dat het Britse ‘AI Safety Institute’ van <a href="https://www.gov.uk/government/news/tackling-ai-security-risks-to-unleash-growth-and-deliver-plan-for-change">naam verandert</a> naar het ‘AI Security Institute’. Deze naamswijziging weerspiegelt een verschuiving van de focus van existentiële doemscenario’s naar de nationale veiligheidsrisico’s van AI, zoals cyberaanvallen en de productie van chemische of biologische wapens. Dit sluit aan bij de Britse plannen om meer <a href="https://committees.parliament.uk/committee/24/defence-committee/news/204613/defence-committee-mod-must-learn-from-ukraine-and-embrace-ai/">gebruik te maken van AI</a> binnen defensie.</p> <p>In dezelfde week als de top in Parijs <a href="https://www.reuters.com/technology/eu-ditches-plans-regulate-tech-patents-ai-liability-online-privacy-2025-02-12/">schrapte</a> de Europese Commissie de AI-aansprakelijkheidsrichtlijn uit 2022. Deze richtlijn zou consumenten het recht hebben gegeven om schadevergoeding te eisen wanneer ze schade leden door fouten of nalatigheid van AI-aanbieders, -ontwikkelaars of -gebruikers.</p> <p>Het pleidooi van JD Vance’s in Parijs weerspiegelde Donald Trumps visie op AI. Deze richt zich op het positioneren van de VS als wereldleider in AI-ontwikkeling via deregulering, investeringen en innovatie. Tijdens het Wereld Economisch Forum in Davos begin dit jaar verklaarde Trump dat hij van de VS de “<a href="https://www.businesstoday.in/wef-2025/story/trump-outlines-ambitious-vision-for-us-leadership-in-ai-and-cryptocurrency-at-davos-461898-2025-01-24">globale hoofdstad van artificiële intelligentie</a>” wil maken. In lijn met deze visie trok hij een presidentieel besluit van Joe Biden in dat gericht was op het beperken van AI-risico’s voor consumenten, werknemers en de nationale veiligheid. Geruggesteund door deze visie van Trump <a href="https://www.politico.eu/article/google-eu-rules-advanced-ai-artificial-intelligence-step-in-wrong-direction/">bekritiseren</a> de grote technologiebedrijven Meta en Google de Europese AI regulaties als een stap in de verkeerde richting.</p> <p>De zorgen over AI zijn niet verdwenen omdat men de technologie zou onderschatten. Integendeel: tijdens de top in Parijs waarschuwde Dario Amodei, CEO van Anthropic (bekend van chatbot Claude), dat AI-systemen <a href="https://www.anthropic.com/news/paris-ai-summit">tegen 2026</a> mogelijk even krachtig zouden kunnen zijn als een ‘nieuwe natie vol genieën’, met verstrekkende gevolgen voor economie, maatschappij en veiligheid. In een <a href="https://www.bloomberg.com/features/2025-sam-altman-interview/">recent interview</a> voorspelde Sam Altman dat AGI, een AI-systeem dat menselijke intelligentie evenaart, nog tijdens Trumps ambtstermijn gerealiseerd zal worden.</p> <p>Ondertussen pieken de investeringen in het inzetten van AI voor defensie. Bedrijven zoals het controversiële AI-defensiebedrijf Palantir, de beurslieveling die zijn marktwaarde sinds de verkiezing van Trump al met meer dan 180% zag stijgen, hebben de voorbije jaren contracten voor miljarden dollars binnengehaald van de Amerikaanse overheid om de grenzen te bewaken. De CEO, <a href="https://www.wsj.com/tech/who-is-alex-karp-palantir-ceo-dcd66e21">Alex Karp</a>, schreef recent een boek waarin hij pleit dat technologiebedrijven de democratische waarden van het Westen moeten verdedigen. Hij klopt zichzelf op de schouder dat de software van Palantir Amerika dodelijker maakt. Tegelijkertijd heeft OpenAI zijn modellen aangepast en beveiligingen verwijderd om minder te censureren en “<a href="https://techcrunch.com/2025/02/16/openai-tries-to-uncensor-chatgpt/">intellectuele vrijheid meer te omarmen</a>”. Dit betekent dat onderwerpen die tot voor kort werden geweigerd of waar een waarschuwing bij stond, zoals “Black Lives Matter”, nu vrijelijk besproken kunnen worden. Bij verschillende sociale mediabedrijven zoals Meta en X worden veiligheidsteams ontmanteld, wat leidt tot meer tolerantie voor controversiële content.</p> <p>De aandacht voor AI-veiligheid is na de initiële bezorgdheid rond ChatGPT sterk afgenomen. Internationale toppen, oorspronkelijk bedoeld voor veiligheidsdiscussies, zijn verworden tot platforms waar landen vooral hun AI-investeringen en -ambities etaleren. Terwijl de VS onder Trump en de EU onder Von der Leyen inzetten op deregulering en onderlinge competitie, toont China, ironisch genoeg, de meeste bereidheid tot internationale samenwerking op het gebied van veiligheid. Grote technologiebedrijven ontmantelen ondertussen hun veiligheidsteams en verwijderen beveiligingen, terwijl de investeringen in militaire AI-toepassingen een hoogtepunt bereiken. We kunnen alleen maar hopen dat een superintelligente computer niet te snel verschijnt, of op zijn minst menslievend van aard zal zijn.</p>]]></content><author><name></name></author><category term="AI-Veiligheid"/><category term="Europa"/><category term="US"/><summary type="html"><![CDATA[Na de komst van ChatGPT stond AI veiligheid hoog op de (politieke) agenda maar dat lijkt met de AI Action top in Parijs vorige week definitief verleden tijd.]]></summary></entry><entry><title type="html">Eerste stap van de AI Act. Binnenkort allemaal AI geletterd?</title><link href="https://wimcasteels.github.io/blog/2025/AI-Act-stap-1/" rel="alternate" type="text/html" title="Eerste stap van de AI Act. Binnenkort allemaal AI geletterd?"/><published>2025-02-13T00:00:00+00:00</published><updated>2025-02-13T00:00:00+00:00</updated><id>https://wimcasteels.github.io/blog/2025/AI-Act-stap-1</id><content type="html" xml:base="https://wimcasteels.github.io/blog/2025/AI-Act-stap-1/"><![CDATA[<div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/250214.webp" sizes="95vw"/> <img src="/assets/img/250214.webp" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <p>De AI Act reguleert de ontwikkeling en het gebruik van AI binnen de Europese Unie, en geldt ook voor buitenlandse bedrijven die hun producten aan Europeanen aanbieden. De wet heeft een tweeledig doel: enerzijds het bevorderen van veilige en betrouwbare AI-systemen die de fundamentele rechten van EU-burgers respecteren, anderzijds het stimuleren van AI-investeringen en innovatie in Europa. De sancties bij overtreding zijn aanzienlijk: tot 35 miljoen euro of 7% van de jaarlijkse bedrijfsomzet. De AI Act, die op 1 augustus 2024 in werking trad, wordt stapsgewijs ingevoerd. Sinds 2 februari zijn AI-systemen met onacceptabel risico verboden en gelden er verplichtingen rond AI-geletterdheid.</p> <p>De basis van de wet is een indeling van AI-toepassingen in risicoklassen (zie figuur): van onacceptabel (en dus verboden) tot minimaal risico. Systemen in de categorie ‘hoog risico’ moeten voldoen aan strikte verplichtingen, waaronder risicobeoordeling en mitigatie strategieën.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/250214-1-480.webp 480w,/assets/img/250214-1-800.webp 800w,/assets/img/250214-1-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/250214-1.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> De risicoklassen binnen de AI Act (bron: <a href="https://www.adalovelaceinstitute.org/resource/eu-ai-act-explainer/">Ada Lovelace Institute</a>) </div> <p>De risicoklassen in de AI Act zijn niet scherp afgebakend, waardoor er onduidelijkheid bestaat over de classificatie van veel systemen. Om dit te verduidelijken publiceerde de Europese Commissie op 4 februari, twee dagen na de start van het verbod op systemen in de hoogste risicoklasse, een <a href="https://digital-strategy.ec.europa.eu/en/library/commission-publishes-guidelines-prohibited-artificial-intelligence-ai-practices-defined-ai-act">document met richtlijnen</a>. Deze niet-bindende richtlijnen bevatten praktische voorbeelden en toelichtingen voor de interpretatie en naleving van de AI Act. Zo zijn sociale scoringsalgoritmes in het algemeen verboden, maar mogen financiële instellingen wel AI gebruiken om de kredietwaardigheid van klanten te beoordelen. Op 6 februari volgde nog een aanvullende <a href="https://digital-strategy.ec.europa.eu/en/library/commission-publishes-guidelines-ai-system-definition-facilitate-first-ai-acts-rules-application">richtlijn</a> over de definitie van AI en wat er binnen de AI Act onder een AI-systeem valt. Deze tekst stelt vast dat er geen sluitende classificatie of volledige lijst kan worden opgesteld van systemen die wel of niet onder de definitie vallen.</p> <p>De systemen in de hoogste risicoklasse zijn sinds 2 februari in principe verboden, maar de handhaving en sancties van de AI Act treden pas in werking vanaf 2 augustus 2025. Tot die datum blijft het verbod dus zonder actieve handhaving. Er heerst nog veel onduidelijkheid over de implementatie van deze handhaving. Lidstaten moesten voor 2 november 2024 hun nationale bevoegde instanties aanwijzen. Op die deadline hadden slechts <a href="https://artificialintelligenceact.eu/national-implementation-plans/">7 van de 27 lidstaten</a> dit gedaan, en <a href="https://digital-strategy.ec.europa.eu/en/policies/ai-act-governance-and-enforcement">op het moment dat deze post verschijnt</a> zijn er nog steeds 6 lidstaten die in gebreke blijven, waaronder, je raadt het al, België.</p> <p>De AI Act wordt wereldwijd gezien als een van de meest vooruitstrevende AI-wetgevingen, maar de totstandkoming verliep moeizaam. Het proces begon in april 2021 met een eerste <a href="https://digital-strategy.ec.europa.eu/en/library/proposal-regulation-laying-down-harmonised-rules-artificial-intelligence">voorstel van de Europese Commissie</a> en duurde tot eind 2023 voordat de finale tekst werd goedgekeurd. Een belangrijke complicerende factor was de introductie van ChatGPT tijdens het wetgevingsproces. Deze ontwikkeling leidde ertoe dat plotseling veel meer mensen AI gingen gebruiken. De snelle evolutie van de onderliggende taalmodellen, die steeds krachtiger werden, bracht nieuwe risico’s met zich mee die niet in het originele voorstel waren meegenomen. Deze systemen werden uiteindelijk in 2023 in de wetgeving opgenomen onder de bredere term ‘general-purpose AI<em>’</em> (GPAI) modellen.</p> <p>De ontwikkeling van deze GPAI-modellen vereist enorme investeringen. Dit leidde bij de introductie in de AI Act tot intensieve lobbyactiviteiten vanuit de industrie. Het <a href="https://digital-strategy.ec.europa.eu/en/policies/regulatory-framework-ai">Byte to Byte</a> rapport van Corporate Europe Observatory toont aan dat grote technologiebedrijven buitenproportioneel veel toegang hadden tot Europese beleidsmakers in vergelijking met andere belanghebbenden (zie ook figuur). Een sprekend voorbeeld: Google’s CEO Sundar Pichai wist op één dag gesprekken te voeren met drie verschillende Europese commissarissen.</p> <p align="center"><iframe aria-label="Bar chart" data-external="1" frameborder="0" height="205" id="datawrapper-chart-0CcqX" scrolling="no" src="https://datawrapper.dwcdn.net/0CcqX/1/" style="border: none;" title="Top 5 lobbyists on the AI Act in 2023" width="600"></iframe></p> <p>Het lobbywerk tegen de AI Act was succesvol en zwakte de wetgeving aanzienlijk af, maar het was uiteindelijk de <a href="https://corporateeurope.org/en/2024/03/trojan-horses-how-european-startups-teamed-big-tech-gut-ai-act">weerstand vanuit Europa</a> zelf die de doorslag gaf. De Franse startup Mistral AI en de Duitse startup Aleph Alpha vonden gehoor bij hun respectievelijke regeringen. Een Frans-Duits-Italiaans front zorgde er vervolgens voor dat bindende maatregelen uit de AI Act verdwenen en werden vervangen door transparantievereisten. De strengste regels gelden voor <a href="https://artificialintelligenceact.eu/article/51/">GPAI-systemen met een systemisch risico</a>. De enige concrete definitie hiervoor betreft modellen waarvoor bij de ontwikkeling meer dan 10^24 FLOPS aan computerberekeningen nodig waren, een enorme hoeveelheid waar momenteel wereldwijd alleen GPT-4 van OpenAI onder valt. Deze grens lijkt al helemaal achterhaald sinds het <a href="https://www.technologyreview.com/2025/01/24/1110526/china-deepseek-top-ai-despite-sanctions/">Chinese Deepseek</a> aantoonde dat er veel minder computerkracht nodig is voor deze modellen. Hoewel modellen met grote maatschappelijke impact ook onder deze categorie met systemisch risico vallen, blijft vooralsnog onduidelijk hoe dit precies wordt bepaald.</p> <p>Tijdens de <a href="https://www.elysee.fr/en/sommet-pour-l-action-sur-l-ia">AI Action top</a> in Parijs eerder deze week leken sommige Europese leiders gemengde gevoelens te hebben over de AI Act. De Franse president <a href="https://www.nytimes.com/2025/02/10/business/ai-summit-paris.html">Macron</a> benadrukte het belang van innovatie en waarschuwde dat regulering deze kan belemmeren. Hij verklaarde dat Europa nog steeds meedoet in de ‘AI race’ en kondigde <a href="https://www.cnbc.com/2025/02/10/frances-answer-to-stargate-macron-announces-ai-investment.html">Franse investeringen</a> aan ter waarde van 109 miljard euro. <a href="https://www.euractiv.com/section/tech/news/von-der-leyen-launches-worlds-largest-public-private-partnership-to-win-ai-race/">Ursula Von der Leyen</a>, de voorzitter van de Europese Commissie<strong>,</strong> bevestigde dat de AI race nog niet voorbij is en lanceerde InvestAI, een publiek-private samenwerking ter waarde van 200 miljard euro. De Amerikaanse vicepresident <a href="https://www.reuters.com/technology/artificial-intelligence/europe-looks-embrace-ai-paris-summits-2nd-day-while-global-consensus-unclear-2025-02-11/">JD Vance</a> verzette zich nadrukkelijk tegen regulering en stelde dat de Europese wetgeving de technologie ‘wurgt’. De slotverklaring van de top in Parijs over ‘inclusieve en duurzame AI’ werd niet ondertekend door de VS en het VK, waardoor de top algemeen als een gemiste kans wordt beschouwd.</p> <p>Op 2 februari trad ook het artikel over AI-geletterdheid in de AI Act in werking. De originele versie was hier een <a href="https://www.law.kuleuven.be/citip/blog/this-time-humans-learn-about-machines-ai-literacy-in-the-ai-act-part-1/">stuk ambitieuzer</a>: deze verplichtte zowel lidstaten als bedrijven om AI-geletterdheid in alle sectoren van de samenleving te bevorderen. In het <a href="https://artificialintelligenceact.eu/article/4/">finale artikel</a> zijn de lidstaten echter geschrapt en richt de wet zich alleen op AI-bedrijven. Zij moeten ervoor zorgen dat hun personeel en andere betrokkenen een ‘voldoende niveau’ van AI-geletterdheid bereiken. Dit niveau hangt af van de context, zoals de risicoklasse van het AI-systeem, maar wat precies als ‘voldoende’ wordt beschouwd en hoe dit zal worden gehandhaafd, blijft voorlopig onduidelijk.</p> <p>De <a href="https://artificialintelligenceact.eu/article/3/">definitie van AI-geletterdheid</a> in de AI Act reikt verder dan alleen bedrijven en deze vermeld dat ook personen die door AI-systemen worden beïnvloed, moeten beschikken over AI-geletterdheid. In de definitie wordt bij AI geletterdheid onder andere verstaan dat men bewust is van de mogelijkheden, risico’s en potentiële schade van AI. Dit stuk gaat veel breder dan enkel de werknemers van AI bedrijven. Een aanvullende bepaling (<a href="https://artificialintelligenceact.eu/recital/20/"><em>Recital 20</em></a>) benadrukt het belang van een brede implementatie van AI-geletterdheid en de rol van de <a href="https://digital-strategy.ec.europa.eu/en/policies/ai-board">Europese AI Raad</a> hierin. We kunnen dus verwachten dat Europa nog meer initiatieven zal lanceren rond AI-geletterdheid. De Vlaamse AI Academy (VAIA) voorziet alvast enkele <a href="https://www.vaia.be/nl/blog/ai-literacy-eu-ai-act-artikel-4">tips</a> om te werken aan AI geletterdheid.</p> <p>De AI Act is vooruitstrevend en behandelt belangrijke maatschappelijke uitdagingen van AI (hoewel bijvoorbeeld de ecologische voetafdruk buiten beschouwing blijft). De implementatie blijkt echter complex. De wet beoogt innovatie te stimuleren, maar de industrie toonde zich hierover sceptisch. Door krachtige tegenstand is de wetgeving significant afgezwakt. Er zijn nog diverse obstakels te overwinnen, waarbij veel zal afhangen van de uiteindelijke interpretatie en handhaving, aspecten die momenteel nog onduidelijk zijn.</p>]]></content><author><name></name></author><category term="AI-Act"/><category term="Europa"/><summary type="html"><![CDATA[Begin februari trad de eerste fase van de AI Act in werking. Deze Europese wetgeving verbiedt AI-systemen met een onacceptabel risico en stelt verplichtingen over AI-geletterdheid.]]></summary></entry></feed>