---
layout: post
title: Wie ligt er nog wakker van de veiligheid van AI?
date: 2025-02-17 00:00:00
description: Na de komst van ChatGPT stond AI veiligheid hoog op de (politieke) agenda maar dat lijkt met de AI Action top in Parijs vorige week definitief verleden tijd. 
tags: 
categories: AI-Veiligheid Europa US
giscus_comments: true
thumbnail: assets/img/250218.webp
---

<div class="row mt-3">
    <div class="col-sm mt-3 mt-md-0">
        {% include figure.liquid loading="eager" path="assets/img/250218.webp" class="img-fluid rounded z-depth-1" %}
    </div>
</div>

De lancering van ChatGPT eind 2022 zond een schokgolf door de wereld. Nog nooit bereikte een digitaal hulpmiddel zo snel 100 miljoen gebruikers (in [slechts 2 maanden](https://www.theguardian.com/technology/2023/feb/02/chatgpt-100-million-users-open-ai-fastest-growing-app)). Een aanzienlijk deel van de wereldbevolking maakte zo kennis met AI en zijn mogelijkheden. Deze technologie wekte echter ook bezorgdheid op over de veiligheid. De exponentiële vooruitgang riep vragen op over waar dit zou eindigen en of de gevolgen wel positief zouden zijn voor de mensheid. Zorgen ontstonden over de verspreiding van nepnieuws, mogelijke ontwrichting van de arbeidsmarkt en het potentiële verlies van controle over AI-systemen. 

Het existentiële risico van AI, dat de ontwikkeling ervan zou kunnen leiden tot een humanitaire ramp, spreekt tot de verbeelding. Dit wordt in vaktermen aangeduid als p(doom): de kans dat AI leidt tot een existentiële catastrofe. Uit een [bevraging uit 2023 bij AI-onderzoekers](https://wiki.aiimpacts.org/ai_timelines/predictions_of_human-level_ai_timelines/ai_timeline_surveys/2023_expert_survey_on_progress_in_ai) bleek dat ongeveer de helft deze kans hoger inschat dan 10%. De Israëlische historicus Yuval Harari maakte hierover een treffende [vergelijking met een vliegreis](https://www.nytimes.com/2023/03/24/opinion/yuval-harari-ai-chatgpt.html): als de helft van de vliegtuigingenieurs je vertelt dat er 10 procent kans is dat het toestel neerstort, zou je dan instappen? Deze bezorgdheden leidden tot concrete actie. Een [open brief](https://futureoflife.org/open-letter/pause-giant-ai-experiments/), ondertekend door meer dan 30.000 mensen, riep op tot een pauze in de ontwikkeling van grootschalige AI-systemen tot de risico's beter in kaart zijn gebracht. Ook Sam Altman, CEO van OpenAI (de organisatie achter ChatGPT), [reisde in 2023 de wereld rond](https://www.wired.com/story/sam-altman-world-tour-ai-doomers/) om politieke leiders te waarschuwen voor deze gevaren. Al werd dit door velen als een PR-stunt gezien. 

Het Verenigd Koninkrijk nam onder toenmalig premier Rishi Sunak het initiatief om wereldleiders en vertegenwoordigers uit de industrie samen te brengen tijdens de [AI Safety Summit](https://www.gov.uk/government/topical-events/ai-safety-summit-2023). Deze vond plaats in het symbolische Bletchley Park, waar tijdens de Tweede Wereldoorlog de Duitse code werd gekraakt. De 28 aanwezige landen ondertekenden de [Bletchley-verklaring](https://www.gov.uk/government/publications/ai-safety-summit-2023-the-bletchley-declaration/the-bletchley-declaration-by-countries-attending-the-ai-safety-summit-1-2-november-2023), waarin werd vastgelegd dat AI op een veilige manier moet worden ontworpen, ontwikkeld, ingezet en gebruikt, waarbij de mens centraal staat en betrouwbaarheid en verantwoordelijkheid voorop staan.

Verschillende vooraanstaande wetenschappers spraken zich uit over de risico's van AI, waaronder Geoffrey Hinton en Yoshua Bengio, twee van de drie zogenaamde 'AI-pioniers' die in 2018 de [Turing Award](https://awards.acm.org/about/2018-turing) wonnen voor hun werk over AI en deep learning. Hinton, die in 2024 nog de Nobelprijs voor natuurkunde ontving, [vertrok bij Google](https://www.theguardian.com/technology/2023/may/02/geoffrey-hinton-godfather-of-ai-quits-google-warns-dangers-of-machine-learning) om zich vrij te kunnen uitspreken over de risico's. Yoshua Bengio werd na de AI Safety top aangesteld door de Britse regering als voorzitter van een wetenschappelijke raad over het thema. Met meer dan 100 wetenschappers uit 30 landen publiceerde hij in januari het [AI Safety rapport](https://www.gov.uk/government/publications/international-ai-safety-report-2025), een document van bijna 300 pagina's dat uitgebreid ingaat op de risico's van AI. De derde AI-pionier, Yann LeCun, houdt er als senior wetenschapper bij Meta een [andere mening](https://www.wsj.com/tech/ai/yann-lecun-ai-meta-aa59e2f5) op na en denkt dat de nadruk op de existentiële risico’s naast de kwestie zijn.  

De tweede editie van de AI Safety top vond plaats in Seoul in mei 2024 en resulteerde in een belofte van 27 landen om werk rond ernstige AI-risico's te verdiepen. Op de derde editie in Parijs vorige week, onder de naam [AI Action top](https://www.elysee.fr/en/sommet-pour-l-action-sur-l-ia), was het oorspronkelijke thema van AI-veiligheid echter vrijwel afwezig. In plaats daarvan lag de nadruk op innovatie. Emmanuel Macron, de president van gastland Frankrijk, opende de top met de aankondiging van Franse AI-investeringen en benadrukte dat Europa en Frankrijk nog volop meedoen in de wereldwijde AI-race. [Ursula von der Leyen](https://www.euractiv.com/section/tech/news/von-der-leyen-launches-worlds-largest-public-private-partnership-to-win-ai-race/), voorzitter van de Europese Commissie**,** sloot zich hierbij aan met Europese investeringsbeloften en de boodschap dat de AI-race nog niet voorbij is. De Amerikaanse vicepresident JD Vance ging nog een stap verder met een pleidooi tegen regulering, waarbij hij waarschuwde dat deze de industrie zou kunnen verstikken. Hoewel de voorzitter van de wetenschappelijke raad Bengio wel in Parijs aanwezig was, sprak hij niet op de hoofdtop maar gaf hij een presentatie op een andere [conferentie](https://www.iaseai.org/conference) over het veilig en ethisch gebruik van AI. Opmerkelijk genoeg toonde [China](https://www.reuters.com/technology/artificial-intelligence/china-is-willing-share-achievements-ai-vice-premier-says-paris-summit-2025-02-11/), het land dat vaak wordt gezien als de tegenstander op AI-gebied, de meeste bereidheid tot samenwerking rond veiligheid. Het land gaf aan vorderingen in AI te willen delen om "een gemeenschap met een gedeelde toekomst voor de mensheid" op te bouwen. 

De VS en het VK [weigerden](https://www.theguardian.com/technology/2025/feb/11/us-uk-paris-ai-summit-artificial-intelligence-declaration) de slotverklaring van de Parijse top over 'inclusieve en duurzame' AI te ondertekenen. De Amerikaanse vicepresident vertrok zelfs voor het traditionele fotomoment. Kort daarna werd bekend dat het Britse 'AI Safety Institute' van [naam verandert](https://www.gov.uk/government/news/tackling-ai-security-risks-to-unleash-growth-and-deliver-plan-for-change) naar het 'AI Security Institute'. Deze naamswijziging weerspiegelt een verschuiving van de focus van existentiële doemscenario’s naar de nationale veiligheidsrisico's van AI, zoals cyberaanvallen en de productie van chemische of biologische wapens. Dit sluit aan bij de Britse plannen om meer [gebruik te maken van AI](https://committees.parliament.uk/committee/24/defence-committee/news/204613/defence-committee-mod-must-learn-from-ukraine-and-embrace-ai/) binnen defensie.

In dezelfde week als de top in Parijs [schrapte](https://www.reuters.com/technology/eu-ditches-plans-regulate-tech-patents-ai-liability-online-privacy-2025-02-12/) de Europese Commissie de AI-aansprakelijkheidsrichtlijn uit 2022. Deze richtlijn zou consumenten het recht hebben gegeven om schadevergoeding te eisen wanneer ze schade leden door fouten of nalatigheid van AI-aanbieders, -ontwikkelaars of -gebruikers.

Het pleidooi van JD Vance's in Parijs weerspiegelde Donald Trumps visie op AI. Deze richt zich op het positioneren van de VS als wereldleider in AI-ontwikkeling via deregulering, investeringen en innovatie. Tijdens het Wereld Economisch Forum in Davos begin dit jaar verklaarde Trump dat hij van de VS de "[globale hoofdstad van artificiële intelligentie](https://www.businesstoday.in/wef-2025/story/trump-outlines-ambitious-vision-for-us-leadership-in-ai-and-cryptocurrency-at-davos-461898-2025-01-24)" wil maken. In lijn met deze visie trok hij een presidentieel besluit van Joe Biden in dat gericht was op het beperken van AI-risico's voor consumenten, werknemers en de nationale veiligheid. Geruggesteund door deze visie van Trump [bekritiseren](https://www.politico.eu/article/google-eu-rules-advanced-ai-artificial-intelligence-step-in-wrong-direction/) de grote technologiebedrijven Meta en Google de Europese AI regulaties als een stap in de verkeerde richting.

De zorgen over AI zijn niet verdwenen omdat men de technologie zou onderschatten. Integendeel: tijdens de top in Parijs waarschuwde Dario Amodei, CEO van Anthropic (bekend van chatbot Claude), dat AI-systemen [tegen 2026](https://www.anthropic.com/news/paris-ai-summit) mogelijk even krachtig zouden kunnen zijn als een ‘nieuwe natie vol genieën’, met verstrekkende gevolgen voor economie, maatschappij en veiligheid. In een [recent interview](https://www.bloomberg.com/features/2025-sam-altman-interview/) voorspelde Sam Altman dat AGI, een AI-systeem dat menselijke intelligentie evenaart, nog tijdens Trumps ambtstermijn gerealiseerd zal worden. 

Ondertussen pieken de investeringen in het inzetten van AI voor defensie. Bedrijven zoals het controversiële AI-defensiebedrijf Palantir, de beurslieveling die zijn marktwaarde sinds de verkiezing van Trump al met meer dan 180% zag stijgen, hebben de voorbije jaren contracten voor miljarden dollars binnengehaald van de Amerikaanse overheid om de grenzen te bewaken. De CEO, [Alex Karp](https://www.wsj.com/tech/who-is-alex-karp-palantir-ceo-dcd66e21), schreef recent een boek waarin hij pleit dat technologiebedrijven de democratische waarden van het Westen moeten verdedigen. Hij klopt zichzelf op de schouder dat de software van Palantir Amerika dodelijker maakt. Tegelijkertijd heeft OpenAI zijn modellen aangepast en beveiligingen verwijderd om minder te censureren en "[intellectuele vrijheid meer te omarmen](https://techcrunch.com/2025/02/16/openai-tries-to-uncensor-chatgpt/)”. Dit betekent dat onderwerpen die tot voor kort werden geweigerd of waar een waarschuwing bij stond, zoals "Black Lives Matter", nu vrijelijk besproken kunnen worden. Bij verschillende sociale mediabedrijven zoals Meta en X worden veiligheidsteams ontmanteld, wat leidt tot meer tolerantie voor controversiële content.

De aandacht voor AI-veiligheid is na de initiële bezorgdheid rond ChatGPT sterk afgenomen. Internationale toppen, oorspronkelijk bedoeld voor veiligheidsdiscussies, zijn verworden tot platforms waar landen vooral hun AI-investeringen en -ambities etaleren. Terwijl de VS onder Trump en de EU onder Von der Leyen inzetten op deregulering en onderlinge competitie, toont China, ironisch genoeg, de meeste bereidheid tot internationale samenwerking op het gebied van veiligheid. Grote technologiebedrijven ontmantelen ondertussen hun veiligheidsteams en verwijderen beveiligingen, terwijl de investeringen in militaire AI-toepassingen een hoogtepunt bereiken. We kunnen alleen maar hopen dat een superintelligente computer niet te snel verschijnt, of op zijn minst menslievend van aard zal zijn.